{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1aa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "953d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# !wget \"http://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\" --no-check-certificate\n",
    "data = pd.read_excel('ENB2012_data.xlsx', header=0).iloc[:, :10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240997c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from torch import nn\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import HMC, MCMC, SVI, NUTS, TraceMeanField_ELBO\n",
    "from pyro import poutine\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange\n",
    "from rec.utils import kl_estimate_with_mc\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f82ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Laplace_GCN_Code.preds.laplace import Laplace\n",
    "from Laplace_GCN_Code.preds.likelihoods import GaussianLh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c277c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e5bc23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "device = torch.device('cpu')\n",
    "data = load_iris()\n",
    "x_ = data['data']\n",
    "y_ = data['target']\n",
    "N_tr = 50\n",
    "N_val = 150 - N_tr\n",
    "a = np.arange(x_.shape[0])\n",
    "train_index = np.random.choice(a, size = N_tr, replace = False)\n",
    "val_index = np.delete(a, train_index, axis=0)\n",
    "x_train = x_[train_index]\n",
    "y_train = y_[train_index]\n",
    "x_val = x_[val_index][:]\n",
    "y_val = y_[val_index][:]\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train-x_m)/ x_s\n",
    "x_val = (x_val-x_m)/ x_s\n",
    "D_in = x_train.shape[1]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.tensor(y_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.tensor(y_val)\n",
    "plt.scatter(x_train.numpy()[:,0],y_train.numpy())\n",
    "    \n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_test = x_val.to(device)\n",
    "y_test = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dfbdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(x, y=None, weights=None, in_size=1, num_nodes=10, out_size=1, ELBO_BETA=1.):\n",
    "    # sample vector of weights for regression\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    # sample params\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        weights = pyro.sample(\"weights\", dist.Normal(torch.zeros(total_weights), 1.).to_event(1))\n",
    "\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    logits = x.squeeze()\n",
    "    \n",
    "    with pyro.plate(\"data\", x.shape[0]):\n",
    "        obs = pyro.sample(\"obs\", dist.Categorical(logits=logits).to_event(1), obs=y)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def make_empirical_gmm(samples, num_nodes, x_test):\n",
    "    rho_noise = samples['params'][:, -D_out:]\n",
    "    noise = F.softplus(rho_noise) ** 2\n",
    "    preds_dict = Predictive(regression_model, samples, return_sites=['_RETURN'])(x_test, None, num_nodes=num_nodes,\n",
    "                                                                                 in_size=D_in, out_size=D_out)\n",
    "    preds = preds_dict['_RETURN']\n",
    "    mix = dist.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = dist.MultivariateNormal(loc=preds.squeeze().permute(1, 0, 2), covariance_matrix=torch.diag_embed(noise))\n",
    "    gmm = dist.MixtureSameFamily(mix, comp)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71944c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class map_regression_model(nn.Module):\n",
    "    def __init__(self, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(map_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "        self.fc1_weights = nn.Parameter(torch.randn(self.num_nodes, self.in_size))\n",
    "        self.fc1_bias = nn.Parameter(torch.randn(self.num_nodes))\n",
    "\n",
    "        self.fc2_weights = nn.Parameter(torch.randn(self.num_nodes, self.num_nodes))\n",
    "        self.fc2_bias = nn.Parameter(torch.randn(self.num_nodes))\n",
    "\n",
    "        self.fc3_weights = nn.Parameter(torch.randn(self.out_size, self.num_nodes))\n",
    "        self.fc3_bias = nn.Parameter(torch.randn(self.out_size))\n",
    "\n",
    "        self.rho = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    # compute forward pass\n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "\n",
    "        return x  \n",
    "    \n",
    "    def loss_function(self, x, y):\n",
    "        y_preds = self.forward(x)\n",
    "        return -D.Normal(loc=y_preds, scale=F.softplus(self.rho)).log_prob(y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e035560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deterministic_regression_model(nn.Module):\n",
    "    def __init__(self, params, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(deterministic_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "        weights, rho = params[:-out_size], params[-out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes *self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx +self.out_size].reshape(self.out_size)\n",
    "        idx +=self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params\n",
    "\n",
    "        # compute forward pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def weight_prior_lp(self):\n",
    "        return dist.Normal(loc=0., scale=1.).log_prob(self.params).mean()\n",
    "    \n",
    "    def data_likelihood(self, x, y):\n",
    "        likelihood = dist.Normal(loc=self.forward(x),\n",
    "                              scale=F.softplus(self.rho))\n",
    "        return likelihood.log_prob(y).sum(-1).mean()\n",
    "    \n",
    "    def joint_log_prob(self, x, y):\n",
    "        return self.data_likelihood(x, y) + self.weight_prior_lp(x, y)\n",
    "    \n",
    "    def make_weights_from_sample(self, params):\n",
    "        weights, rho = params[:-self.out_size], params[-self.out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes * self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx + self.out_size].reshape(self.out_size)\n",
    "        idx += self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12998e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = x_.shape[-1]\n",
    "D_out = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8f31aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 2000/2000 [00:04, 483.32it/s, step size=1.63e-01, acc. prob=0.742]\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(10)\n",
    "ELBO_BETA = 1.\n",
    "S=0\n",
    "num_nodes = 50\n",
    "\n",
    "# run HMC\n",
    "kernel = HMC(classification_model, step_size=0.001, num_steps=5, target_accept_prob=0.8)\n",
    "nuts_kernel = NUTS(classification_model, step_size=0.1, target_accept_prob=0.5, max_tree_depth=5)\n",
    "mcmc = MCMC(kernel, num_samples=1000, warmup_steps=1000, num_chains=1)\n",
    "mcmc.run(x_train, y_train, ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31603ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_samples = mcmc.get_samples(50)\n",
    "from pyro.infer import Predictive\n",
    "pred = Predictive(classification_model, full_samples, return_sites=['obs', '_RETURN'])(x_test, None, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "68cdc544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.3517)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.Categorical(logits=pred['_RETURN']).log_prob(y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a31e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6396bb31d27443b1af2f21615f4c909c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "\n",
    "# train Factored Gaussian approx\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(classification_model)\n",
    "svi = SVI(classification_model, guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_iterations = 10000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train, y_train, ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fab2f19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd1e15592b0>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc9a2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = params\n",
    "variational_posterior = dist.MultivariateNormal(loc=means, covariance_matrix=torch.diag(stds ** 2))\n",
    "variational_sample = variational_posterior.sample((50,))\n",
    "variational_samples = {\"weights\" : variational_sample}\n",
    "#kl_var_prior = kl_estimate_with_mc(variational_posterior, prior)\n",
    "var_pred = Predictive(classification_model, variational_samples, return_sites=['obs', '_RETURN'])(x_test, None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfbebb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4375)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.Categorical(logits=var_pred['_RETURN']).log_prob(y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19384eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_test[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_test[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_test[S]).mean()}, KDE {kde_gmm.log_prob(y_test[S]).mean()}, VAR {var_gmm.log_prob(y_test[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_train[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_train[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_train[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_train[S]).mean()}, KDE {kde_gmm.log_prob(y_train[S]).mean()}, VAR {var_gmm.log_prob(y_train[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a0740",
   "metadata": {},
   "source": [
    "# Compress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd607f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f50d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = deterministic_regression_model(full_samples['params'][10], in_size=D_in, num_nodes=num_nodes, out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20464c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = full_samples['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2cfde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p = kl_kde_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = samples.mean(0)\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1.\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d14d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dummy_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bec8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = torch.zeros([0])\n",
    "for w in compressed_weights_emp_low_eps:\n",
    "    weight_samples = torch.cat([weight_samples, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890686b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = {'params':weight_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1175cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c41881",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm = make_empirical_gmm(weight_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71553a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298483e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE_BNN import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_target = kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train[S],\n",
    "                         y_data=y_train[S],\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1.,\n",
    "                        total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    weight_samples_kde = torch.cat([weight_samples_kde, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffea139",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    dummy_model.make_weights_from_sample(w)\n",
    "    log_probs_kde = torch.cat([log_probs_kde, dummy_model.data_likelihood(x_train[S], y_train[S])[None]], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192855a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"params\":weight_samples_kde[torch.topk(log_probs_kde, k=25)[1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = {'params':weight_samples_kde}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_kde, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde = make_empirical_gmm(weight_samples_kde, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb80562",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde_train = make_empirical_gmm(weight_samples_kde, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_kde_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbaf5c0",
   "metadata": {},
   "source": [
    "# Variational Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1.)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1322371",
   "metadata": {},
   "outputs": [],
   "source": [
    "del compute_params_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = torch.zeros([0])\n",
    "for w in compressed_weights_var_high_eps:\n",
    "    weight_samples_var = torch.cat([weight_samples_var, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a543bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = {'params':weight_samples_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da278808",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_var, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var = make_empirical_gmm(weight_samples_var, num_nodes, x_test[S])\n",
    "\n",
    "compressed_gmm_var.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var_train = make_empirical_gmm(weight_samples_var, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_var_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "# pkl.dump(full_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/full_samples_split{S}.pkl\", \"wb\"))\n",
    "# pkl.dump(kde_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(variational_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/variational_samples_split{S}.pkl\", \"wb\"))\n",
    "# pkl.dump(weight_samples_kde, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_kde_samples_split{S}.pkl\", \"wb\"))\n",
    "# pkl.dump(weight_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_emp_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_var, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_var_samples_split{S}.pkl\", \"wb\"))\n",
    "# pkl.dump(kl_kde_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_kl_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_var_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/var_kl_split{S}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ea80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4763d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
