{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fda7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cf83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037cc729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1984273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31634b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7307c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltorch.set_random_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e89d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95942b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BNNs.DeterministicNN import Deterministic_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102bfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds(preds, title='', fs=16):\n",
    "    # plot the fit\n",
    "    fs = 16\n",
    "\n",
    "    m = preds.mean(0).to('cpu')\n",
    "    s = preds.std(0).to('cpu')\n",
    "    s_al = (preds.var(0).to('cpu') + beta ** -1) ** 0.5\n",
    "\n",
    "    f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = (m - s*2).flatten(), (m + s*2).flatten()\n",
    "    # + aleotoric\n",
    "    lower_al, upper_al = (m - s_al*2).flatten(), (m + s_al*2).flatten()\n",
    "\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(xs.numpy(), m.numpy(), 'b', rasterized=True)\n",
    "    ax.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)# Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(xs.flatten().numpy(), lower.numpy(), upper.numpy(), alpha=0.5, rasterized=True)\n",
    "    ax.fill_between(xs.flatten().numpy(), lower_al.numpy(), upper_al.numpy(), alpha=0.2, rasterized=True)\n",
    "    plt.grid()\n",
    "    ax.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "    ax.set_title(title, fontsize=fs)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_preds(preds_1, preds_2, title_1='', title_2='', fs=12):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # plot 1\n",
    "    m_1 = preds_1.mean(0).to('cpu')\n",
    "    s_1 = preds_1.std(0).to('cpu')\n",
    "    s_al_1 = (preds_1.var(0).to('cpu') + beta ** -1) ** 0.5\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower_1, upper_1 = (m_1 - s_1*2).flatten(), (m_1 + s_1*2).flatten()\n",
    "    # + aleotoric\n",
    "    lower_al_1, upper_al_1 = (m_1 - s_al_1*2).flatten(), (m_1 + s_al_1*2).flatten()\n",
    "\n",
    "    # Plot training data as black stars\n",
    "    ax1.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "    # Plot predictive means as blue line\n",
    "    ax1.plot(xs.numpy(), m_1.numpy(), 'b', rasterized=True)\n",
    "    ax1.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)# Shade between the lower and upper confidence bounds\n",
    "    ax1.fill_between(xs.flatten().numpy(), lower_1.numpy(), upper_1.numpy(), alpha=0.5, rasterized=True)\n",
    "    ax1.fill_between(xs.flatten().numpy(), lower_al_1.numpy(), upper_al_1.numpy(), alpha=0.2, rasterized=True)\n",
    "    plt.grid()\n",
    "    ax1.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax1.tick_params(axis='both', which='minor', labelsize=14)\n",
    "    ax1.set_title(title_1, fontsize=fs)\n",
    "    \n",
    "    # plot 2\n",
    "    m_2 = preds_2.mean(0).to('cpu')\n",
    "    s_2 = preds_2.std(0).to('cpu')\n",
    "    s_al_2 = (preds_2.var(0).to('cpu') + beta ** -1) ** 0.5\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower_2, upper_2 = (m_2 - s_2*2).flatten(), (m_2 + s_2*2).flatten()\n",
    "    # + aleotoric\n",
    "    lower_al_2, upper_al_2 = (m_2 - s_al_2*2).flatten(), (m_2 + s_al_2*2).flatten()\n",
    "\n",
    "    # Plot training data as black stars\n",
    "    ax2.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "    # Plot predictive means as blue line\n",
    "    ax2.plot(xs.numpy(), m_2.numpy(), 'b', rasterized=True)\n",
    "    ax2.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)# Shade between the lower and upper confidence bounds\n",
    "    ax2.fill_between(xs.flatten().numpy(), lower_2.numpy(), upper_2.numpy(), alpha=0.5, rasterized=True)\n",
    "    ax2.fill_between(xs.flatten().numpy(), lower_al_2.numpy(), upper_al_2.numpy(), alpha=0.2, rasterized=True)\n",
    "    plt.grid()\n",
    "    ax2.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=14)\n",
    "    ax2.tick_params(axis='both', which='minor', labelsize=14)\n",
    "    ax2.set_title(title_2, fontsize=fs)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create toy dataset\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.manual_seed(20)\n",
    "x = torch.cat([torch.Tensor(75).uniform_(-5, -2).sort()[0].reshape(-1, 1),\n",
    "               torch.Tensor(50).uniform_(2, 5).sort()[0].reshape(-1, 1)])\n",
    "i = 30\n",
    "x_data = torch.cat([x[0:i - 15], x[i + 14:]])\n",
    "\n",
    "# generate some data\n",
    "alpha, beta, num_nodes = 1., 100., 2\n",
    "\n",
    "# generate some data\n",
    "data_generator_model = Deterministic_NN(alpha=alpha, beta=beta, num_nodes=num_nodes)\n",
    "sampled_weights = data_generator_model.sample_weights_from_prior()\n",
    "data_generator_model.make_weights_from_sample(sampled_weights)\n",
    "y_data = data_generator_model(x_data).detach() + (\n",
    "            1 / data_generator_model.likelihood_beta ** 0.5) * torch.randn_like(\n",
    "    data_generator_model(x_data).detach())\n",
    "\n",
    "x_test = torch.Tensor(200).uniform_(-10., 10.).sort()[0]\n",
    "y_test = data_generator_model(x_test).detach() + (\n",
    "            1 / data_generator_model.likelihood_beta ** 0.5) * torch.randn_like(\n",
    "    data_generator_model(x_test).detach()).sort()[0]\n",
    "\n",
    "xs = torch.linspace(-10, 10, 100)\n",
    "ys = data_generator_model(xs).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(x_data,y_data, 'k*')\n",
    "plt.plot(xs, ys, 'r')\n",
    "plt.legend(['Observed Data', 'Ground Truth'], fontsize = 16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9643737",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(x_data,y_data, 'k*')\n",
    "plt.plot(x_test,y_test, 'k+')\n",
    "plt.plot(xs, ys, 'r')\n",
    "plt.legend(['Observed Data', 'Ground Truth', 'Test Data'], fontsize = 16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da46a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device  =torch.device('cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x.view(-1, 1)))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.009\n",
    "num_samples = 5000\n",
    "L = 10\n",
    "burn = 1000\n",
    "store_on_GPU = False\n",
    "debug = False\n",
    "model_loss = 'regression'\n",
    "mass = 1.0\n",
    "\n",
    "# Effect of tau\n",
    "# Set to tau = 1000. to see a function that is less bendy (weights restricted to small bends)\n",
    "# Set to tau = 1. for more flexible\n",
    "\n",
    "ELBO_BETA = .1\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = beta * 1./ELBO_BETA # Output Precision\n",
    "r = 0 # Random seed\n",
    "\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "# Set initial weights\n",
    "params_init = hamiltorch.util.flatten(net).to(device).clone()\n",
    "# Set the Inverse of the Mass matrix\n",
    "inv_mass = torch.ones(params_init.shape) / mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params_init.shape)\n",
    "integrator = hamiltorch.Integrator.EXPLICIT\n",
    "sampler = hamiltorch.Sampler.HMC\n",
    "\n",
    "hamiltorch.set_random_seed(r)\n",
    "params_hmc_f = hamiltorch.sample_model(net, x_data.to(device), y_data.to(device), params_init=params_init,\n",
    "                                       model_loss=model_loss, num_samples=num_samples,\n",
    "                                       burn = burn, inv_mass=inv_mass.to(device),step_size=step_size,\n",
    "                                       num_steps_per_sample=L,tau_out=tau_out, tau_list=tau_list,\n",
    "                                       debug=debug, store_on_GPU=store_on_GPU,\n",
    "                                       sampler = sampler)\n",
    "\n",
    "# At the moment, params_hmc_f is on the CPU so we move to GPU\n",
    "\n",
    "params_hmc_gpu = [ll.to(device) for ll in params_hmc_f[1:]]\n",
    "\n",
    "\n",
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list_hmc, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=params_hmc_gpu,\n",
    "                                                  model_loss=model_loss, tau_out=beta,\n",
    "                                                  tau_list=tau_list)\n",
    "# Let's evaluate the performance over the training data\n",
    "pred_list_tr, log_probs_split_tr = hamiltorch.predict_model(net, x = x_data.to(device), y=y_data.to(device),\n",
    "                                                            samples=params_hmc_gpu, model_loss=model_loss,\n",
    "                                                            tau_out=beta, tau_list=tau_list)\n",
    "ll_full = torch.zeros(pred_list_tr.shape[0])\n",
    "ll_full[0] = - 0.5 * tau_out * ((pred_list_tr[0].cpu() - y_data) ** 2).sum(0)\n",
    "for i in range(pred_list_tr.shape[0]):\n",
    "    ll_full[i] = - 0.5 * tau_out * ((pred_list_tr[:i].mean(0).cpu() - y_data) ** 2).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3281da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_full = torch.zeros(pred_list_tr.shape[0])\n",
    "ll_full[0] = - 0.5 * beta * ((pred_list_tr[0].cpu() - y_data) ** 2).sum(0)\n",
    "for i in range(pred_list_tr.shape[0]):\n",
    "    ll_full[i] = - 0.5 * tau_out * ((pred_list_tr[:i].mean(0).cpu() - y_data) ** 2).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f36c71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots(1,1, figsize = (10,5))\n",
    "ax1.set_title('Training Log-Likelihood')\n",
    "ax1.plot(ll_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83610634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list_hmc, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=params_hmc_gpu,\n",
    "                                                  model_loss='regression', tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e749b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preds(pred_list_hmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f12931",
   "metadata": {},
   "source": [
    "# Draw subset of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "subset = random.sample(params_hmc_gpu, 1000)\n",
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list_hmc_subsample, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=subset,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_hmc_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_samples = torch.empty([0])\n",
    "for s in subset:\n",
    "    emp_samples = torch.cat([emp_samples, s[None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece02157",
   "metadata": {},
   "source": [
    "# Let's try the KDE coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal kde_var\n",
    "from models.BNNs.BNN_KDE import BNN_KDE\n",
    "\n",
    "bnn_kde = BNN_KDE(emp_samples, alpha=alpha, beta=beta, kl_beta=ELBO_BETA)\n",
    "\n",
    "num_epochs = 5000\n",
    "num_parallel_samples = 128\n",
    "optimiser = torch.optim.Adamax(bnn_kde.parameters(), lr=5e-2)\n",
    "for i in range(num_epochs):\n",
    "    optimiser.zero_grad()\n",
    "    loss = -bnn_kde.elbo(x_data, y_data, num_parallel_samples)\n",
    "    if i % 1000 == 0:\n",
    "        print(f'The loss is: {loss.item():.5f}, val of var is: {torch.exp(bnn_kde.log_kde_std)[0].item() ** 2:.5f}')\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104be273",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_var = torch.exp(bnn_kde.log_kde_std)[0].item() ** 2\n",
    "#n_samples = 100\n",
    "KDE_weights = dist.Categorical(torch.ones(emp_samples.shape[0]))\n",
    "initial_seed = 0\n",
    "torch.manual_seed(initial_seed)\n",
    "KDE_components = dist.MultivariateNormal(loc=emp_samples,\n",
    "                                         covariance_matrix=KDE_var * torch.eye(emp_samples.shape[-1]))\n",
    "\n",
    "KDE_target = dist.MixtureSameFamily(KDE_weights, KDE_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c26584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.utils import kl_estimate_with_mc\n",
    "prior = D.MultivariateNormal(loc=torch.zeros_like(emp_samples[0]), covariance_matrix = 1./alpha * torch.eye(emp_samples.shape[-1]))\n",
    "kl_q_p = kl_estimate_with_mc(KDE_target, prior)\n",
    "print(f\"{kl_q_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e8802",
   "metadata": {},
   "source": [
    "# Lets optimise the variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from models.BNNs.BNN_for_HMC import BNN_for_HMC\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c68221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = BNN_for_HMC(alpha=alpha, beta=beta, num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6388fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# pkl.dump(emp_samples, open(\"PickledStuff/emp_samples.pkl\", \"wb\"))\n",
    "# pkl.dump(x_data, open(\"PickledStuff/x_data.pkl\", \"wb\"))\n",
    "# pkl.dump(y_data, open(\"PickledStuff/y_data.pkl\", \"wb\"))\n",
    "# pkl.dump(ys, open(\"PickledStuff/ys.pkl\", \"wb\"))\n",
    "# pkl.dump(xs, open(\"PickledStuff/xs.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22beb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dist = dist.Empirical(emp_samples, log_weights=torch.ones(emp_samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = emp_dist.mean\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1./alpha\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791ab12",
   "metadata": {},
   "source": [
    "# Let's use the EMP scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_emp_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = ys.to(device), samples=compressed_weights_emp_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_low_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711edb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_med_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbcfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_med_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_high_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f83bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_high_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d449a",
   "metadata": {},
   "source": [
    "# Let's try the KDE coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db352ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39075d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_exact = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    torch.manual_seed(i)\n",
    "    compressed_weights_kde_exact.append(KDE_target.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_exact, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_exact,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_low_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75963162",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_med_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f8fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_med_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_high_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46777f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_high_eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863a2ae",
   "metadata": {},
   "source": [
    "# Let's Compute some Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empirical_predictive(weights, x_input, y_output):\n",
    "    pred_list, _ = hamiltorch.predict_model(net, x = x_input.flatten().to(device),\n",
    "                                                  y = y_output.flatten().to(device), samples=weights,\n",
    "                                                  model_loss='regression', tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "    \n",
    "    # need to make gmm at each sample\n",
    "    return pred_list\n",
    "\n",
    "def make_empirical_gmm(preds):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Normal(loc=preds.squeeze().permute(1, 0), scale=beta ** -0.5)\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "    return gmm\n",
    "\n",
    "def compute_gmm_lp(weights, x, y):\n",
    "    preds = make_empirical_predictive(weights, x, y)\n",
    "    \n",
    "    gmm = make_empirical_gmm(preds)\n",
    "    \n",
    "    return gmm.log_prob(y.squeeze()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(params_hmc_gpu, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e191965",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_exact, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb47325",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43589692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(subset, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/HMC_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_exact, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
