{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fda7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cf83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037cc729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kristophermiltiadou/Documents/UniWork/Cambridge/Thesis/CODE/new_iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1984273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device  =torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31634b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "370e89d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a664e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "x_ = data['data']\n",
    "y_ = data['target']\n",
    "N_tr = int(x_.shape[0] * 0.5)\n",
    "N_val = x_.shape[0] - N_tr\n",
    "a = np.arange(x_.shape[0])\n",
    "train_index = np.random.choice(a, size = N_tr, replace = False)\n",
    "val_index = np.delete(a, train_index, axis=0)\n",
    "x_train = x_[train_index]\n",
    "y_train = y_[train_index].reshape(-1, 1)\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train-x_m)/ x_s\n",
    "x_val = x_[val_index][:]\n",
    "y_val = y_[val_index][:].reshape(-1, 1)\n",
    "x_val = (x_val-x_m)/ x_s\n",
    "D_in = x_train.shape[1]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "plt.scatter(x_train.numpy()[:,0],y_train.numpy())\n",
    "    \n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da46a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device=torch.device('cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "num_nodes = 50\n",
    "alpha = 1.\n",
    "beta = 100.\n",
    "ELBO_BETA = 1.\n",
    "net = Net(num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e062db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1e-3\n",
    "\n",
    "num_samples = 10000\n",
    "L = 5\n",
    "burn = 5000\n",
    "store_on_GPU = False\n",
    "debug = False\n",
    "model_loss = 'regression'\n",
    "mass = 1.0\n",
    "\n",
    "# Effect of tau\n",
    "# Set to tau = 1000. to see a function that is less bendy (weights restricted to small bends)\n",
    "# Set to tau = 1. for more flexible\n",
    "\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = beta * 1/ELBO_BETA # Output Precision\n",
    "r = 1000 # Random seed\n",
    "\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "# Set initial weights\n",
    "params_init = hamiltorch.util.flatten(net).to(device).clone()\n",
    "# Set the Inverse of the Mass matrix\n",
    "inv_mass = torch.ones(params_init.shape) / mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a29e3379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3301])\n",
      "Sampling (Sampler.HMC; Integrator.EXPLICIT)\n",
      "Time spent  | Time remain.| Progress             | Samples     | Samples/sec\n",
      "0d:00:00:38 | 0d:00:01:34 | ######-------------- |  2897/10000 | 75.42       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-bfef46efcdba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhamiltorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m params_hmc_f = hamiltorch.sample_model(net, x_train.to(device), y_train.to(device), params_init=params_init,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                        \u001b[0mmodel_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                        \u001b[0mburn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mburn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minv_mass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Torch/lib/python3.8/site-packages/hamiltorch/samplers.py\u001b[0m in \u001b[0;36msample_model\u001b[0;34m(model, x, y, params_init, model_loss, num_samples, num_steps_per_sample, step_size, burn, inv_mass, jitter, normalizing_const, softabs_const, explicit_binding_const, fixed_point_threshold, fixed_point_max_iterations, jitter_max_tries, sampler, integrator, metric, debug, tau_out, tau_list, store_on_GPU, desired_accept_rate)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps_per_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps_per_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mburn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mburn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minv_mass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizing_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalizing_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftabs_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoftabs_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_binding_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_binding_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_point_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_point_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_point_max_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_point_max_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter_max_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter_max_tries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintegrator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintegrator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_accept_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesired_accept_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_on_GPU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore_on_GPU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_split_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multi_class_linear_output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps_per_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mburn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizing_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftabs_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_binding_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_point_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_point_max_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter_max_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHMC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintegrator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIntegrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPLITTING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHESSIAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtau_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore_on_GPU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired_accept_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Torch/lib/python3.8/site-packages/hamiltorch/samplers.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(log_prob_func, params_init, num_samples, num_steps_per_sample, step_size, burn, jitter, inv_mass, normalizing_const, softabs_const, explicit_binding_const, fixed_point_threshold, fixed_point_max_iterations, jitter_max_tries, sampler, integrator, metric, debug, desired_accept_rate, store_on_GPU)\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleapfrog_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleapfrog_momenta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mnew_ham\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhamiltonian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftabs_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoftabs_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_binding_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_binding_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizing_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalizing_const\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintegrator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintegrator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minv_mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Torch/lib/python3.8/site-packages/hamiltorch/samplers.py\u001b[0m in \u001b[0;36mhamiltonian\u001b[0;34m(params, momentum, log_prob_func, jitter, normalizing_const, softabs_const, explicit_binding_const, inv_mass, ham_func, sampler, integrator, metric)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHMC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_nan_or_inf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Torch/lib/python3.8/site-packages/hamiltorch/samplers.py\u001b[0m in \u001b[0;36mlog_prob_func\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_flattened_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_shape_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0;31m# weights.data = params[i_prev:index+i_prev].reshape(shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_prev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi_prev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m             \u001b[0ml_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml_prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0mi_prev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(params_init.shape)\n",
    "integrator = hamiltorch.Integrator.EXPLICIT\n",
    "sampler = hamiltorch.Sampler.HMC_NUTS\n",
    "\n",
    "hamiltorch.set_random_seed(r)\n",
    "params_hmc_f = hamiltorch.sample_model(net, x_train.to(device), y_train.to(device), params_init=params_init,\n",
    "                                       model_loss=model_loss, num_samples=num_samples,\n",
    "                                       burn = burn, inv_mass=inv_mass.to(device),step_size=step_size,\n",
    "                                       num_steps_per_sample=L,tau_out=tau_out, tau_list=tau_list,\n",
    "                                       debug=debug, store_on_GPU=store_on_GPU,\n",
    "                                       sampler = sampler, integrator=integrator)\n",
    "\n",
    "# At the moment, params_hmc_f is on the CPU so we move to GPU\n",
    "\n",
    "params_hmc_gpu = [ll.to(device) for ll in params_hmc_f[1:]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8e749b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_hmc, log_probs_f = hamiltorch.predict_model(net, x = x_train.to(device),\n",
    "                                                  y = y_train.to(device), samples=params_hmc_gpu,\n",
    "                                                  model_loss=model_loss, tau_out=beta,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59327ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb6693fb070>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEDCAYAAAA2k7/eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXQ0lEQVR4nO3de7Bd1X3Y8e9PupJAiIdBEiAkLIGBmhgbwy0BP7ATwHHkBOqOk6ETp4lrh3imSWN3CIONJ2n7h2ecuCVpmrhRwUmc+DE2wY/xUMemdWu7gwkCIyPA2LyRhODKYN5wz+PXP8454lo593nO1tln7+9n5s49+3HOWuucfX533d9ee+3ITCRJ1bds1BWQJB0cBnxJqgkDviTVhAFfkmrCgC9JNWHAl6SaKH3Aj4hPRsTjEbFzgfv/akTcFRF3RsRniq6fJI2LKPs4/Ig4H3gW+FRmvmaefU8BPg/8fGY+GRHrM/Pxg1FPSSq70vfwM/NbwBMz10XEyRHxtYi4NSK+HRH/rLvpt4A/z8wnu8812EtSV+kD/iy2Ab+bmWcDlwN/0V1/KnBqRPy/iPhuRLx9ZDWUpJKZGHUFFisi1gBvAL4QEb3Vq7q/J4BTgLcCG4FvR8RrMvMnB7maklQ6Yxfw6fxX8pPMPLPPtl3AdzOzATwQEffQ+QNwy0GsnySV0tildDLzaTrB/FcAouN13c1fAn6uu34tnRTP/aOopySVTekDfkR8FrgJOC0idkXEe4FfA94bETuAO4FLurv/A/DjiLgL+Cbw+5n541HUW5LKpvTDMiVJw1H6Hr4kaThKfdJ27dq1uXnz5lFXQ5LGxq233rovM9f121bqgL9582a2b98+6mpI0tiIiIdm22ZKR5JqwoAvSTVhwJekmjDgS1JNGPAlqSYM+JJUEwZ8SaqJUo/Dl6S6+ML2R3jkiecBWL1qgve/5eShl2HAl6QRe7HR4vev+z4AEbB2zSoDviRV0XSrDcBH3vFq3vfmkworxxy+JI1Yo9kJ+CuWFxuSDfiSNGLNdmea+onlMc+egzHgS9KINbopnRXL7OFLUqU1W/bwJakWmu1OD3/CHL4kVVuj28NfscweviRV2sspHXv4klRpjf0pnTHo4UfE5RGREbF2lu0PRsQdEXF7RHjPQkmaodfDX1lwD3/gK20jYhNwEfDwPLv+XGbuG7Q8SaqaZndY5sQY5PCvBq4AcgivJUm105taodQ5/Ii4GNidmTvm2TWBr0fErRFx2TyveVlEbI+I7VNTU4NUT5LGQi+ls6LgHP68KZ2IuBE4rs+mq4APA29bQDlvzMw9EbEe+EZE/CAzv9Vvx8zcBmwDmJyc9L8GqQTum3qWPT95YdTVqKw7dj8FwETBV9rOG/Az88J+6yPiDGALsCMiADYCt0XEOZm594DX2NP9/XhEfBE4B+gb8CWVS2Zy8Z99h+emW6OuSuUduXpFoa+/5JO2mXkHsL63HBEPApMHnpiNiMOAZZn5TPfx24D/tNRyJR1crXby3HSLS//5Jt519sZRV6eyjjx0BSccdWihZRQyH35EbACuycytwLHAF7v/BUwAn8nMrxVRrqTh610F+spjDmNy89Ejro0GMbSAn5mbZzzeA2ztPr4feN2wypF0cPUuCir6hKKK55W2kua0/7L/gseIq3gGfElzah6kMeIqnp+gpDk12gdnjLiKZ8CXNKfe/VaLHiOu4vkJSppT7+YcKyYMF+POT1DSnA7WzTlUPAO+pDkdrJtzqHh+gpLm9PJMjvbwx50BX9KcesMyV3jSduz5CUqaU7PdS+nYwx93hcylI2n8tdvJvVPPcv/UswCsMIc/9gz4kvq6/nu7ufwLL9/b6PBDDBfjzk9QUl9PPPcSAH966ZmsO3wVp6xfM+IaaVAGfEl99cbf/8LPHMchK5aPuDYaBpNykvp6+T6rhomq8JOU1Fej1SYClnuFbWUY8CX11Wi37d1XjJ+mpL6arXT+nIox4Evqq9lqO39OxfhpSuqr0U5velIxBnxJfTWabW96UjF+mpL6arbT+XMqxoAvqa9Gy1E6VeOnKamvZsscftUY8CX11Wybw68a59KRxtBLzRYvTLcKLeP56ZY9/IoZSsCPiMuBPwbWZea+PtuPAq4BXgMk8G8y86ZhlC3VTaudvPlj3+TxZ14qvKyf3XJ04WXo4Bk44EfEJuAi4OE5dvtT4GuZ+a6IWAmsHrRcqa5earZ4/JmXuPDVx/LGVx1TaFnnGPArZRg9/KuBK4Av99sYEUcA5wO/CZCZ08D0EMqVaqnR7Mxied7Jx/CeN24ZcW00TgY6IxMRFwO7M3PHHLudBEwBfxUR34uIayLisDle87KI2B4R26empgapnlRJjXb3puLm17VI8wb8iLgxInb2+bkEuAr4g3leYgI4C/hEZr4eeA64cradM3NbZk5m5uS6desW0RSpHnrz1DuCRos1b0onMy/stz4izgC2ADsiAmAjcFtEnJOZe2fsugvYlZk3d5evY46AL2lujZY9fC3NknP4mXkHsL63HBEPApMHjtLJzL0R8UhEnJaZ9wAXAHcttVyp7l4O+PbwtTiFHDERsSEibpix6neBT0fE94EzgY8WUa5UB812N6VjD1+LNLQLrzJz84zHe4CtM5ZvByaHVZZUZ70evjl8LZZHjDRmeidtV07Yw9fiGPClMWMPX0vlESONmUbLHL6WxoAvjZlm21E6WhqPGGnM9HL4BnwtltMjSyWz96kXeWDfc7Nuv3PPUwBMLDOlo8Ux4Esl856/voW7H3163v2OPHTFQaiNqsSAL5XMU89P85ZT1/H+t5w86z5HHrqCTUc7y7gWx4Avlcx0K9lw1KGcd3Kxc92rfjzrI5VMs912YjQVwoAvlUyzlY7AUSE8qqSSmW61vahKhTDgSyXTbLVZ4bQJKoBHlVQirXbSTi+qUjE8qqQS2T8xmikdFcCAL5VI7+YmjtJREQz4Uok0vX2hCuRRJZXI9P6Ujl9NDZ9HlVQi+2fCdGI0FcCAL5WIUx+rSM6lIxXk2u88wM33/3hRz3l+ugU4SkfFMOBLBbnm2/fz/HSL4488ZFHPO3PTUZxxwpEF1Up1ZsCXCtJotXnHa4/no+88Y9RVkQBz+FJhGq305KtKxYAvFaTZanvyVaXi0SgVpNFKx9OrVIZyNEbE5RGREbG2z7bTIuL2GT9PR8QHhlGuVFaZSaPdZqWjbVQiA5+0jYhNwEXAw/22Z+Y9wJndfZcDu4EvDlquVGatdpLpFbMql2EcjVcDVwC5gH0vAO7LzIeGUK5UWr1J0BxPrzIZKOBHxMXA7szcscCnXAp8dpAypXHQmxNnpT18lci8KZ2IuBE4rs+mq4APA29bSEERsRK4GPjQPPtdBlwGcOKJJy7kpaXS6U2RMOGwTJXIvAE/My/stz4izgC2ADsiAmAjcFtEnJOZe/s85ReB2zLzsXnK2wZsA5icnFxImkgqnf3THE/Yw1d5LPmkbWbeAazvLUfEg8BkZu6b5Sn/CtM5qoleSsd706pMCjkaI2JDRNwwY3k1nZE81xdRnlQ2+1M6nrRViQxtLp3M3Dzj8R5g64zl54FjhlWWVHbPvNgEnOZY5eLRKBXgG3d1TmMdtXrFiGsivcyALxWgN9rgTa/6JxefSyNjwJcK0GglK5cvozuCTSoFA75UgEarzQpP2KpkDPhSAZqttmPwVToekVIBplvJhGPwVTIekVIBmi2nRlb5GPClAjRabadGVul4REoFaLTTk7YqHQO+VIBG0/vZqnw8IqUCNNtpwFfpeERKBejk8E3pqFwM+FIBOhde+fVSuXhESgVotDxpq/Ix4EsFaNrDVwl5REoF8EpblZFHpFSAZqvNyglTOioXA75UAE/aqow8IqUCNEzpqIQ8IqUCNEzpqIQM+FIBmm17+Cofj0ipAM6lozLyiJQK0Gh7i0OVjwFfKkDnSlu/XioXj0hpyNrtpNVOJ09T6RjwpSFrtNsA9vBVOh6R0pA1WwlgDl+lMzGMF4mIy4E/BtZl5r4+2z8IvA9I4A7gPZn54jDKlkbphekW+5596afWPf1iA7CHr/IZOOBHxCbgIuDhWbafAPw74PTMfCEiPg9cCvz1oGVLo/arf3kTd+x+qu+2w1YOpT8lDc0wjsirgSuAL89TzqER0QBWA3uGUK40cnuffpFzTzqad5296afWr1geXHT6sSOqldTfQAE/Ii4Gdmfmjoj++crM3B0RH6fzH8ALwNcz8+tzvOZlwGUAJ5544iDVkwrXbLU57djDedfZG0ddFWle8yYZI+LGiNjZ5+cS4CrgD+Z5/iuAS4AtwAbgsIh492z7Z+a2zJzMzMl169YtrjXSQdZoJRPm6jUm5u3hZ+aF/dZHxBl0gnivd78RuC0izsnMvTN2vRB4IDOnus+7HngD8HcD1l0auWmnQdYYWXJKJzPvANb3liPiQWCyzyidh4FzI2I1nZTOBcD2pZYrlUnnVoYOv9R4KKRrEhEbIuIGgMy8GbgOuI3OkMxlwLYiypUOplY7aafDLzU+hjZuLDM3z3i8B9g6Y/kPgT8cVllSGTRaXlGr8eKRKi3RywHflI7GgwFfWqLG/ikU/BppPHikSkvU6+E7K6bGhQFfWiJz+Bo3HqnSEvVSOisN+BoTzu4kAH742DP88LFnRl2NsbL3qc6Er6Z0NC4M+ALg/X97K/fve27U1RhLa9esGnUVpAUx4AuAZ15qsvWM4/jghaeOuipj5ZAVy9l09OpRV0NaEAO+gM4JyLVrVnHKsYePuiqSCuLZJgGd2/I52kSqNr/hApz1UaoDv+EiM2k466NUeQZ80Won6ayPUuX5DZdzwkg14TdcNNrO+ijVgQFfNJrOCSPVgd9wmdKRasJvuLyRh1QTBnztD/grJzwcpCpzaoUay0w+8qWd7Nz9FAATywz4UpX5Da+xRiv59M0P8+Pnpjn/1HWceeJRo66SpALZw6+xZnc45q+f+0p++y0nj7g2kopmD7/GGk1H50h14je9xqYdnSPVigG/xrwJt1QvftNrzIAv1ctQvukRcXlEZESsnWX770XEzoi4MyI+MIwyNbj9Ad/x91ItDPxNj4hNwEXAw7Nsfw3wW8A5wOuAX4qIUwYtV4PrTamw0hy+VAvD6NpdDVwB5CzbXw18NzOfz8wm8H+Bdw6hXA3IlI5ULwN90yPiYmB3Zu6YY7edwPkRcUxErAa2ApvmeM3LImJ7RGyfmpoapHqahwFfqpd5L7yKiBuB4/psugr4MPC2uZ6fmXdHxMeAbwDPAjuA5hz7bwO2AUxOTs72X4OGYLo7Dn/ClI5UC/MG/My8sN/6iDgD2ALsiAiAjcBtEXFOZu494DWuBa7tPu+jwK4B660h2D9pmj18qRaWPLVCZt4BrO8tR8SDwGRm7jtw34hYn5mPR8SJwL8EzltquZpbs9Xm/9wzxfON1rz73rmnM2maKR2pHgqZSyciNgDXZObW7qq/j4hjgAbwbzPzySLKFfzjg0/wvk9tX/D+EXDMmpUF1khSWQwt4Gfm5hmP99A5OdtbfvOwytHcnn2xc3rkv7/7LF61/vB59z/8kAmOPeKQoqslqQScLbNiemPrt6xdw6vWrxlxbSSVicnbivF2hZJmY8CvmGnH1kuahVGhYpq96RKcH0fSAYwKFePVs5JmY1SomF7A9+pZSQcy4FfMtFfPSpqFUaFivE+tpNkYFSqm0WqzLGD5MlM6kn6aAb9iGu22vXtJfRkZKqbRTPP3kvpyaoUFareTX/nLm3hg33OjrsqcnnupyWGr/Fgl/VNGhgV6qdnm1oee5KwTj+JnNhw56urM6bUby10/SaNhwF+g3nDHd7x2A+9905YR10aSFs9k7wK9fHcoR79IGk8G/AXqzVHjCBhJ48rotUAvT1ngWyZpPBm9FmjaeeYljTkD/gI1nKNG0pgzei2Qc9RIGndGrwXan9LxxiKSxpTRa4G8V6ykcWfAXyBz+JLGndFrgbx1oKRxV/upFX702DN85Es79+foZ/PU8w3AWwdKGl+1D/jbH3qSmx94gp/dcjQr5zghu2bVBKdvOIKT1605iLWTpOGpfcDvpWr+4tfO4pg1q0ZcG0kqzkAJ6Yj4DxGxOyJu7/5snWW/t0fEPRFxb0RcOUiZwzbddLilpHoYRg//6sz8+GwbI2I58OfARcAu4JaI+Epm3jWEsgfW6E6K5ugbSVV3MKLcOcC9mXl/Zk4DnwMuOQjlLoijbyTVxTCi3O9ExPcj4pMR8Yo+208AHpmxvKu7rq+IuCwitkfE9qmpqSFUb26NVptlAcuXOfpGUrXNG/Aj4saI2Nnn5xLgE8DJwJnAo8B/7vcSfdblbOVl5rbMnMzMyXXr1i2sFQOYbrXt3UuqhXlz+Jl54UJeKCL+B/DVPpt2AZtmLG8E9iyodgdBo5nm7yXVwqCjdI6fsfhOYGef3W4BTomILRGxErgU+Mog5Q5To9V2hI6kWhh0lM4fRcSZdFI0DwK/DRARG4BrMnNrZjYj4neAfwCWA5/MzDsHLHdoGq22E6JJqoWBAn5m/vos6/cAW2cs3wDcMEhZRTGHL6kuah/pGi1z+JLqoZJTK/zyn32HFxutBe376FMvsuGoQwqukSSNXiUD/snrDpt39sueU45dw1tPXV9wjSRp9CoZ8P/k0tePugqSVDomryWpJgz4klQTBnxJqgkDviTVhAFfkmrCgC9JNWHAl6SaMOBLUk1E5qz3Ihm5iJgCHlri09cC+4ZYnXFgm+vBNlffIO19ZWb2vXtUqQP+ICJie2ZOjroeB5NtrgfbXH1FtdeUjiTVhAFfkmqiygF/26grMAK2uR5sc/UV0t7K5vAlST+tyj18SdIMBnxJqonKBfyIeHtE3BMR90bElaOuz7BExKaI+GZE3B0Rd0bE73XXHx0R34iIH3V/v2LGcz7UfR/uiYhfGF3tBxMRyyPiexHx1e5ypdscEUdFxHUR8YPu531eDdr8we5xvTMiPhsRh1StzRHxyYh4PCJ2zli36DZGxNkRcUd323+NiFhwJTKzMj/AcuA+4CRgJbADOH3U9RpS244Hzuo+Phz4IXA68EfAld31VwIf6z4+vdv+VcCW7vuyfNTtWGLb/z3wGeCr3eVKtxn4G+B93ccrgaOq3GbgBOAB4NDu8ueB36xam4HzgbOAnTPWLbqNwD8C5wEB/E/gFxdah6r18M8B7s3M+zNzGvgccMmI6zQUmfloZt7WffwMcDedL8oldAIE3d//ovv4EuBzmflSZj4A3Evn/RkrEbEReAdwzYzVlW1zRBxBJzBcC5CZ05n5Eyrc5q4J4NCImABWA3uoWJsz81vAEwesXlQbI+J44IjMvCk70f9TM54zr6oF/BOAR2Ys7+quq5SI2Ay8HrgZODYzH4XOHwWgd0f2qrwXfwJcAcy8K32V23wSMAX8VTeNdU1EHEaF25yZu4GPAw8DjwJPZebXqXCbZ1hsG0/oPj5w/YJULeD3y2VVatxpRKwB/h74QGY+PdeufdaN1XsREb8EPJ6Zty70KX3WjVWb6fR0zwI+kZmvB56j86/+bMa+zd289SV0UhcbgMMi4t1zPaXPurFq8wLM1saB2l61gL8L2DRjeSOdfw0rISJW0An2n87M67urH+v+m0f39+Pd9VV4L94IXBwRD9JJz/18RPwd1W7zLmBXZt7cXb6Ozh+AKrf5QuCBzJzKzAZwPfAGqt3mnsW2cVf38YHrF6RqAf8W4JSI2BIRK4FLga+MuE5D0T0Tfy1wd2b+lxmbvgL8RvfxbwBfnrH+0ohYFRFbgFPonOwZG5n5oczcmJmb6XyW/zsz302127wXeCQiTuuuugC4iwq3mU4q59yIWN09zi+gc46qym3uWVQbu2mfZyLi3O579a9nPGd+oz5zXcCZ8K10RrDcB1w16voMsV1vovOv2/eB27s/W4FjgP8F/Kj7++gZz7mq+z7cwyLO5JfxB3grL4/SqXSbgTOB7d3P+kvAK2rQ5v8I/ADYCfwtndEplWoz8Fk65ygadHrq711KG4HJ7vt0H/Df6M6YsJAfp1aQpJqoWkpHkjQLA74k1YQBX5JqwoAvSTVhwJekmjDgS1JNGPAlqSb+P0Rsd48jb0ppAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log_probs_f[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cca83c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list_hmc, log_probs_f = hamiltorch.predict_model(net, x = x_val.to(device),\n",
    "                                                  y = y_val.to(device), samples=params_hmc_gpu,\n",
    "                                                  model_loss=model_loss, tau_out=beta,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d87fbfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[437.2684],\n",
       "        [403.0728],\n",
       "        [386.7837],\n",
       "        [390.5259],\n",
       "        [459.4637],\n",
       "        [457.2155],\n",
       "        [451.2189],\n",
       "        [456.9491],\n",
       "        [454.9436],\n",
       "        [440.9226],\n",
       "        [443.6459],\n",
       "        [441.3521],\n",
       "        [444.7716],\n",
       "        [386.5075],\n",
       "        [443.2302],\n",
       "        [445.2063],\n",
       "        [407.1714],\n",
       "        [442.5841],\n",
       "        [436.0824],\n",
       "        [444.3894],\n",
       "        [429.1201],\n",
       "        [415.6090],\n",
       "        [405.1211],\n",
       "        [403.8068],\n",
       "        [375.9648],\n",
       "        [389.9141],\n",
       "        [392.9860],\n",
       "        [406.1201],\n",
       "        [412.2848],\n",
       "        [394.2310],\n",
       "        [582.8681],\n",
       "        [451.4934],\n",
       "        [418.1205],\n",
       "        [426.4171],\n",
       "        [431.5228],\n",
       "        [461.5383],\n",
       "        [466.8603],\n",
       "        [465.0750],\n",
       "        [422.2428],\n",
       "        [426.7513],\n",
       "        [506.0716],\n",
       "        [505.6515],\n",
       "        [429.4015],\n",
       "        [404.2358],\n",
       "        [403.6180],\n",
       "        [405.9090],\n",
       "        [428.0786],\n",
       "        [419.1961],\n",
       "        [422.3844],\n",
       "        [428.0546],\n",
       "        [424.0219],\n",
       "        [505.1155],\n",
       "        [507.3335],\n",
       "        [510.5533],\n",
       "        [510.4369],\n",
       "        [503.9958],\n",
       "        [507.4548],\n",
       "        [541.4985],\n",
       "        [377.4043],\n",
       "        [382.2567],\n",
       "        [383.4839],\n",
       "        [370.1461],\n",
       "        [555.3356],\n",
       "        [555.0039],\n",
       "        [554.2329],\n",
       "        [505.5483],\n",
       "        [554.1392],\n",
       "        [552.1147],\n",
       "        [559.1161],\n",
       "        [532.2231],\n",
       "        [532.0343],\n",
       "        [448.2639],\n",
       "        [446.7204],\n",
       "        [528.9070],\n",
       "        [512.2053],\n",
       "        [509.6603],\n",
       "        [503.4758],\n",
       "        [424.7117],\n",
       "        [427.1806],\n",
       "        [509.4011],\n",
       "        [513.4409],\n",
       "        [501.8200],\n",
       "        [514.7117],\n",
       "        [521.7023],\n",
       "        [500.0289],\n",
       "        [485.9942],\n",
       "        [507.2866],\n",
       "        [445.0454],\n",
       "        [436.2835],\n",
       "        [425.6842],\n",
       "        [430.9030],\n",
       "        [385.5986],\n",
       "        [383.3392],\n",
       "        [513.7133],\n",
       "        [506.8280],\n",
       "        [509.0555],\n",
       "        [508.2213],\n",
       "        [405.5806],\n",
       "        [398.5718],\n",
       "        [408.6761],\n",
       "        [519.8371],\n",
       "        [514.8579],\n",
       "        [478.3432],\n",
       "        [393.0214],\n",
       "        [415.6909],\n",
       "        [439.1679],\n",
       "        [434.1629],\n",
       "        [421.2785],\n",
       "        [411.5665],\n",
       "        [390.0310],\n",
       "        [432.6344],\n",
       "        [435.1406],\n",
       "        [453.3198],\n",
       "        [442.4266],\n",
       "        [436.6255],\n",
       "        [423.0964],\n",
       "        [437.5613],\n",
       "        [437.0522],\n",
       "        [426.9304],\n",
       "        [422.0790],\n",
       "        [430.6665],\n",
       "        [438.3261],\n",
       "        [443.0860],\n",
       "        [428.5799],\n",
       "        [455.9226],\n",
       "        [449.5676],\n",
       "        [438.6338],\n",
       "        [400.3462],\n",
       "        [422.6320],\n",
       "        [428.0600],\n",
       "        [423.0858],\n",
       "        [422.5779],\n",
       "        [422.2227],\n",
       "        [413.0692],\n",
       "        [384.2665],\n",
       "        [404.0639],\n",
       "        [400.1403],\n",
       "        [404.3766],\n",
       "        [384.4829],\n",
       "        [374.7478],\n",
       "        [427.9472],\n",
       "        [370.1186],\n",
       "        [432.4614],\n",
       "        [404.3515],\n",
       "        [404.3793],\n",
       "        [403.8247],\n",
       "        [467.6799],\n",
       "        [459.3694],\n",
       "        [447.3816],\n",
       "        [387.9701],\n",
       "        [398.4905],\n",
       "        [398.0228],\n",
       "        [446.4695],\n",
       "        [440.4749],\n",
       "        [449.4689],\n",
       "        [446.0380],\n",
       "        [428.8040],\n",
       "        [428.0704],\n",
       "        [432.0231],\n",
       "        [421.6231],\n",
       "        [522.5330],\n",
       "        [436.0029],\n",
       "        [417.9410],\n",
       "        [383.8210],\n",
       "        [383.8238],\n",
       "        [387.5581],\n",
       "        [394.0067],\n",
       "        [395.1256],\n",
       "        [496.9893],\n",
       "        [485.0986],\n",
       "        [466.1574],\n",
       "        [477.3535],\n",
       "        [422.5772],\n",
       "        [456.1591],\n",
       "        [462.3224],\n",
       "        [515.0816],\n",
       "        [451.9608],\n",
       "        [754.7406],\n",
       "        [757.2271],\n",
       "        [757.3027],\n",
       "        [750.7644],\n",
       "        [743.8350],\n",
       "        [742.4000],\n",
       "        [732.6121],\n",
       "        [752.4359],\n",
       "        [758.2883],\n",
       "        [765.3363],\n",
       "        [763.6033],\n",
       "        [750.9881],\n",
       "        [765.0760],\n",
       "        [763.5505],\n",
       "        [773.1473],\n",
       "        [763.6365],\n",
       "        [726.5331],\n",
       "        [766.5052],\n",
       "        [756.3573],\n",
       "        [761.0010],\n",
       "        [752.2496],\n",
       "        [763.6498],\n",
       "        [768.7461],\n",
       "        [755.5559],\n",
       "        [767.8546],\n",
       "        [734.8410],\n",
       "        [704.4614],\n",
       "        [678.4708],\n",
       "        [680.1982],\n",
       "        [697.0436],\n",
       "        [674.1770],\n",
       "        [676.2878],\n",
       "        [736.0699],\n",
       "        [669.3566],\n",
       "        [673.6490],\n",
       "        [676.2894],\n",
       "        [684.0925],\n",
       "        [682.8776],\n",
       "        [690.2317],\n",
       "        [675.5991],\n",
       "        [674.7517],\n",
       "        [762.3933],\n",
       "        [758.4845],\n",
       "        [678.4531],\n",
       "        [734.6161],\n",
       "        [758.9789],\n",
       "        [730.6096],\n",
       "        [754.4053],\n",
       "        [759.0358],\n",
       "        [714.4680],\n",
       "        [757.3057],\n",
       "        [758.6553],\n",
       "        [758.2062],\n",
       "        [755.4564],\n",
       "        [670.9329],\n",
       "        [748.0034],\n",
       "        [754.8857],\n",
       "        [758.6492],\n",
       "        [746.1831],\n",
       "        [730.1588],\n",
       "        [760.7062],\n",
       "        [755.9551],\n",
       "        [755.7457],\n",
       "        [740.8549],\n",
       "        [748.6815],\n",
       "        [796.6877],\n",
       "        [772.8687],\n",
       "        [795.9069],\n",
       "        [795.0120],\n",
       "        [499.8771],\n",
       "        [510.3135],\n",
       "        [508.9018],\n",
       "        [510.8068],\n",
       "        [424.0760],\n",
       "        [429.4150],\n",
       "        [430.5294]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_hmc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f12931",
   "metadata": {},
   "source": [
    "# Draw subset of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "375cbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "subset = random.sample(params_hmc_gpu[-5000:], 1000)\n",
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list_hmc_subsample, log_probs_f = hamiltorch.predict_model(net, x = x_val.to(device),\n",
    "                                                  y = x_val.to(device), samples=subset,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2a74db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_samples = torch.empty([0])\n",
    "for s in subset:\n",
    "    emp_samples = torch.cat([emp_samples, s[None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "02205e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py:81: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-407.8339)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = D.MultivariateNormal(loc=torch.zeros_like(emp_samples[0]), covariance_matrix = 1./alpha * torch.eye(emp_samples.shape[-1]))\n",
    "prior.log_prob(emp_samples).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece02157",
   "metadata": {},
   "source": [
    "###### Let's try the KDE coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f603ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f738fdea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chosen_emp_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-bd0109c06681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbnn_kde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The loss is: {loss.item():.5f}, val of var is: {torch.exp(bnn_kde.log_kde_std)[0].item() ** 2:.5f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/models/BNNs/BNN_KDE.py\u001b[0m in \u001b[0;36melbo\u001b[0;34m(self, x, y, n_samples)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# first sample weights from KDE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mweight_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mweight_prior_lp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_prior_lp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/models/BNNs/BNN_KDE.py\u001b[0m in \u001b[0;36msample_from_kde\u001b[0;34m(self, n_samples)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mchosen_stds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkde_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchosen_emp_samples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchosen_stds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chosen_emp_samples' is not defined"
     ]
    }
   ],
   "source": [
    "# find optimal kde_var\n",
    "from models.BNNs.BNN_KDE import BNN_KDE\n",
    "\n",
    "bnn_kde = BNN_KDE(emp_samples, alpha=alpha, beta=beta, kl_beta=ELBO_BETA)\n",
    "\n",
    "num_epochs = 5000\n",
    "num_parallel_samples = 128\n",
    "optimiser = torch.optim.Adamax(bnn_kde.parameters(), lr=5e-2)\n",
    "for i in range(num_epochs):\n",
    "    optimiser.zero_grad()\n",
    "    loss = -bnn_kde.elbo(x_train, y_train, num_parallel_samples)\n",
    "    if i % 1000 == 0:\n",
    "        print(f'The loss is: {loss.item():.5f}, val of var is: {torch.exp(bnn_kde.log_kde_std)[0].item() ** 2:.5f}')\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104be273",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_var = torch.exp(bnn_kde.log_kde_std)[0].item() ** 2\n",
    "#n_samples = 100\n",
    "KDE_weights = dist.Categorical(torch.ones(emp_samples.shape[0]))\n",
    "initial_seed = 0\n",
    "torch.manual_seed(initial_seed)\n",
    "KDE_components = dist.MultivariateNormal(loc=emp_samples,\n",
    "                                         covariance_matrix=KDE_var * torch.eye(emp_samples.shape[-1]))\n",
    "\n",
    "KDE_target = dist.MixtureSameFamily(KDE_weights, KDE_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c26584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.utils import kl_estimate_with_mc\n",
    "prior = D.MultivariateNormal(loc=torch.zeros_like(emp_samples[0]), covariance_matrix = 1./alpha * torch.eye(emp_samples.shape[-1]))\n",
    "kl_q_p = kl_estimate_with_mc(KDE_target, prior)\n",
    "print(f\"{kl_q_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e8802",
   "metadata": {},
   "source": [
    "# Lets optimise the variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from models.BNNs.BNN_for_HMC import BNN_for_HMC\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c68221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = BNN_for_HMC(alpha=alpha, beta=beta, num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6388fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# pkl.dump(emp_samples, open(\"PickledStuff/emp_samples.pkl\", \"wb\"))\n",
    "# pkl.dump(x_data, open(\"PickledStuff/x_data.pkl\", \"wb\"))\n",
    "# pkl.dump(y_data, open(\"PickledStuff/y_data.pkl\", \"wb\"))\n",
    "# pkl.dump(ys, open(\"PickledStuff/ys.pkl\", \"wb\"))\n",
    "# pkl.dump(xs, open(\"PickledStuff/xs.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22beb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dist = dist.Empirical(emp_samples, log_weights=torch.ones(emp_samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = emp_dist.mean\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1./alpha\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791ab12",
   "metadata": {},
   "source": [
    "# Let's use the EMP scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_emp_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = ys.to(device), samples=compressed_weights_emp_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_low_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711edb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_med_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_med_eps.append(w[0])\n",
    "\n",
    "pred_list_emp_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_emp_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_med_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_high_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_high_eps.append(w[0])\n",
    "\n",
    "pred_list_emp_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_emp_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_high_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d449a",
   "metadata": {},
   "source": [
    "# Let's try the KDE coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db352ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39075d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_exact = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    torch.manual_seed(i)\n",
    "    compressed_weights_kde_exact.append(KDE_target.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_exact, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_exact,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_low_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75963162",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_med_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f8fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_med_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_high_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46777f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_high_eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863a2ae",
   "metadata": {},
   "source": [
    "# Let's Compute some Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empirical_predictive(weights, x_input, y_output):\n",
    "    pred_list, _ = hamiltorch.predict_model(net, x = x_input.flatten().to(device),\n",
    "                                                  y = y_output.flatten().to(device), samples=weights,\n",
    "                                                  model_loss='regression', tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "    \n",
    "    # need to make gmm at each sample\n",
    "    return pred_list\n",
    "\n",
    "def make_empirical_gmm(preds):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Normal(loc=preds.squeeze().permute(1, 0), scale=beta ** -0.5)\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "    return gmm\n",
    "\n",
    "def compute_gmm_lp(weights, x, y):\n",
    "    preds = make_empirical_predictive(weights, x, y)\n",
    "    \n",
    "    gmm = make_empirical_gmm(preds)\n",
    "    \n",
    "    return gmm.log_prob(y.squeeze()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(params_hmc_gpu, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb397f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(params_hmc_gpu, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e191965",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_exact, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb47325",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43589692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(kl_q_p, open(f'PickledStuff/BNN_STUFF/EMP/hmc_kl_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(subset, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/HMC_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_exact, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f05a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
