{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fda7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cf83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037cc729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1984273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31634b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7307c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltorch.set_random_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370e89d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3304b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BNNs.BNN_KDE_CLASSIFICATION import BNN_KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "397ee4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (fc3): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "num_nodes = 2\n",
    "net = Net(num_nodes=num_nodes)\n",
    "    \n",
    "\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc358935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_categorical_mixture(preds, y):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Categorical(logits=preds.permute(1, 0, 2))\n",
    "    \n",
    "    mixture_of_categorical = D.MixtureSameFamily(mix, comp)\n",
    "    mean_preds = torch.argmax(mixture_of_categorical.component_distribution.probs.mean(1), dim=1).float()\n",
    "    accuracy = torch.sum(mean_preds == y) / y.shape[0]\n",
    "    \n",
    "    ll = mixture_of_categorical.log_prob(y).sum()\n",
    "    return accuracy, ll\n",
    "\n",
    "def compute_ensemble_preds(preds, y):\n",
    "    mean_probs = F.softmax(preds, dim=-1).mean(0)\n",
    "    mean_preds = torch.argmax(mean_probs, dim=-1)\n",
    "    ll = D.Categorical(probs=mean_probs).log_prob(y)\n",
    "\n",
    "    accuracy = torch.sum(mean_preds == y) / y.shape[0]\n",
    "    return accuracy, ll.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e492877d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "device = torch.device('cpu')\n",
    "data = load_iris()\n",
    "x_ = data['data']\n",
    "y_ = data['target']\n",
    "N_tr = 50\n",
    "N_val = 150 - N_tr\n",
    "a = np.arange(x_.shape[0])\n",
    "train_index = np.random.choice(a, size = N_tr, replace = False)\n",
    "val_index = np.delete(a, train_index, axis=0)\n",
    "x_train = x_[train_index]\n",
    "y_train = y_[train_index]\n",
    "x_val = x_[val_index][:]\n",
    "y_val = y_[val_index][:]\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train-x_m)/ x_s\n",
    "x_val = (x_val-x_m)/ x_s\n",
    "D_in = x_train.shape[1]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "plt.scatter(x_train.numpy()[:,0],y_train.numpy())\n",
    "    \n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a922e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set hyperparameters for network\n",
    "ELBO_BETA = 1.\n",
    "alpha = 1.\n",
    "tau_list = []\n",
    "tau = alpha * ELBO_BETA\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau)\n",
    "tau_list = torch.tensor(tau_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea2880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25])\n",
      "Sampling (Sampler.HMC; Integrator.EXPLICIT)\n",
      "Time spent  | Time remain.| Progress             | Samples   | Samples/sec\n",
      "Final Adapted Step Size:  0.09906769543886185--- |  500/2500 | 60.82       \n",
      "0d:00:00:12 | 0d:00:00:28 | ######-------------- |  785/2500 | 60.95       \r"
     ]
    }
   ],
   "source": [
    "hamiltorch.set_random_seed(1)\n",
    "params_init = hamiltorch.util.flatten(net).to(device).clone()\n",
    "print(params_init.shape)\n",
    "step_size = 1.0\n",
    "num_samples = 2500\n",
    "burn = 500\n",
    "L = 10\n",
    "tau_out = 1.\n",
    "integrator = hamiltorch.Integrator.EXPLICIT\n",
    "sampler = hamiltorch.Sampler.HMC_NUTS\n",
    "params_hmc = hamiltorch.sample_model(net, x_train, y_train, params_init=params_init, num_samples=num_samples,\n",
    "                               step_size=step_size, num_steps_per_sample=L, tau_out=tau_out, tau_list=tau_list,\n",
    "                                    sampler=sampler, integrator=integrator, burn=burn, desired_accept_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa9117",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_weights = torch.empty([0])\n",
    "for w in params_hmc:\n",
    "    hmc_weights = torch.cat([hmc_weights, w[None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list, log_prob_list = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=hmc_weights, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491535d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_train, log_prob_list = hamiltorch.predict_model(net, x=x_train, y=y_train, samples=hmc_weights, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f12931",
   "metadata": {},
   "source": [
    "# Draw subset of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c982e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(1)\n",
    "perm = torch.randperm(hmc_weights.size(0), generator=g)\n",
    "num_s = 500\n",
    "idx = perm[:num_s]\n",
    "samples = hmc_weights[idx]\n",
    "samples_rest = hmc_weights[perm[num_s:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6bd0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred_list, log_prob_list = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=samples, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6eab51",
   "metadata": {},
   "source": [
    "# Build a KDE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff03cb14",
   "metadata": {},
   "source": [
    "# KDE 100 Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4153fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal kde_var\n",
    "from models.BNNs.BNN_KDE_CLASSIFICATION import BNN_KDE\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_kde = BNN_KDE(alpha=alpha, emp_samples=samples, num_nodes=num_nodes, kl_beta=ELBO_BETA)\n",
    "\n",
    "with torch.no_grad():\n",
    "    rho_linspace = torch.linspace(-5, 5, 1000)\n",
    "    rho_elbos = torch.zeros_like(rho_linspace)\n",
    "    for i, rho in enumerate(rho_linspace):\n",
    "        bnn_kde.log_kde_rho = nn.Parameter(rho)\n",
    "        rho_elbos[i] = bnn_kde.elbo(x_train, y_train, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_rho = rho_linspace[torch.argmax(rho_elbos)].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5ae07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(F.softplus(rho_linspace), rho_elbos.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960251a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnn_kde.log_kde_rho = nn.Parameter(rho_linspace[torch.argmax(rho_elbos)])\n",
    "KDE_target = bnn_kde.kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.utils import kl_estimate_with_mc\n",
    "prior = D.MultivariateNormal(loc=torch.zeros_like(samples[0]), covariance_matrix = 1./alpha * torch.eye(samples.shape[-1]))\n",
    "kl_q_p = kl_estimate_with_mc(KDE_target, prior)\n",
    "print(f\"{kl_q_p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed9ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_compressed_samples = 1000\n",
    "compressed_weights_kde_exact = KDE_target.sample((num_compressed_samples,))\n",
    "\n",
    "pred_list_kde, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_kde_exact, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2af382",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_categorical_mixture(pred_list_kde, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hmc_weights[:, 0], hmc_weights[:, -1], alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(compressed_weights_kde_exact[:, 0], compressed_weights_kde_exact[:, -1], alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_coding_efficiency(kl, epsilon=0.2):\n",
    "    K = (1 + epsilon) * kl\n",
    "    return K + torch.log(K + 1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_expected_coding_efficiency(kl_q_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e8802",
   "metadata": {},
   "source": [
    "# Lets optimise the variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from models.BNNs.BNN_for_HMC_classification import BNN_for_HMC\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c68221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = BNN_for_HMC(alpha=alpha, num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.make_weights_from_sample(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22beb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dist = dist.Empirical(samples, log_weights=torch.ones(samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_train,\n",
    "                     y_train,\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = emp_dist.mean\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1./alpha\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791ab12",
   "metadata": {},
   "source": [
    "# Let's use the EMP scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_low_eps = []\n",
    "pbar = trange(num_compressed_samples)\n",
    "lps = []\n",
    "for i in pbar:\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train,\n",
    "                     y_train,\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    pbar.set_description(f\"Log prob of sample is: {KDE_target.log_prob(w).detach().item()}\")\n",
    "    lps.append(KDE_target.log_prob(w).detach().item())\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82212d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_emp_low_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_emp_low_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_emp_low_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711edb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_med_eps = []\n",
    "pbar = trange(num_compressed_samples)\n",
    "for i in pbar:\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train,\n",
    "                     y_train,\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    pbar.set_description(f\"Log prob of sample is: {KDE_target.log_prob(w).detach().item()}\")\n",
    "    compressed_weights_emp_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e4fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_emp_med_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_emp_med_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_emp_med_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_high_eps = []\n",
    "pbar = trange(num_compressed_samples)\n",
    "for i in pbar:\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train,\n",
    "                     y_train,\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    pbar.set_description(f\"Log prob of sample is: {KDE_target.log_prob(w).detach().item()}\")\n",
    "    compressed_weights_emp_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501df926",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_emp_high_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_emp_high_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_emp_high_eps, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d449a",
   "metadata": {},
   "source": [
    "# Let's try the KDE coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db352ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE_BNN import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39075d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_exact = KDE_target.sample((num_compressed_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train,\n",
    "                         y_data=y_train,\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1651ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_low_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_kde_low_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_kde_low_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75963162",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_med_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train,\n",
    "                         y_data=y_train,\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a76a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_med_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_kde_med_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_kde_med_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_high_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train,\n",
    "                         y_data=y_train,\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46777f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_high_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_kde_high_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_kde_high_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43589692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(kl_q_p, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/EMP/hmc_kl_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(samples, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/EMP/HMC_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(KDE_target, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/EMP/HMC_KDE_target_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_low_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/EMP/emp_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_med_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/EMP/emp_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_high_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/EMP/emp_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_exact, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/KDE/kde_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_low_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/KDE/kde_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_med_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/KDE/kde_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_high_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/KDE/kde_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515f4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
