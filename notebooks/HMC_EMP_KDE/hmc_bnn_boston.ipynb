{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fda7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cf83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037cc729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1984273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device  =torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31634b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "370e89d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a664e7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "x_ = data['data']\n",
    "y_ = data['target']\n",
    "N_tr = int(x_.shape[0] * 0.5)\n",
    "N_val = x_.shape[0] - N_tr\n",
    "a = np.arange(x_.shape[0])\n",
    "train_index = np.random.choice(a, size = N_tr, replace = False)\n",
    "val_index = np.delete(a, train_index, axis=0)\n",
    "x_train = x_[train_index]\n",
    "y_train = y_[train_index].reshape(-1, 1)\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train-x_m)/ x_s\n",
    "x_val = x_[val_index][:]\n",
    "y_val = y_[val_index][:].reshape(-1, 1)\n",
    "x_val = (x_val-x_m)/ x_s\n",
    "D_in = x_train.shape[1]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "plt.scatter(x_train.numpy()[:,0],y_train.numpy())\n",
    "    \n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da46a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device=torch.device('cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "num_nodes = 10\n",
    "alpha = 1.\n",
    "beta = 1.\n",
    "ELBO_BETA = 1.\n",
    "net = Net(num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e062db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 1e-3\n",
    "\n",
    "num_samples = 10000\n",
    "L = 5\n",
    "burn = 5000\n",
    "store_on_GPU = False\n",
    "debug = False\n",
    "model_loss = 'regression'\n",
    "mass = 1.0\n",
    "\n",
    "# Effect of tau\n",
    "# Set to tau = 1000. to see a function that is less bendy (weights restricted to small bends)\n",
    "# Set to tau = 1. for more flexible\n",
    "\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = beta * 1/ELBO_BETA # Output Precision\n",
    "r = 1000 # Random seed\n",
    "\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "# Set initial weights\n",
    "params_init = hamiltorch.util.flatten(net).to(device).clone()\n",
    "# Set the Inverse of the Mass matrix\n",
    "inv_mass = torch.ones(params_init.shape) / mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a29e3379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([261])\n",
      "Sampling (Sampler.HMC; Integrator.EXPLICIT)\n",
      "Time spent  | Time remain.| Progress             | Samples     | Samples/sec\n",
      "Final Adapted Step Size:  0.0006970011745579541- |  4987/10000 | 62.35       \n",
      "0d:00:02:17 | 0d:00:00:00 | #################### | 10000/10000 | 72.93       \n",
      "Acceptance Rate 0.87\n"
     ]
    }
   ],
   "source": [
    "print(params_init.shape)\n",
    "integrator = hamiltorch.Integrator.EXPLICIT\n",
    "sampler = hamiltorch.Sampler.HMC_NUTS\n",
    "\n",
    "hamiltorch.set_random_seed(r)\n",
    "params_hmc_f = hamiltorch.sample_model(net, x_train.to(device), y_train.to(device), params_init=params_init,\n",
    "                                       model_loss=model_loss, num_samples=num_samples,\n",
    "                                       burn = burn, inv_mass=inv_mass.to(device),step_size=step_size,\n",
    "                                       num_steps_per_sample=L,tau_out=tau_out, tau_list=tau_list,\n",
    "                                       debug=debug, store_on_GPU=store_on_GPU,\n",
    "                                       sampler = sampler, integrator=integrator)\n",
    "\n",
    "# At the moment, params_hmc_f is on the CPU so we move to GPU\n",
    "\n",
    "params_hmc_gpu = [ll.to(device) for ll in params_hmc_f[1:]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e749b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_hmc, log_probs_f = hamiltorch.predict_model(net, x = x_train.to(device),\n",
    "                                                  y = y_train.to(device), samples=params_hmc_gpu,\n",
    "                                                  model_loss=model_loss, tau_out=beta,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cca83c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list_hmc, log_probs_f = hamiltorch.predict_model(net, x = x_val.to(device),\n",
    "                                                  y = y_val.to(device), samples=params_hmc_gpu,\n",
    "                                                  model_loss=model_loss, tau_out=beta,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c10e2a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.7539],\n",
       "        [21.6830],\n",
       "        [19.5856],\n",
       "        [21.0248],\n",
       "        [20.6190],\n",
       "        [14.1150],\n",
       "        [14.9942],\n",
       "        [15.8494],\n",
       "        [16.0924],\n",
       "        [17.5997],\n",
       "        [15.1319],\n",
       "        [22.4978],\n",
       "        [22.1789],\n",
       "        [22.6274],\n",
       "        [34.6715],\n",
       "        [32.3832],\n",
       "        [25.3144],\n",
       "        [25.7270],\n",
       "        [22.8500],\n",
       "        [21.3654],\n",
       "        [21.1247],\n",
       "        [20.7827],\n",
       "        [21.3708],\n",
       "        [20.6460],\n",
       "        [27.3648],\n",
       "        [23.5319],\n",
       "        [24.6906],\n",
       "        [30.3764],\n",
       "        [22.0304],\n",
       "        [15.8919],\n",
       "        [21.1368],\n",
       "        [20.8999],\n",
       "        [21.5428],\n",
       "        [23.3133],\n",
       "        [24.6287],\n",
       "        [20.7888],\n",
       "        [19.4224],\n",
       "        [21.1365],\n",
       "        [27.8474],\n",
       "        [24.3434],\n",
       "        [21.2042],\n",
       "        [26.0814],\n",
       "        [23.9923],\n",
       "        [25.1872],\n",
       "        [30.6853],\n",
       "        [31.9951],\n",
       "        [26.6495],\n",
       "        [24.1435],\n",
       "        [24.7598],\n",
       "        [19.5526],\n",
       "        [24.9220],\n",
       "        [43.8717],\n",
       "        [36.6313],\n",
       "        [23.4038],\n",
       "        [14.8849],\n",
       "        [21.3595],\n",
       "        [22.1877],\n",
       "        [20.4558],\n",
       "        [23.1022],\n",
       "        [20.8728],\n",
       "        [18.9292],\n",
       "        [20.7987],\n",
       "        [17.4839],\n",
       "        [19.2928],\n",
       "        [19.8495],\n",
       "        [23.6468],\n",
       "        [21.0128],\n",
       "        [17.7325],\n",
       "        [20.7574],\n",
       "        [23.3057],\n",
       "        [13.4871],\n",
       "        [20.8749],\n",
       "        [13.3168],\n",
       "        [14.9889],\n",
       "        [15.6408],\n",
       "        [18.8522],\n",
       "        [12.7478],\n",
       "        [14.3739],\n",
       "        [11.9067],\n",
       "        [13.0141],\n",
       "        [17.2990],\n",
       "        [14.2399],\n",
       "        [21.8174],\n",
       "        [19.5887],\n",
       "        [27.4393],\n",
       "        [28.1408],\n",
       "        [53.4055],\n",
       "        [20.2847],\n",
       "        [48.4638],\n",
       "        [23.1809],\n",
       "        [22.4376],\n",
       "        [24.2759],\n",
       "        [25.5541],\n",
       "        [30.0625],\n",
       "        [35.0757],\n",
       "        [41.6420],\n",
       "        [35.1524],\n",
       "        [22.6192],\n",
       "        [28.4348],\n",
       "        [25.5761],\n",
       "        [31.3499],\n",
       "        [35.2363],\n",
       "        [31.0953],\n",
       "        [32.3185],\n",
       "        [40.6346],\n",
       "        [19.1839],\n",
       "        [19.4638],\n",
       "        [16.3201],\n",
       "        [19.1440],\n",
       "        [17.9076],\n",
       "        [21.2006],\n",
       "        [24.1513],\n",
       "        [30.3480],\n",
       "        [21.7946],\n",
       "        [25.7957],\n",
       "        [30.5731],\n",
       "        [29.2889],\n",
       "        [26.3747],\n",
       "        [44.1987],\n",
       "        [42.0608],\n",
       "        [29.6620],\n",
       "        [32.7326],\n",
       "        [43.6655],\n",
       "        [22.1102],\n",
       "        [27.3054],\n",
       "        [20.4381],\n",
       "        [24.2689],\n",
       "        [16.6243],\n",
       "        [20.6593],\n",
       "        [43.9762],\n",
       "        [21.1563],\n",
       "        [35.9773],\n",
       "        [30.6755],\n",
       "        [38.8317],\n",
       "        [34.9545],\n",
       "        [32.2293],\n",
       "        [20.4917],\n",
       "        [25.8573],\n",
       "        [31.3591],\n",
       "        [34.6630],\n",
       "        [27.7760],\n",
       "        [35.7452],\n",
       "        [43.7045],\n",
       "        [35.3491],\n",
       "        [39.3847],\n",
       "        [33.9543],\n",
       "        [25.3905],\n",
       "        [22.2560],\n",
       "        [29.4453],\n",
       "        [21.4810],\n",
       "        [29.6306],\n",
       "        [20.3653],\n",
       "        [23.2375],\n",
       "        [31.2674],\n",
       "        [36.1701],\n",
       "        [28.5511],\n",
       "        [37.3256],\n",
       "        [26.0038],\n",
       "        [18.7356],\n",
       "        [18.8710],\n",
       "        [20.7295],\n",
       "        [21.8691],\n",
       "        [16.6053],\n",
       "        [21.0784],\n",
       "        [23.7907],\n",
       "        [20.9900],\n",
       "        [19.7948],\n",
       "        [24.1528],\n",
       "        [24.6435],\n",
       "        [20.3985],\n",
       "        [17.2903],\n",
       "        [23.6343],\n",
       "        [22.2341],\n",
       "        [21.4453],\n",
       "        [20.5696],\n",
       "        [21.2688],\n",
       "        [19.9530],\n",
       "        [22.1447],\n",
       "        [23.2410],\n",
       "        [27.9633],\n",
       "        [27.3049],\n",
       "        [46.9012],\n",
       "        [20.8412],\n",
       "        [34.8431],\n",
       "        [43.9252],\n",
       "        [44.3515],\n",
       "        [26.3209],\n",
       "        [14.8414],\n",
       "        [10.8420],\n",
       "        [ 8.6761],\n",
       "        [ 7.6872],\n",
       "        [ 8.7964],\n",
       "        [ 9.6258],\n",
       "        [12.2368],\n",
       "        [ 9.4976],\n",
       "        [13.7724],\n",
       "        [15.2166],\n",
       "        [15.6768],\n",
       "        [13.7079],\n",
       "        [ 7.0986],\n",
       "        [11.1803],\n",
       "        [21.2406],\n",
       "        [16.0811],\n",
       "        [12.1131],\n",
       "        [11.7620],\n",
       "        [14.8785],\n",
       "        [10.4845],\n",
       "        [ 8.0192],\n",
       "        [ 9.3657],\n",
       "        [10.3837],\n",
       "        [12.6404],\n",
       "        [15.7011],\n",
       "        [10.1754],\n",
       "        [14.0291],\n",
       "        [10.6569],\n",
       "        [15.8955],\n",
       "        [10.1750],\n",
       "        [ 5.7717],\n",
       "        [10.8108],\n",
       "        [14.7107],\n",
       "        [11.1102],\n",
       "        [ 7.6434],\n",
       "        [ 9.7727],\n",
       "        [14.5977],\n",
       "        [12.8041],\n",
       "        [11.6361],\n",
       "        [14.9049],\n",
       "        [11.4009],\n",
       "        [13.4542],\n",
       "        [16.5081],\n",
       "        [18.1539],\n",
       "        [17.5643],\n",
       "        [21.3001],\n",
       "        [16.1185],\n",
       "        [ 9.8354],\n",
       "        [19.3857],\n",
       "        [25.9835],\n",
       "        [29.0050],\n",
       "        [29.5038],\n",
       "        [28.6635],\n",
       "        [25.7761],\n",
       "        [25.8299],\n",
       "        [18.7994],\n",
       "        [26.2428],\n",
       "        [16.2517],\n",
       "        [10.6367],\n",
       "        [21.8836],\n",
       "        [23.8959],\n",
       "        [21.2083],\n",
       "        [20.4257],\n",
       "        [20.7520],\n",
       "        [27.0359],\n",
       "        [20.2966]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_hmc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f12931",
   "metadata": {},
   "source": [
    "# Draw subset of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375cbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "subset = random.sample(params_hmc_gpu[-5000:], 1000)\n",
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list_hmc_subsample, log_probs_f = hamiltorch.predict_model(net, x = x_val.to(device),\n",
    "                                                  y = x_val.to(device), samples=subset,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a74db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_samples = torch.empty([0])\n",
    "for s in subset:\n",
    "    emp_samples = torch.cat([emp_samples, s[None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02205e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py:81: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-262.3856)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = D.MultivariateNormal(loc=torch.zeros_like(emp_samples[0]), covariance_matrix = 1./alpha * torch.eye(emp_samples.shape[-1]))\n",
    "prior.log_prob(emp_samples).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece02157",
   "metadata": {},
   "source": [
    "###### Let's try the KDE coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f603ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f738fdea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chosen_emp_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bd0109c06681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbnn_kde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The loss is: {loss.item():.5f}, val of var is: {torch.exp(bnn_kde.log_kde_std)[0].item() ** 2:.5f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/models/BNNs/BNN_KDE.py\u001b[0m in \u001b[0;36melbo\u001b[0;34m(self, x, y, n_samples)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# first sample weights from KDE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mweight_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mweight_prior_lp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_prior_lp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/models/BNNs/BNN_KDE.py\u001b[0m in \u001b[0;36msample_from_kde\u001b[0;34m(self, n_samples)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mchosen_stds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkde_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchosen_emp_samples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchosen_stds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chosen_emp_samples' is not defined"
     ]
    }
   ],
   "source": [
    "# find optimal kde_var\n",
    "from models.BNNs.BNN_KDE_ import BNN_KDE\n",
    "\n",
    "bnn_kde = BNN_KDE(emp_samples, alpha=alpha, beta=beta, kl_beta=ELBO_BETA)\n",
    "\n",
    "num_epochs = 5000\n",
    "num_parallel_samples = 128\n",
    "optimiser = torch.optim.Adamax(bnn_kde.parameters(), lr=5e-2)\n",
    "for i in range(num_epochs):\n",
    "    optimiser.zero_grad()\n",
    "    loss = -bnn_kde.elbo(x_train, y_train, num_parallel_samples)\n",
    "    if i % 1000 == 0:\n",
    "        print(f'The loss is: {loss.item():.5f}, val of var is: {torch.exp(bnn_kde.log_kde_std)[0].item() ** 2:.5f}')\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104be273",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_var = torch.exp(bnn_kde.log_kde_std)[0].item() ** 2\n",
    "#n_samples = 100\n",
    "KDE_weights = dist.Categorical(torch.ones(emp_samples.shape[0]))\n",
    "initial_seed = 0\n",
    "torch.manual_seed(initial_seed)\n",
    "KDE_components = dist.MultivariateNormal(loc=emp_samples,\n",
    "                                         covariance_matrix=KDE_var * torch.eye(emp_samples.shape[-1]))\n",
    "\n",
    "KDE_target = dist.MixtureSameFamily(KDE_weights, KDE_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c26584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.utils import kl_estimate_with_mc\n",
    "prior = D.MultivariateNormal(loc=torch.zeros_like(emp_samples[0]), covariance_matrix = 1./alpha * torch.eye(emp_samples.shape[-1]))\n",
    "kl_q_p = kl_estimate_with_mc(KDE_target, prior)\n",
    "print(f\"{kl_q_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e8802",
   "metadata": {},
   "source": [
    "# Lets optimise the variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from models.BNNs.BNN_for_HMC import BNN_for_HMC\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c68221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = BNN_for_HMC(alpha=alpha, beta=beta, num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6388fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# pkl.dump(emp_samples, open(\"PickledStuff/emp_samples.pkl\", \"wb\"))\n",
    "# pkl.dump(x_data, open(\"PickledStuff/x_data.pkl\", \"wb\"))\n",
    "# pkl.dump(y_data, open(\"PickledStuff/y_data.pkl\", \"wb\"))\n",
    "# pkl.dump(ys, open(\"PickledStuff/ys.pkl\", \"wb\"))\n",
    "# pkl.dump(xs, open(\"PickledStuff/xs.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22beb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dist = dist.Empirical(emp_samples, log_weights=torch.ones(emp_samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = emp_dist.mean\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1./alpha\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791ab12",
   "metadata": {},
   "source": [
    "# Let's use the EMP scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_emp_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = ys.to(device), samples=compressed_weights_emp_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_low_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711edb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_med_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_med_eps.append(w[0])\n",
    "\n",
    "pred_list_emp_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_emp_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_med_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_high_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_high_eps.append(w[0])\n",
    "\n",
    "pred_list_emp_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_emp_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_high_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d449a",
   "metadata": {},
   "source": [
    "# Let's try the KDE coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db352ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39075d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_exact = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    torch.manual_seed(i)\n",
    "    compressed_weights_kde_exact.append(KDE_target.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_exact, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_exact,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_low_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75963162",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_med_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f8fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_med_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_high_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46777f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_high_eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863a2ae",
   "metadata": {},
   "source": [
    "# Let's Compute some Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empirical_predictive(weights, x_input, y_output):\n",
    "    pred_list, _ = hamiltorch.predict_model(net, x = x_input.flatten().to(device),\n",
    "                                                  y = y_output.flatten().to(device), samples=weights,\n",
    "                                                  model_loss='regression', tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "    \n",
    "    # need to make gmm at each sample\n",
    "    return pred_list\n",
    "\n",
    "def make_empirical_gmm(preds):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Normal(loc=preds.squeeze().permute(1, 0), scale=beta ** -0.5)\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "    return gmm\n",
    "\n",
    "def compute_gmm_lp(weights, x, y):\n",
    "    preds = make_empirical_predictive(weights, x, y)\n",
    "    \n",
    "    gmm = make_empirical_gmm(preds)\n",
    "    \n",
    "    return gmm.log_prob(y.squeeze()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(params_hmc_gpu, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb397f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(params_hmc_gpu, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e191965",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_exact, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb47325",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43589692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(kl_q_p, open(f'PickledStuff/BNN_STUFF/EMP/hmc_kl_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(subset, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/HMC_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_exact, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f05a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
