{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fda7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cf83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037cc729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1984273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device  =torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31634b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "370e89d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a664e7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcFUlEQVR4nO3dbYxcV3kH8P/j8YSMA3RsskntSYxNhOwSXGdhC4aVUOOgGGpIVgYTooDcCuEvtCVRtGSNEEmqVF6xFYQPVSUTaF3FTe3E7sbgtk6UDaqwiGE362Dc2Ap522Ts2kvsDcE7xOPdpx9m7npm9r7NzJ17z733/5Os2b3zdq5n55kzz3nOOaKqICKi+FkQdQOIiKg1DOBERDHFAE5EFFMM4EREMcUATkQUUwvDfLIrr7xSV6xYEeZTEhHF3tjY2G9VtavxeKgBfMWKFRgdHQ3zKYmIYk9EXrU7zhQKEVFMMYATEcUUAzgRUUwxgBMRxRQDOBFRTPmqQhGRVwC8BWAGwEVV7RGRJQB2A1gB4BUAX1DVc0E38I4f/ByHXjxbd2yBABkByrOXjuVzWdx3y/Xo6y74fuzh8SKGDp7AyakSluVz6N+wCgDmHWvmMYmIwiJ+ViOsBvAeVf1tzbHvADirqoMiMgBgsare4/Y4PT092kwZoV3wdpNdIBjavNZXwB0eL2LbvqMolWcu3T8jgALl2Uv/J7lsBts3rWEQJ6LIiMiYqvY0Hm8nhXIrgJ3Vn3cC6GvjsWw1E7yBSuAdOnjC122HDp6oC94AUJ7RuuANAKXyjO/HJCIKk98ArgCeEJExEdlaPXa1qp4CgOrlVXZ3FJGtIjIqIqOTk5Ptt9jDyalSoLdr9rZERGHxG8B7VfVDAD4N4Gsi8gm/T6CqO1S1R1V7urrmzQQN3LJ8LtDbNXtbIqKw+ArgqnqyenkGwH8A+AiA0yKyFACql2eCblzvdUuaun12gcwNRHrp37AKuWym/v4ZQXaB1B3LZTO+H5OIKEyeAVxErhCRd1k/A7gZwK8B7AewpXqzLQAeD7pxu776Mccg3tjwfC7rewATAPq6C9i+aQ0K+RwEQCGfw9Dn12Jo89q6YxzAJCJTeVahiMj7UOl1A5Wyw39T1b8XkfcA2ANgOYAJAJtV1XXUsdkqFItdxQirQ4goLZyqUDzrwFX1JQBrbY6/AeCmYJrn7r79x+ZVjFjVIQzgRJRWxs/EHB4vYqpUtr2O1SFElGbGB3C3GmxWhxBRmhkfwN162awOIaI0Mz6AO/WyFy/KMv9NRKlmfAC3q9fOZTO497PXR9QiIiIzhLonZiusXjZXCCQiqmd8D5yIiOwZ3wNvnMRTnCph276jAMBeOBGlmvE9cLtlX7nEKxFRDAJ40aGMkJN4iCjtjA7gw+NFiMN1nMRDRGlndAAfOngCdkttCTiJh4jI6ADulD5RcACTiMjoAJ4R+wSK03EiojQxOoDPOKxV7nSciChNjA7gBYeBSkFlgJOIKM2MDuD9G1bZVqEo3JeZJSJKA6MDeF93wbYKBWAdOBGR0QEccE6jsA6ciNLO+ADutJws68CJKO2MD+B93QVs37QG+Vx27tjlWeObTUTUcbGJhG9fnJ37+dx0Gdv2HWUlChGlWiwCOFckJCKaLxYBnCsSEhHNZ3wA54qERET2jA/g9+0/xhUJiYhsGB3Ah8eLmCqVba/jioRElHZGB3C3QUqnCT5ERGlhdAB3G6S8cXVXiC0hIjKP0QHcbZDy4WcmcMP9T7AWnIhSy+gAbjeNvtZUiRN6iCi9jA7g1jR6N5zQQ0RpZXQABypB3GvAkhN6iCiNjA/ggHcqhRN6iCiNFkbdAD+seu/7f3wM56br68K5tCwRpZXvHriIZERkXER+Uv19iYg8KSIvVC8Xd66ZlSA+/u2b8eBtN6CQz0FQqQXfvmkNJ/QQUSo10wP/OoDnAby7+vsAgKdUdVBEBqq/3xNw++bp6y4wYBMRwWcPXESuAbARwEM1h28FsLP6804AfYG2jIiIXPlNoTwI4BsAZmuOXa2qpwCgenmV3R1FZKuIjIrI6OTkZDttJSKiGp4BXEQ+A+CMqo618gSqukNVe1S1p6uL09+JiILiJwfeC+AWEfkLAJcDeLeIPAzgtIgsVdVTIrIUwJlONpSIiOp59sBVdZuqXqOqKwB8EcCIqn4JwH4AW6o32wLg8U41cni8iN7BEawcOIDewRFOnSciQnt14IMA9ojIVwBMANgcTJPqDY8XsW3f0bk9MYtTJWzbdxQA1wMnonRraiamqv5UVT9T/fkNVb1JVd9fvTzbiQZyQ2MiInvGT6V3WueE658QUdoZH8Cd1jnh+idElHbGB/D+DauQzdTvS5/NCNc/IaLUMz6APzo6gfJMw770dtvUExGljNEB/FvDR3Hoxfljo+VZ5SAmEaWe0QF81+EJx+s4iElEaWd0AFeXVAkHMYko7YwO4G44iElEaWd0AF+UtW/eZRnhLEwiSj2jA3hhsX2a5L3vWRRyS4iIzGN0AH/hzPmmjhMRpYnRAZyIiJwxgBMRxVRsAzjXBCeitIttAL9v/7Gom0BEFKnYBvCpUjnqJhARRSq2AZyIKO1iG8AXL8pG3QQiokjFNoBv/NOlUTeBiChSRgfwyxo2cqi1d6zIShQiSjWjA/h3Pr/W8TpubExEaWd0APfCNcGJKM2MDuD9jx5xvZ5rghNRmhkdwMuzztflshmuCU5EqWZ0AHezfdMarglORKkW2wDO4E1EaRfbAE5ElHYM4EREMRXbAP6t4aNRN4GIKFKxDeAPPzPBIE5EqRbbAA4Au56ZiLoJRESRiXUA16gbQEQUoVgHcIBbqxFResU+gHNrNSJKK6MD+ALn1WTncGs1IkorzwAuIpeLyC9E5DkROSYi91ePLxGRJ0Xkherl4qAb57IcOBFR6i30cZu3AaxX1d+LSBbAz0TkvwBsAvCUqg6KyACAAQD3BNk4t8WsLF5bqw2PFzF08AROTpWwLJ9D/4ZVnIZPRIng2QPXit9Xf81W/ymAWwHsrB7fCaCvEw30cu9nr3e8bni8iG37jqI4VYICKE6VsG3fUQ58ElEi+MqBi0hGRI4AOAPgSVU9DOBqVT0FANXLqxzuu1VERkVkdHJyMqBmX+LWmx46eAKl8kzdMe7kQ0RJ4SuAq+qMqt4A4BoAHxGRD/p9AlXdoao9qtrT1dXVYjPtZcQ9Se60Yw938iGiJGiqCkVVpwD8FMCnAJwWkaUAUL08E3TjvKx7n/u4qdOOPdzJh4iSwE8VSpeI5Ks/5wB8EsBxAPsBbKnebAuAxzvURkevvOHek+7fsAq5bKbuGHfyIaKk8FOFshTAThHJoBLw96jqT0Tk5wD2iMhXAEwA2NzBdtrySoVY+XFWoRBREnkGcFX9FYBum+NvALipE43yy08qpK+7wIBNRInkpwduLFNSIaw1J6IoxDqAmxAkrVpzq1zRqjUHzGgfESVXbAN4LmvGMi5utea1AZy9dCIKmhlRsAUXZtSIGZV+as05I5SIOsHoAO42UWdmVnH3nuciD4J+as05I5SIOsHoAO41UWdGNfKerJ9ac84IJaJOMDqAe03UAaLvyfZ1F7B90xoU8jkIgEI+h+2b1tTltzkjlIg6wehBzKLPHmrUPVmvWvP+DavqKlUAzgglovYZHcD9Mr0nyxmhRNQJsQ/gcenJckYoEQUt1gG8wJ4sEaWY0QFcUNn6x07vdUuw66sfC7M5RERGMboK5Y51y22PX54RBm8iSj2jA/gDfWtw9bsum3f8DzOKO37w87pjw+NF9A6OYOXAAfQOjszVhjsdJyKKO6NTKMPjRZx+64LtdYdePIvh8SL6uguOC0qNvnoWe8eKXGiKiBLJ6B74tn2/cr3emsDjNFX9kcOvcQo7ESWW0QG8VJ51vb44VULv4IjjhJ8ZtR8CjXriDxFREIwO4H4Up0pwWvLKaTEs0yf+EBH5EfsADtiXGuayGdz+0Wu5qTERJVYiAnijxYuy2L5pDR7oWzNvoanPfbiAoYMnWJVCRLFndBVKqxZdtnCuyqR2Cju3PyOiJElkD7w4VbKtB797z3OsSiGixEhkDxxA3dZlVj04q1KIKEkSG8AtVj24U/AGWJVCRPGUyBRKI7fgzaoUIoqrVARwN43bnxERxUXqAziDNxHFVaoDeIG5byKKsdQGcOa+iSjuEl+FUsva4cdpK7bh8WJHNh7u1OMSUbqlKoB/77YbHANnp2ZpcvYnEXVKqlIobgHTaU3xdmdpdupxiYhS1QNfOXDAMYXhNBvTzyxNtxRJO49LROQmVT3w2un1jasQOs3G9JqlaaVIilMl28dv9XGJiLykKoBbSuUZ3Ln7SN1iV/0bVrW0drhXiqTVxyUi8iLqMs0cAETkWgD/CuCPAcwC2KGq3xeRJQB2A1gB4BUAX1DVc26P1dPTo6Ojo74bt2LggO/btqq2MuXG1V14+vhkU9UiKwcO2G4oYT32shYfl4jIIiJjqtrTeNxPDvwigLtV9VkReReAMRF5EsBfAnhKVQdFZADAAIB7gmx0GKzgW5wqYe9Ysemp9cvyOcc9Oa2USiuPS0TkxTOFoqqnVPXZ6s9vAXgeQAHArQB2Vm+2E0Bfh9oYmlaqQ+xSJEE8LhGRl6Zy4CKyAkA3gMMArlbVU0AlyAO4yuE+W0VkVERGJycn22xu5zn1pp30dRfqtm1zwqoTIgqa7zJCEXkngL0A7lTV34nDju+NVHUHgB1AJQfeSiODZOW8nTjtZO+mdtu23sER2w+B2qoTzswkoiD46oGLSBaV4L1LVfdVD58WkaXV65cCONOZJgbr49ctcV3Eym3tcD+8qk68yg6JiPzyDOBS6Wr/EMDzqvrdmqv2A9hS/XkLgMeDb17wXnmjhEMD6x2DeLsrFDamVAr5XN0AJmdmElFQ/KRQegF8GcBRETlSPfZNAIMA9ojIVwBMANjckRYGrDhVmktzNKZTgqrPrk2pNOLMTCIKimcAV9WfAY7jczcF25zOE1waqFR4r1AYNKeyQ87MJKJmxXomZu91S+blm7MZQXaB/eeN3QCmFbwPDawPZSCx2ZmZw+NF9A6OYOXAgbqZo0REsV7M6pmXzuH2j147t+t8RgS3/dm1ADBvJ/qCy4Sb2vRFpytEanPhXs/BpWiJyE2sA/iMKnb/4lKgtn6H1FeTWD3coYMnXNMXYQVMtxx5LbcBTwZwIjI6hZLLejevPKvzfi/P1B+zgp5T+uLG1V3oHRzBnbuPBF4h0k4KhAOeROTG6B5481NqnJ2cKtmmL25c3YW9Y8V5gbuWVbnSbFql3R49BzyJyI3RAXy6PBvYY1lBrzF90Ts44hq8gfrKlWaCcLspkP4Nq+o+AAAuRUtElxgdwFuRXSCAoC6Nks0Izr990XZHHq90hF3lSqk8g/t/fMxzILLdFEgzA55ElD6JCuBWLTdwKejlF2Xx5nQZU6UygEoPuv/R5wBUAqTbcrBulSvnpss4N33pMe165UGkQPwOeBJR+hg9iNnMulK1tdx93QUcGliPlwc3QrWyC0Wt8qyi/9EjdTMya+WyGTx42w2uU+4b2Q12cjceIuokowO433Wl3IKi1fNuVJ6dPyMTmL92iZ/1vi2NqRGvdVGIiNphdArFLYVhWbwoC1Xgrt1H5koF+7oLcxNy/KqdkVnLLg99/u2Lth8MdqkRpkCIqFOMDuD9G1bhzt1HXG/z5nR5LkVSnCrhrt1H8OjoBJ6deNOzuqSR0+BiYxDPL8oiu0DqatCZGiGisBmdQvHTc23MbyuAQy+ebTp4A86Di41reJ+bLgMC5HNZpkaIKDJG98AB4IrLMjh/oflg3Iqz599G9989ganpcl3Jnl09d3lGccU7FuLIvTeH0jaAO/nEDV8v6jTjA7i2uUNOM0rlWZSqk4dqSwNNmNLOha3iha8XhcHoFArQ+mzMIKbhl8ozuHvPc/ijXNb2eqfjncCdfOKFrxeFwfgA3opcNoM71i2vK9/LtxhsZ1Rx/sJF2/+o8xcuhrY+twnfAsg/vl4UBuMDuJ8VCWtZA4oP9K3BoYH1+N5tNwBwrgf3ozyjtl368oyG1qNyGmDlwlZm4utFYTA+gF/ucxINAGRE6gaKaqtH2jXrkIoP4rGd1C5FO33h4rydhli6aC7OwqUwGD+IOTXtv+c8o1o3UGSXhwxappn5/k1oHAQ7N11GNiPI57J4s1RmVYPhuBAZhcH4AO622JSd2uVaw8g3zqiid3Ak8DenKaWL1DrOwqVOMz6FcuPqrqbvYwX8sPKNVolYkAOaQQ6CcWNkomQyPoA/fXyy6fsIKkHLLg/ZmYRH8CViQQ2CNc4i7cSHDRFFw/gA3kqPU4G5NMrnPlyYy1NnRHDHuuUdC+KNu9u30+sNahCM9chEyZW4HLjl5FQJw+NF7B0r1u9a/8vXgm7inCB3tw9qEIz1yETJZXwAt9sX0o9l+ZzjQGAn1PaO290L0xLEIBg3RiZKLuNTKLWbIvhlBdNO9zIzIrarEbr1esMeUGQ9MlFyGd8Dr13RLSMylw6ptXhRZZq8tUflOxZWPpeaSb/YbV7sZUZ1bh9OP3thAkD/Y8/NfQtod4EjP6vdsR6ZKLkkzNX+enp6dHR01PftG3PJdnLZDD734QL2jhXrbud03I6fnX/c5LKZuh64n3Y3Pn/jTkBe7J6jsR1ElAwiMqaqPY3HjU6hOM2kbExdPH180jbn/PTxybo9KRdXd9KpZaUTmknRNGqs6rDSPn5nabaS6mF1CREZnUJxCmyzqnh5cOPc73c5bLt2cqo0byDQLe1w1+4jTadRnNra111wbFejVgYUWV1CREYHcL8VFM1UWjhVdvR1Fzz33/RqK1D/AbHAIWffaLq6LG0zqY80VZdwZxsie0anUPxWUARVadFqGsV6rsZZj3bBO7tAsKhhidxz0+WmZ0empbqEM0mJnBkdwGtLCN02D/Z7Oy92QdFOPpe1fS4/OfuhzWux+Ip3zLtNs/lrp3MG0HSZoslrpTDXT3HXyfeX0VUoUaj9up5flMXv/3AR5ZrFwJ0qPYbHi64pmEI+N5cCcKp4EQAvD25sOWXQSmWK6dUsKwcO2I5LWP9XRCYL6v3VchWKiPxIRM6IyK9rji0RkSdF5IXq5WLfLTFcX3cBhwbW4+XBjRj/9s0Y2rzWs2dvvUhOBKhLATjVpizL59pKGbTSWzW9h8udbSjOOv3+8pNC+RcAn2o4NgDgKVV9P4Cnqr8nUm1APzSw3vZT023jCLsJQor5qyJa+et2XvBWKlNMr2ZJS66fkqnT7y/PAK6q/wPgbMPhWwHsrP68E0BfIK0xkJ/8lduL4ZSgUsC2Z9/OC95Kb9X0Hm5Q4xtEUej0+6vVMsKrVfUUAKjqKRG5yumGIrIVwFYAWL58eYtPFw2/qwo65bUL+RzOv33RdkPlfC5rO/uynfJAu4W/vHqrrdwnbNzZhuKq0++vjlehqOoOVe1R1Z6uruZ314mS33SG29d8p8mYTsfbSRm00ltlD5eoczr9/mq1B35aRJZWe99LAZwJpDWG8ZvOcFswymk2ptNmzX4Wn3KrUmmlt8oeLpkiiZO2Ovn+ajWA7wewBcBg9fLxwFpkkCBmeDo9hgKOmyG7veBBbBZBZCL+bTfPsw5cRB4B8OcArgRwGsC9AIYB7AGwHMAEgM2q2jjQOY/JdeB2n/wAfNVwOvUahseLuG//MdsceK18Lov7brne1x9p7+CIY77d74qGSezlNErDOSZNEH/bSeVUB+7ZA1fV2x2uuqntVvnU6Tej0yf/9k1rsH3TGs90ht19R18962spWwCYKpV99zTaLUtKQy8nDeeYRKaXtJrI6MWsgHDejG6DlU613173feTwa74Wsmp8Pq9zancRq6C2ezNZGs4xidK0QFtQjF4LBQhnpmA7n/xOt2kmeDfzfO1ObElDLycN55hEnLTVPON74GG8GZv95PezZKzT9m9uW7f56Wm0W6WShl5OGs4xibj9X/OMD+BhvBmbKbZvTOnYBWm37dxy1aVkp8uzdcezCwTTFy5i5cABLMvncOPqLjx9fLLpUkGvlFMcJu60Kw3nmFQsaW2O8SmU/g2r5m2Dll0ggb4Zmym297vN2wN9lQFQa8Nly3R5FgrBl9Ytn3u+fC4LSGVdcGsBq4efmejIglZpmLjT7jmavLwuUS3je+AA5q/85G+ryab4/eT3u82b9ZhDB0/gXMOkHWu/Tqs0qndwxLPU0O8gnJ+UUxp6Oa2eIytYKE6M74EPHTyB8kx9mqI8o5Etd9rs4jR+AqrffH6nFrSiS0xfXpeolvEB3JSKAutrtd163m75VT8B1W9w9bugFUfyW2fK3xuRH8YHcBN6lLWbLAD163l75Vf9BFQ/W7l1ckErusSEvzciv4zPgZtQUWD3tdpaz9triq+f0ii727hVoXhJQ467U0z4eyPyy/gAbkJtaLtfq/0E1LCDLtcKsWfC3xuRX8YHcCD6HmXSJoaw0sJd1H9vRH4ZnwM3QdIGBllpQZQMseiBRy1pX6vjWmnBtI95+JpEiwHcpyR9rY5jSohpH/PwNYkeUygpFMeUENM+5uFrEj32wFMojimhuKZ9koyvSfQYwFMqbimhOKZ9ko6vSfSYQqFYiGPaJ+n4mkSPPXCKhTimfZKOr0n0PHelD5LJu9ITEZnKaVd6plCIiGKKAZyIKKYYwImIYooBnIgophjAiYhiKtQqFBGZBPBqaE9YcSWA34b8nKZI87kD6T7/NJ87kLzzf6+qdjUeDDWAR0FERu3Kb9IgzecOpPv803zuQHrOnykUIqKYYgAnIoqpNATwHVE3IEJpPncg3eef5nMHUnL+ic+BExElVRp64EREicQATkQUU4kN4CLyKRE5ISK/EZGBqNsTJhG5VkSeFpHnReSYiHw96jaFTUQyIjIuIj+Jui1hE5G8iDwmIserfwMfi7pNYRGRu6p/878WkUdE5PKo29RJiQzgIpIB8I8APg3gAwBuF5EPRNuqUF0EcLeq/gmAdQC+lrLzB4CvA3g+6kZE5PsA/ltVVwNYi5T8P4hIAcDfAuhR1Q8CyAD4YrSt6qxEBnAAHwHwG1V9SVUvAPh3ALdG3KbQqOopVX22+vNbqLyBU7PKvohcA2AjgIeibkvYROTdAD4B4IcAoKoXVHUq0kaFayGAnIgsBLAIwMmI29NRSQ3gBQCv1fz+OlIUwGqJyAoA3QAOR9yUMD0I4BsAZiNuRxTeB2ASwD9XU0gPicgVUTcqDKpaBPAPACYAnALwpqo+EW2rOiupAVxsjqWuXlJE3glgL4A7VfV3UbcnDCLyGQBnVHUs6rZEZCGADwH4J1XtBnAeQCrGgERkMSrftFcCWAbgChH5UrSt6qykBvDXAVxb8/s1SPhXqUYikkUleO9S1X1RtydEvQBuEZFXUEmdrReRh6NtUqheB/C6qlrfuB5DJaCnwScBvKyqk6paBrAPwMcjblNHJTWA/xLA+0VkpYhchspAxv6I2xQaERFUcqDPq+p3o25PmFR1m6peo6orUHndR1Q10b2wWqr6fwBeExFra/ibAPxvhE0K0wSAdSKyqPoeuAkJH8BN5K70qnpRRP4awEFURqJ/pKrHIm5WmHoBfBnAURE5Uj32TVX9z+iaRCH6GwC7qp2XlwD8VcTtCYWqHhaRxwA8i0ol1jgSPqWeU+mJiGIqqSkUIqLEYwAnIoopBnAiophiACciiikGcCKimGIAJyKKKQZwIqKY+n/C1i6kYbgqYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "x_ = data['data']\n",
    "y_ = data['target']\n",
    "N_tr = int(x_.shape[0] * 0.8)\n",
    "N_val = x_.shape[0] - N_tr\n",
    "a = np.arange(x_.shape[0])\n",
    "train_index = np.random.choice(a, size = N_tr, replace = False)\n",
    "val_index = np.delete(a, train_index, axis=0)\n",
    "x_train = x_[train_index]\n",
    "y_train = y_[train_index].reshape(-1, 1)\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train-x_m)/ x_s\n",
    "x_val = (x_val-x_m)/ x_s\n",
    "x_val = x_[val_index][:]\n",
    "y_val = y_[val_index][:].reshape(-1, 1)\n",
    "D_in = x_train.shape[1]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "plt.scatter(x_train.numpy()[:,0],y_train.numpy())\n",
    "    \n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0da46a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device  =torch.device('cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "num_nodes = 2\n",
    "alpha = 1.\n",
    "beta = 1.\n",
    "ELBO_BETA = 1.\n",
    "net = Net(num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e062db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.1\n",
    "\n",
    "num_samples = 30000\n",
    "L = 5\n",
    "burn = 10000\n",
    "store_on_GPU = False\n",
    "debug = False\n",
    "model_loss = 'regression'\n",
    "mass = 1.0\n",
    "\n",
    "# Effect of tau\n",
    "# Set to tau = 1000. to see a function that is less bendy (weights restricted to small bends)\n",
    "# Set to tau = 1. for more flexible\n",
    "\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = beta * 1/ELBO_BETA # Output Precision\n",
    "r = 1000 # Random seed\n",
    "\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "# Set initial weights\n",
    "params_init = hamiltorch.util.flatten(net).to(device).clone()\n",
    "# Set the Inverse of the Mass matrix\n",
    "inv_mass = torch.ones(params_init.shape) / mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a29e3379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37])\n",
      "Sampling (Sampler.HMC; Integrator.IMPLICIT)\n",
      "Time spent  | Time remain.| Progress             | Samples     | Samples/sec\n",
      "Final Adapted Step Size:  0.038417212665081024-- |  9976/30000 | 102.80       \n",
      "0d:00:04:36 | 0d:00:00:00 | #################### | 30000/30000 | 108.44       \n",
      "Acceptance Rate 0.27\n"
     ]
    }
   ],
   "source": [
    "print(params_init.shape)\n",
    "integrator = hamiltorch.Integrator.EXPLICIT\n",
    "sampler = hamiltorch.Sampler.HMC_NUTS\n",
    "\n",
    "hamiltorch.set_random_seed(r)\n",
    "params_hmc_f = hamiltorch.sample_model(net, x_train.to(device), y_train.to(device), params_init=params_init,\n",
    "                                       model_loss=model_loss, num_samples=num_samples,\n",
    "                                       burn = burn, inv_mass=inv_mass.to(device),step_size=step_size,\n",
    "                                       num_steps_per_sample=L,tau_out=tau_out, tau_list=tau_list,\n",
    "                                       debug=debug, store_on_GPU=store_on_GPU,\n",
    "                                       sampler = sampler)\n",
    "\n",
    "# At the moment, params_hmc_f is on the CPU so we move to GPU\n",
    "\n",
    "params_hmc_gpu = [ll.to(device) for ll in params_hmc_f[1:]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c8e749b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_hmc, log_probs_f = hamiltorch.predict_model(net, x = x_train.to(device),\n",
    "                                                  y = y_train.to(device), samples=params_hmc_gpu,\n",
    "                                                  model_loss=model_loss, tau_out=beta,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "59327ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-20.9151],\n",
       "        [-22.8643],\n",
       "        [-13.0516],\n",
       "        [-28.2550],\n",
       "        [ -8.2645],\n",
       "        [-20.0828],\n",
       "        [-23.0086],\n",
       "        [-11.0522],\n",
       "        [-22.6078],\n",
       "        [-23.5979],\n",
       "        [ -7.9366],\n",
       "        [ -9.9387],\n",
       "        [-12.3298],\n",
       "        [-23.3979],\n",
       "        [-17.6143],\n",
       "        [-24.1913],\n",
       "        [-28.5981],\n",
       "        [ -8.2786],\n",
       "        [-26.1706],\n",
       "        [-16.3905],\n",
       "        [-22.5417],\n",
       "        [-22.4371],\n",
       "        [-11.4459],\n",
       "        [-14.5243],\n",
       "        [-16.3342],\n",
       "        [-28.3382],\n",
       "        [-19.9489],\n",
       "        [-24.1831],\n",
       "        [-22.6364],\n",
       "        [-17.0057],\n",
       "        [-14.7581],\n",
       "        [-12.5975],\n",
       "        [ -6.6814],\n",
       "        [-14.8978],\n",
       "        [-14.0339],\n",
       "        [ -7.8673],\n",
       "        [-22.2898],\n",
       "        [-49.3557],\n",
       "        [-10.8913],\n",
       "        [-20.9655],\n",
       "        [-13.1098],\n",
       "        [-29.4785],\n",
       "        [-23.9206],\n",
       "        [-19.1832],\n",
       "        [-17.0699],\n",
       "        [-18.0768],\n",
       "        [-13.4699],\n",
       "        [-19.6029],\n",
       "        [-18.1844],\n",
       "        [-22.8473],\n",
       "        [-18.0889],\n",
       "        [-23.3667],\n",
       "        [-49.5208],\n",
       "        [-17.9443],\n",
       "        [-11.4470],\n",
       "        [-14.0602],\n",
       "        [-29.2587],\n",
       "        [-17.8422],\n",
       "        [-28.5303],\n",
       "        [-27.5529],\n",
       "        [-16.3769],\n",
       "        [-32.1003],\n",
       "        [-27.1728],\n",
       "        [-23.9612],\n",
       "        [-16.6403],\n",
       "        [ -4.5212],\n",
       "        [-23.8889],\n",
       "        [-23.8588],\n",
       "        [-22.3970],\n",
       "        [-22.9083],\n",
       "        [-24.7320],\n",
       "        [-18.4545],\n",
       "        [-19.2182],\n",
       "        [-36.8074],\n",
       "        [-29.5177],\n",
       "        [-26.1142],\n",
       "        [-33.2900],\n",
       "        [-19.7107],\n",
       "        [-21.0556],\n",
       "        [ -9.8732],\n",
       "        [-27.1098],\n",
       "        [-30.0701],\n",
       "        [-20.7984],\n",
       "        [-26.2177],\n",
       "        [-13.7763],\n",
       "        [-23.0379],\n",
       "        [-20.4026],\n",
       "        [-22.7449],\n",
       "        [ -4.4605],\n",
       "        [-15.9162],\n",
       "        [-25.9060],\n",
       "        [-21.8273],\n",
       "        [-16.9022],\n",
       "        [-10.0557],\n",
       "        [-24.8018],\n",
       "        [ -8.3260],\n",
       "        [-12.7441],\n",
       "        [-34.9347],\n",
       "        [-34.4247],\n",
       "        [-19.7117],\n",
       "        [-24.4175],\n",
       "        [-13.6821],\n",
       "        [-11.3927],\n",
       "        [-22.4558],\n",
       "        [-12.6382],\n",
       "        [-27.5859],\n",
       "        [-15.6942],\n",
       "        [-14.6372],\n",
       "        [-34.3063],\n",
       "        [-24.1490],\n",
       "        [-21.8282],\n",
       "        [-34.5604],\n",
       "        [ -5.7728],\n",
       "        [-20.6088],\n",
       "        [-13.1514],\n",
       "        [ -9.9060],\n",
       "        [-21.6042],\n",
       "        [-28.3603],\n",
       "        [-24.4592],\n",
       "        [-22.4376],\n",
       "        [-22.7038],\n",
       "        [-19.1802],\n",
       "        [-35.8225],\n",
       "        [-12.2564],\n",
       "        [-19.2019],\n",
       "        [-22.5047],\n",
       "        [-37.2822],\n",
       "        [-18.9505],\n",
       "        [-31.3541],\n",
       "        [-20.1050],\n",
       "        [-30.5854],\n",
       "        [-18.9059],\n",
       "        [-16.9295],\n",
       "        [-34.9346],\n",
       "        [-11.1194],\n",
       "        [-19.6876],\n",
       "        [-21.7338],\n",
       "        [ -8.1331],\n",
       "        [-20.4844],\n",
       "        [-10.4119],\n",
       "        [-19.8404],\n",
       "        [-18.7989],\n",
       "        [-23.4713],\n",
       "        [-22.6004],\n",
       "        [-21.5076],\n",
       "        [-19.7039],\n",
       "        [-18.7635],\n",
       "        [-31.5121],\n",
       "        [-13.8959],\n",
       "        [-21.9857],\n",
       "        [-32.9495],\n",
       "        [-16.1966],\n",
       "        [-26.3150],\n",
       "        [-18.3346],\n",
       "        [-15.0447],\n",
       "        [-19.9177],\n",
       "        [-35.6219],\n",
       "        [-22.2348],\n",
       "        [ -8.0222],\n",
       "        [-12.9444],\n",
       "        [-19.5280],\n",
       "        [-11.5691],\n",
       "        [-19.2897],\n",
       "        [-22.2914],\n",
       "        [-21.0647],\n",
       "        [-21.5557],\n",
       "        [-16.1313],\n",
       "        [-14.2559],\n",
       "        [-17.2790],\n",
       "        [-44.4398],\n",
       "        [-12.9158],\n",
       "        [-21.6230],\n",
       "        [-17.4962],\n",
       "        [-23.1669],\n",
       "        [ -7.5053],\n",
       "        [-17.2877],\n",
       "        [-30.4946],\n",
       "        [-30.1515],\n",
       "        [-19.3360],\n",
       "        [-40.9134],\n",
       "        [-49.5940],\n",
       "        [-14.6150],\n",
       "        [-18.2326],\n",
       "        [-20.9686],\n",
       "        [-12.6289],\n",
       "        [-14.3634],\n",
       "        [-13.0650],\n",
       "        [-24.5428],\n",
       "        [-19.7840],\n",
       "        [-20.1260],\n",
       "        [-18.7037],\n",
       "        [-26.6722],\n",
       "        [-16.7836],\n",
       "        [-15.0817],\n",
       "        [-48.3498],\n",
       "        [-29.6461],\n",
       "        [-22.9337],\n",
       "        [-21.9027],\n",
       "        [-26.6316],\n",
       "        [-17.8055],\n",
       "        [-18.9554],\n",
       "        [-23.9136],\n",
       "        [-22.5758],\n",
       "        [-21.6294],\n",
       "        [-28.9202],\n",
       "        [-23.9979],\n",
       "        [-22.3900],\n",
       "        [-19.0904],\n",
       "        [ -6.8432],\n",
       "        [-22.8997],\n",
       "        [-28.2624],\n",
       "        [-23.6541],\n",
       "        [-15.1752],\n",
       "        [-15.7774],\n",
       "        [-49.5023],\n",
       "        [-22.0432],\n",
       "        [-27.9505],\n",
       "        [-22.3205],\n",
       "        [-26.1083],\n",
       "        [-12.2007],\n",
       "        [-32.4243],\n",
       "        [-49.6255],\n",
       "        [-24.1584],\n",
       "        [-16.1115],\n",
       "        [-49.5380],\n",
       "        [-17.1494],\n",
       "        [-42.4519],\n",
       "        [ -7.1197],\n",
       "        [-28.1392],\n",
       "        [-16.1412],\n",
       "        [-10.4901],\n",
       "        [-47.9488],\n",
       "        [-16.2164],\n",
       "        [-49.4087],\n",
       "        [-18.4847],\n",
       "        [-43.0190],\n",
       "        [-21.9726],\n",
       "        [-20.1420],\n",
       "        [-20.3148],\n",
       "        [-14.7562],\n",
       "        [-23.4307],\n",
       "        [-24.6745],\n",
       "        [-23.2439],\n",
       "        [-19.0118],\n",
       "        [-18.6212],\n",
       "        [-23.5544],\n",
       "        [-19.4908],\n",
       "        [-17.8336],\n",
       "        [-16.8329],\n",
       "        [ -6.8043],\n",
       "        [-14.5363],\n",
       "        [-41.8042],\n",
       "        [-21.3006],\n",
       "        [-16.9036],\n",
       "        [-14.7335],\n",
       "        [-20.7572],\n",
       "        [-13.2481],\n",
       "        [-19.6111],\n",
       "        [-23.4938],\n",
       "        [-31.0447],\n",
       "        [-15.8673],\n",
       "        [-41.3780],\n",
       "        [-34.6005],\n",
       "        [-20.9233],\n",
       "        [-14.8880],\n",
       "        [-19.8485],\n",
       "        [-13.1750],\n",
       "        [-34.1095],\n",
       "        [-11.4617],\n",
       "        [-18.0892],\n",
       "        [-19.3840],\n",
       "        [-20.5050],\n",
       "        [-14.2177],\n",
       "        [-29.8011],\n",
       "        [-21.5496],\n",
       "        [-21.2160],\n",
       "        [-19.2158],\n",
       "        [-46.2378],\n",
       "        [-20.4721],\n",
       "        [-49.5093],\n",
       "        [-36.5498],\n",
       "        [-17.8262],\n",
       "        [-13.8051],\n",
       "        [ -7.8943],\n",
       "        [-36.7364],\n",
       "        [-49.5420],\n",
       "        [-14.7265],\n",
       "        [-14.5920],\n",
       "        [-24.0410],\n",
       "        [-20.5279],\n",
       "        [-11.8863],\n",
       "        [-45.3828],\n",
       "        [-35.6968],\n",
       "        [-23.5032],\n",
       "        [-19.1414],\n",
       "        [-14.1229],\n",
       "        [-25.8988],\n",
       "        [-11.4544],\n",
       "        [ -9.7731],\n",
       "        [-20.6748],\n",
       "        [-21.1856],\n",
       "        [-15.6555],\n",
       "        [-19.6581],\n",
       "        [-10.5081],\n",
       "        [ -6.4751],\n",
       "        [-18.1879],\n",
       "        [-19.9169],\n",
       "        [-21.4937],\n",
       "        [-18.8871],\n",
       "        [-29.7285],\n",
       "        [-32.4407],\n",
       "        [-13.8059],\n",
       "        [-19.9829],\n",
       "        [-11.7344],\n",
       "        [-32.5635],\n",
       "        [-12.3913],\n",
       "        [-21.9129],\n",
       "        [-14.6073],\n",
       "        [-16.5660],\n",
       "        [-21.2283],\n",
       "        [-22.8744],\n",
       "        [-21.7675],\n",
       "        [-23.3361],\n",
       "        [-23.7089],\n",
       "        [-31.1642],\n",
       "        [-23.2112],\n",
       "        [-19.6844],\n",
       "        [-26.8433],\n",
       "        [-49.3748],\n",
       "        [ -6.7734],\n",
       "        [-31.1430],\n",
       "        [ -5.1100],\n",
       "        [-18.7782],\n",
       "        [-31.2345],\n",
       "        [-12.1507],\n",
       "        [ -7.9539],\n",
       "        [-24.3147],\n",
       "        [-31.5328],\n",
       "        [-32.6675],\n",
       "        [-21.5019],\n",
       "        [-22.0449],\n",
       "        [-21.4422],\n",
       "        [-21.5254],\n",
       "        [-28.5848],\n",
       "        [-22.9054],\n",
       "        [-18.8388],\n",
       "        [-18.4333],\n",
       "        [-16.8723],\n",
       "        [-13.4627],\n",
       "        [ -9.7016],\n",
       "        [-23.3898],\n",
       "        [-18.4580],\n",
       "        [-19.0437],\n",
       "        [-18.3222],\n",
       "        [ -9.1619],\n",
       "        [-19.1772],\n",
       "        [-15.1410],\n",
       "        [-18.0905],\n",
       "        [-13.0349],\n",
       "        [-19.5756],\n",
       "        [-30.7637],\n",
       "        [-24.2619],\n",
       "        [-23.3100],\n",
       "        [-19.8790],\n",
       "        [-12.7612],\n",
       "        [-27.3976],\n",
       "        [-26.0594],\n",
       "        [-23.4537],\n",
       "        [-22.2035],\n",
       "        [-17.3842],\n",
       "        [-24.5583],\n",
       "        [-23.9283],\n",
       "        [-12.6848],\n",
       "        [ -9.3186],\n",
       "        [-38.2990],\n",
       "        [-34.4330],\n",
       "        [-12.4431],\n",
       "        [-17.0642],\n",
       "        [-19.6723],\n",
       "        [-19.5940],\n",
       "        [-27.9177],\n",
       "        [ -6.3349],\n",
       "        [-32.8197],\n",
       "        [-20.2864],\n",
       "        [-16.7374],\n",
       "        [-13.4665],\n",
       "        [-20.9652],\n",
       "        [-13.1917],\n",
       "        [-21.3703],\n",
       "        [-13.8429],\n",
       "        [-24.6357],\n",
       "        [-22.2279],\n",
       "        [-19.0570],\n",
       "        [-17.4008],\n",
       "        [-44.9758],\n",
       "        [-20.2832],\n",
       "        [-23.2317],\n",
       "        [-29.7237],\n",
       "        [-24.5804],\n",
       "        [-24.4993],\n",
       "        [-19.5824],\n",
       "        [-18.2349],\n",
       "        [-17.5289],\n",
       "        [-21.5871]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_hmc[-10000:].mean(0) - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cca83c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list_hmc, log_probs_f = hamiltorch.predict_model(net, x = x_val.to(device),\n",
    "                                                  y = y_val.to(device), samples=params_hmc_gpu,\n",
    "                                                  model_loss=model_loss, tau_out=beta,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d87fbfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-23.6100],\n",
       "        [-33.0100],\n",
       "        [-21.3100],\n",
       "        [-20.0100],\n",
       "        [-22.7100],\n",
       "        [-17.8100],\n",
       "        [-18.0100],\n",
       "        [-12.8100],\n",
       "        [-30.4100],\n",
       "        [-34.5100],\n",
       "        [-20.8100],\n",
       "        [-18.9100],\n",
       "        [-19.6100],\n",
       "        [-19.0100],\n",
       "        [-21.3100],\n",
       "        [-20.4100],\n",
       "        [-24.4100],\n",
       "        [-22.2100],\n",
       "        [-24.6100],\n",
       "        [-43.4100],\n",
       "        [-32.8100],\n",
       "        [-18.9100],\n",
       "        [-19.4100],\n",
       "        [-18.1100],\n",
       "        [-20.8100],\n",
       "        [-18.9100],\n",
       "        [-16.9100],\n",
       "        [-15.3100],\n",
       "        [-18.8100],\n",
       "        [-13.6100],\n",
       "        [-13.0100],\n",
       "        [-14.2100],\n",
       "        [-19.0100],\n",
       "        [-15.2100],\n",
       "        [-49.6100],\n",
       "        [-22.2100],\n",
       "        [-24.2100],\n",
       "        [-39.4100],\n",
       "        [-37.5100],\n",
       "        [-29.2100],\n",
       "        [-29.4100],\n",
       "        [-36.0100],\n",
       "        [-23.7100],\n",
       "        [-48.1100],\n",
       "        [-49.6100],\n",
       "        [-18.9100],\n",
       "        [-27.7100],\n",
       "        [-22.9100],\n",
       "        [-21.1100],\n",
       "        [-21.3100],\n",
       "        [-49.6100],\n",
       "        [-21.6100],\n",
       "        [-17.2100],\n",
       "        [-20.1100],\n",
       "        [-25.8100],\n",
       "        [-43.6100],\n",
       "        [-35.6100],\n",
       "        [-42.7100],\n",
       "        [-36.1100],\n",
       "        [-20.3100],\n",
       "        [-20.7100],\n",
       "        [-32.0100],\n",
       "        [-31.8100],\n",
       "        [-21.9100],\n",
       "        [-28.1100],\n",
       "        [-21.3100],\n",
       "        [-24.4100],\n",
       "        [-32.7100],\n",
       "        [-27.8100],\n",
       "        [-15.7100],\n",
       "        [-21.2100],\n",
       "        [-15.8100],\n",
       "        [-20.6100],\n",
       "        [-22.7100],\n",
       "        [-21.8100],\n",
       "        [-22.2100],\n",
       "        [-18.6100],\n",
       "        [-18.3100],\n",
       "        [-32.3100],\n",
       "        [-22.7100],\n",
       "        [-23.7100],\n",
       "        [-20.2100],\n",
       "        [-17.4100],\n",
       "        [-16.4100],\n",
       "        [-27.1100],\n",
       "        [-22.7100],\n",
       "        [-49.6100],\n",
       "        [-49.6100],\n",
       "        [-49.6100],\n",
       "        [-13.4100],\n",
       "        [-13.5100],\n",
       "        [-10.1100],\n",
       "        [ -9.3100],\n",
       "        [-15.9100],\n",
       "        [-10.6100],\n",
       "        [-13.7100],\n",
       "        [-14.5100],\n",
       "        [-22.6100],\n",
       "        [-24.6100],\n",
       "        [-18.7100],\n",
       "        [-13.2100],\n",
       "        [-20.8100]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_hmc[-10000:].mean(0) - y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f12931",
   "metadata": {},
   "source": [
    "# Draw subset of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "375cbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "subset = random.sample(params_hmc_gpu[-5000:], 1000)\n",
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list_hmc_subsample, log_probs_f = hamiltorch.predict_model(net, x = x_val.to(device),\n",
    "                                                  y = x_val.to(device), samples=subset,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2a74db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_samples = torch.empty([0])\n",
    "for s in subset:\n",
    "    emp_samples = torch.cat([emp_samples, s[None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "02205e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py:81: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-407.8339)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = D.MultivariateNormal(loc=torch.zeros_like(emp_samples[0]), covariance_matrix = 1./alpha * torch.eye(emp_samples.shape[-1]))\n",
    "prior.log_prob(emp_samples).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece02157",
   "metadata": {},
   "source": [
    "###### Let's try the KDE coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f603ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f738fdea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chosen_emp_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-bd0109c06681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbnn_kde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The loss is: {loss.item():.5f}, val of var is: {torch.exp(bnn_kde.log_kde_std)[0].item() ** 2:.5f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/models/BNNs/BNN_KDE.py\u001b[0m in \u001b[0;36melbo\u001b[0;34m(self, x, y, n_samples)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# first sample weights from KDE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mweight_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mweight_prior_lp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_prior_lp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/models/BNNs/BNN_KDE.py\u001b[0m in \u001b[0;36msample_from_kde\u001b[0;34m(self, n_samples)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mchosen_stds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkde_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchosen_emp_samples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchosen_stds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chosen_emp_samples' is not defined"
     ]
    }
   ],
   "source": [
    "# find optimal kde_var\n",
    "from models.BNNs.BNN_KDE import BNN_KDE\n",
    "\n",
    "bnn_kde = BNN_KDE(emp_samples, alpha=alpha, beta=beta, kl_beta=ELBO_BETA)\n",
    "\n",
    "num_epochs = 5000\n",
    "num_parallel_samples = 128\n",
    "optimiser = torch.optim.Adamax(bnn_kde.parameters(), lr=5e-2)\n",
    "for i in range(num_epochs):\n",
    "    optimiser.zero_grad()\n",
    "    loss = -bnn_kde.elbo(x_train, y_train, num_parallel_samples)\n",
    "    if i % 1000 == 0:\n",
    "        print(f'The loss is: {loss.item():.5f}, val of var is: {torch.exp(bnn_kde.log_kde_std)[0].item() ** 2:.5f}')\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104be273",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_var = torch.exp(bnn_kde.log_kde_std)[0].item() ** 2\n",
    "#n_samples = 100\n",
    "KDE_weights = dist.Categorical(torch.ones(emp_samples.shape[0]))\n",
    "initial_seed = 0\n",
    "torch.manual_seed(initial_seed)\n",
    "KDE_components = dist.MultivariateNormal(loc=emp_samples,\n",
    "                                         covariance_matrix=KDE_var * torch.eye(emp_samples.shape[-1]))\n",
    "\n",
    "KDE_target = dist.MixtureSameFamily(KDE_weights, KDE_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c26584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.utils import kl_estimate_with_mc\n",
    "prior = D.MultivariateNormal(loc=torch.zeros_like(emp_samples[0]), covariance_matrix = 1./alpha * torch.eye(emp_samples.shape[-1]))\n",
    "kl_q_p = kl_estimate_with_mc(KDE_target, prior)\n",
    "print(f\"{kl_q_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e8802",
   "metadata": {},
   "source": [
    "# Lets optimise the variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from models.BNNs.BNN_for_HMC import BNN_for_HMC\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c68221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = BNN_for_HMC(alpha=alpha, beta=beta, num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6388fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# pkl.dump(emp_samples, open(\"PickledStuff/emp_samples.pkl\", \"wb\"))\n",
    "# pkl.dump(x_data, open(\"PickledStuff/x_data.pkl\", \"wb\"))\n",
    "# pkl.dump(y_data, open(\"PickledStuff/y_data.pkl\", \"wb\"))\n",
    "# pkl.dump(ys, open(\"PickledStuff/ys.pkl\", \"wb\"))\n",
    "# pkl.dump(xs, open(\"PickledStuff/xs.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22beb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dist = dist.Empirical(emp_samples, log_weights=torch.ones(emp_samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = emp_dist.mean\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1./alpha\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791ab12",
   "metadata": {},
   "source": [
    "# Let's use the EMP scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e5ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_emp_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = ys.to(device), samples=compressed_weights_emp_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_low_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711edb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_med_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_med_eps.append(w[0])\n",
    "\n",
    "pred_list_emp_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_emp_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_med_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_emp_high_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_high_eps.append(w[0])\n",
    "\n",
    "pred_list_emp_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_emp_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_emp_high_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d449a",
   "metadata": {},
   "source": [
    "# Let's try the KDE coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db352ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39075d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_exact = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    torch.manual_seed(i)\n",
    "    compressed_weights_kde_exact.append(KDE_target.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_exact, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_exact,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a5ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_low_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75963162",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_med_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f8fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_med_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 50\n",
    "compressed_weights_kde_high_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(KDE_target,\n",
    "                        initial_seed,\n",
    "                        coding_sampler,\n",
    "                        selection_sampler,\n",
    "                        auxiliary_posterior,\n",
    "                        omega,\n",
    "                        epsilon=epsilon,\n",
    "                        beamwidth=beamwidth,\n",
    "                        prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46777f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_kde_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_kde_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_kde_high_eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863a2ae",
   "metadata": {},
   "source": [
    "# Let's Compute some Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empirical_predictive(weights, x_input, y_output):\n",
    "    pred_list, _ = hamiltorch.predict_model(net, x = x_input.flatten().to(device),\n",
    "                                                  y = y_output.flatten().to(device), samples=weights,\n",
    "                                                  model_loss='regression', tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "    \n",
    "    # need to make gmm at each sample\n",
    "    return pred_list\n",
    "\n",
    "def make_empirical_gmm(preds):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Normal(loc=preds.squeeze().permute(1, 0), scale=beta ** -0.5)\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "    return gmm\n",
    "\n",
    "def compute_gmm_lp(weights, x, y):\n",
    "    preds = make_empirical_predictive(weights, x, y)\n",
    "    \n",
    "    gmm = make_empirical_gmm(preds)\n",
    "    \n",
    "    return gmm.log_prob(y.squeeze()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(params_hmc_gpu, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb397f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(params_hmc_gpu, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e191965",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_emp_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_exact, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274708f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a2810",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb47325",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_kde_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43589692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(kl_q_p, open(f'PickledStuff/BNN_STUFF/EMP/hmc_kl_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(subset, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/HMC_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_emp_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/EMP/emp_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_exact, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_kde_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/KDE/kde_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f05a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
