{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1aa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# !wget \"http://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\" --no-check-certificate\n",
    "data = pd.read_excel('ENB2012_data.xlsx', header=0).iloc[:, :10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240997c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from torch import nn\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import HMC, MCMC, SVI, NUTS, TraceMeanField_ELBO\n",
    "from pyro import poutine\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange\n",
    "from rec.utils import kl_estimate_with_mc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c84bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = data[:, :-2]\n",
    "y_ = data[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f476367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_idxs = []\n",
    "for d in range(x_.shape[-1]):\n",
    "    sorted_x = np.argsort(x_[:,d], axis=-1)\n",
    "    total_points = sorted_x.shape[0]\n",
    "    lower_third = total_points // 3\n",
    "    upper_third = total_points * 2 // 3\n",
    "    test_index = sorted_x[lower_third: upper_third]\n",
    "    test_splits_idxs.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6b102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_x, test_splits_y = [], []\n",
    "train_splits_x, train_splits_y = [], []\n",
    "for d in range(x_.shape[-1]):\n",
    "    a = np.arange(x_.shape[0])\n",
    "    test_index = test_splits_idxs[d]\n",
    "    train_index = np.delete(a, test_index, axis=0)\n",
    "    x_train = x_[train_index]\n",
    "    y_train = y_[train_index]\n",
    "    x_test = x_[test_index][:]\n",
    "    y_test = y_[test_index][:]\n",
    "    x_m = x_train.mean(0)\n",
    "    x_s = x_train.std(0)\n",
    "    x_train = (x_train - x_m) / x_s\n",
    "    x_test = (x_test - x_m) / x_s\n",
    "    test_splits_x.append(x_test)\n",
    "    test_splits_y.append(y_test)\n",
    "    train_splits_x.append(x_train)\n",
    "    train_splits_y.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2b3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = x_train.shape[-1]\n",
    "D_out = y_test.shape[-1]\n",
    "x_train = torch.FloatTensor(np.array(train_splits_x))\n",
    "y_train = torch.FloatTensor(np.array(train_splits_y))\n",
    "x_test= torch.FloatTensor(np.array(test_splits_x))\n",
    "y_test = torch.FloatTensor(np.array(test_splits_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfbdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(x, y=None, weight_samples=None, in_size=1, num_nodes=10, out_size=1, ELBO_BETA=1.):\n",
    "    # sample vector of weights for regression\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    # sample params\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(torch.zeros(total_weights + D_out), 1.).to_event(1))\n",
    "    weights, rho = params[:-D_out], params[-D_out:]\n",
    "\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "    with pyro.plate(\"data\"):\n",
    "        obs = pyro.sample(\"obs\", dist.MultivariateNormal(loc=mu, \n",
    "                                                         covariance_matrix=torch.diag(F.softplus(rho) ** 2)), obs=y)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def KDE_guide(x, y=None, weight_samples=None, in_size=D_in, num_nodes=10, out_size=1, ELBO_BETA=None):\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    iso_noise = pyro.param(\"iso_noise\", torch.tensor(1e-5), constraint=dist.constraints.positive)\n",
    "    assignment = dist.Categorical(probs=torch.ones(weight_samples.shape[0])).sample()\n",
    "\n",
    "    # sample assigmnent\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(weight_samples[assignment], iso_noise).to_event(1))\n",
    "\n",
    "    weights, rho = params[:-1], params[-1]\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "def make_empirical_gmm(samples, num_nodes, x_test):\n",
    "    rho_noise = samples['params'][:, -D_out:]\n",
    "    noise = F.softplus(rho_noise) ** 2\n",
    "    preds_dict = Predictive(regression_model, samples, return_sites=['_RETURN'])(x_test, None, num_nodes=num_nodes,\n",
    "                                                                                 in_size=D_in, out_size=D_out)\n",
    "    preds = preds_dict['_RETURN']\n",
    "    mix = dist.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = dist.MultivariateNormal(loc=preds.squeeze().permute(1, 0, 2), covariance_matrix=torch.diag_embed(noise))\n",
    "    gmm = dist.MixtureSameFamily(mix, comp)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e035560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deterministic_regression_model(nn.Module):\n",
    "    def __init__(self, params, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(deterministic_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "        weights, rho = params[:-out_size], params[-out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes *self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx +self.out_size].reshape(self.out_size)\n",
    "        idx +=self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params\n",
    "\n",
    "        # compute forward pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def weight_prior_lp(self):\n",
    "        return dist.Normal(loc=0., scale=1.).log_prob(self.params).mean()\n",
    "    \n",
    "    def data_likelihood(self, x, y):\n",
    "        likelihood = dist.Normal(loc=self.forward(x),\n",
    "                              scale=F.softplus(self.rho))\n",
    "        return likelihood.log_prob(y).sum(-1).mean()\n",
    "    \n",
    "    def joint_log_prob(self, x, y):\n",
    "        return self.data_likelihood(x, y) + self.weight_prior_lp(x, y)\n",
    "    \n",
    "    def make_weights_from_sample(self, params):\n",
    "        weights, rho = params[:-self.out_size], params[-self.out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes * self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx + self.out_size].reshape(self.out_size)\n",
    "        idx += self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aef7f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 2000/2000 [00:11, 177.37it/s, step size=3.65e-01, acc. prob=0.877]\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(10)\n",
    "ELBO_BETA = 1.\n",
    "S=2\n",
    "in_size = x_train.shape[-1]\n",
    "num_nodes = 3\n",
    "\n",
    "# run HMC\n",
    "kernel = HMC(regression_model, step_size=0.001, num_steps=5, target_accept_prob=0.8)\n",
    "nuts_kernel = NUTS(regression_model, step_size=0.1, target_accept_prob=0.5, max_tree_depth=5)\n",
    "mcmc = MCMC(kernel, num_samples=1000, warmup_steps=1000, num_chains=1)\n",
    "mcmc.run(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d708ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py:81: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n"
     ]
    }
   ],
   "source": [
    "full_samples = mcmc.get_samples(50)\n",
    "from pyro.infer import Predictive\n",
    "pred = Predictive(regression_model, full_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "HMC_RMSE = ((pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37458d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d78b444a84433c8a60fc1be50c54f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "scheduler = pyro.optim.ExponentialLR({'optimizer': optimizer, 'optim_args': {'lr': 1}, 'gamma': .95})\n",
    "# train KDE\n",
    "svi = SVI(regression_model, KDE_guide, scheduler, loss=TraceMeanField_ELBO())\n",
    "\n",
    "num_iterations = 1000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train[S], y_train[S], full_samples['params'], \n",
    "                    ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "    scheduler.step()\n",
    "kde_noise = pyro.param(\"iso_noise\")\n",
    "flattened_params = full_samples['params']\n",
    "kde_mix = dist.Categorical(probs=torch.ones(flattened_params.shape[0]))\n",
    "kde_comps = dist.MultivariateNormal(loc=flattened_params,\n",
    "                                    covariance_matrix=kde_noise * torch.eye(flattened_params.shape[-1]))\n",
    "kde = dist.MixtureSameFamily(kde_mix, kde_comps)\n",
    "prior = dist.MultivariateNormal(loc=torch.ones_like(flattened_params[0]),\n",
    "                                covariance_matrix=torch.eye(flattened_params[0].shape[-1]))\n",
    "kl_kde_prior = kl_estimate_with_mc(kde, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3358f2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0273, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de2bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe984165f10>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d153c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_sample = kde.sample((50,))\n",
    "kde_samples = {\"params\" : kde_sample}\n",
    "kde_pred = Predictive(regression_model, kde_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                     out_size=D_out)\n",
    "KDE_RMSE = ((kde_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9686482504e94609ba0e2f120d36d9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "# train Factored Gaussian approx\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(regression_model)\n",
    "svi = SVI(regression_model, guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_iterations = 50000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = params\n",
    "variational_posterior = dist.MultivariateNormal(loc=means, covariance_matrix=torch.diag(stds ** 2))\n",
    "variational_sample = variational_posterior.sample((50,))\n",
    "variational_samples = {\"params\" : variational_sample}\n",
    "kl_var_prior = kl_estimate_with_mc(variational_posterior, prior)\n",
    "var_pred = Predictive(regression_model, variational_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)\n",
    "VAR_RMSE = ((var_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1b1d81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final KLs are: KDE 138.1443328857422, VAR 154.51126098632812\n",
      "The final RMSE are: HMC 4.825972557067871, KDE 4.6923089027404785, VAR 4.7866740226745605\n",
      "The final LLs are: HMC -6.9673285484313965, KDE -5.817266464233398, VAR -6.645021915435791.\n"
     ]
    }
   ],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_test[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_test[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_test[S]).mean()}, KDE {kde_gmm.log_prob(y_test[S]).mean()}, VAR {var_gmm.log_prob(y_test[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80c0db5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final KLs are: KDE 138.1443328857422, VAR 154.51126098632812\n",
      "The final RMSE are: HMC 4.825972557067871, KDE 4.6923089027404785, VAR 4.7866740226745605\n",
      "The final LLs are: HMC -5.025341987609863, KDE -5.350659370422363, VAR -4.59866189956665.\n"
     ]
    }
   ],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_train[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_train[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_train[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_train[S]).mean()}, KDE {kde_gmm.log_prob(y_train[S]).mean()}, VAR {var_gmm.log_prob(y_train[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a0740",
   "metadata": {},
   "source": [
    "# Compress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd607f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f50d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = deterministic_regression_model(full_samples['params'][10], in_size=D_in, num_nodes=num_nodes, out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = full_samples['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9bff399",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p = kl_kde_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac21b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = samples.mean(0)\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1.\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0daa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dummy_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c846557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579835ea1ed049bea1457cde72f331e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8746ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = torch.zeros([0])\n",
    "for w in compressed_weights_emp_low_eps:\n",
    "    weight_samples = torch.cat([weight_samples, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1db1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = {'params':weight_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a788fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "757c7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm = make_empirical_gmm(weight_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed7a7c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.7810)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67ccf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE_BNN import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cb6fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_target = kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ef5aa64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3253d794daad42e889b7c8e7b47542b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train[S],\n",
    "                         y_data=y_train[S],\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1.,\n",
    "                        total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d35f9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    weight_samples_kde = torch.cat([weight_samples_kde, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07405071",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = {'params':weight_samples_kde}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f4c4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_kde, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb968dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde = make_empirical_gmm(weight_samples_kde, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e39de99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.7875)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_gmm_kde.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "229d5f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.1485)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_gmm_kde_train = make_empirical_gmm(weight_samples_kde, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_kde_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f1203",
   "metadata": {},
   "source": [
    "# Variational Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80be3c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The mean loss is 384.68091. The mean KL is: 4.26754: 100%|██████████| 1000/1000 [38:29<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1.)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d62d0a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b7038f8fc349ed9e5da37780601dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7ed45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = torch.zeros([0])\n",
    "for w in compressed_weights_var_high_eps:\n",
    "    weight_samples_var = torch.cat([weight_samples_var, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eef3e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = {'params':weight_samples_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a1f35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_var, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13af2ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.7766)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_gmm_var = make_empirical_gmm(weight_samples_var, num_nodes, x_test[S])\n",
    "\n",
    "compressed_gmm_var.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64e91fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.5742)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_gmm_var_train = make_empirical_gmm(weight_samples_var, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_var_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23d44aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(full_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/full_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kde_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(variational_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/variational_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_kde, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_emp_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_var, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_var_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_kde_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_kl_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_var_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/var_kl_split{S}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f6844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
