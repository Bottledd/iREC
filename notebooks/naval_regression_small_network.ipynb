{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1aa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "np.random.seed(0)\n",
    "# np.random.seed(0)\n",
    "#!wget http://archive.ics.uci.edu/ml/machine-learning-databases/00316/UCI%20CBM%20Dataset.zip\n",
    "zipped = zipfile.ZipFile(\"UCI CBM Dataset.zip\")\n",
    "data = np.loadtxt(zipped.open('UCI CBM Dataset/data.txt'), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240997c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from torch import nn\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import HMC, MCMC, SVI, NUTS, TraceMeanField_ELBO\n",
    "from pyro import poutine\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange\n",
    "from rec.utils import kl_estimate_with_mc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c84bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = data[:, :-2]\n",
    "y_ = data[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f476367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_idxs = []\n",
    "for d in range(x_.shape[-1]):\n",
    "    sorted_x = np.argsort(x_[:,d], axis=-1)\n",
    "    total_points = sorted_x.shape[0]\n",
    "    lower_third = total_points // 3\n",
    "    upper_third = total_points * 2 // 3\n",
    "    test_index = sorted_x[lower_third: upper_third]\n",
    "    test_splits_idxs.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6b102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_x, test_splits_y = [], []\n",
    "train_splits_x, train_splits_y = [], []\n",
    "for d in range(x_.shape[-1]):\n",
    "    a = np.arange(x_.shape[0])\n",
    "    test_index = test_splits_idxs[d]\n",
    "    train_index = np.delete(a, test_index, axis=0)\n",
    "    x_train = x_[train_index]\n",
    "    y_train = y_[train_index]\n",
    "    x_test = x_[test_index][:]\n",
    "    y_test = y_[test_index][:]\n",
    "    x_m = x_train.mean(0)\n",
    "    x_s = x_train.std(0)\n",
    "    # 8th dim in this problem has equal values\n",
    "    x_s[8] = 1\n",
    "    x_train = (x_train - x_m) / x_s\n",
    "    x_test = (x_test - x_m) / x_s\n",
    "    test_splits_x.append(x_test)\n",
    "    test_splits_y.append(y_test)\n",
    "    train_splits_x.append(x_train)\n",
    "    train_splits_y.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2b3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = x_train.shape[-1]\n",
    "D_out = y_test.shape[-1]\n",
    "x_train = torch.FloatTensor(np.array(train_splits_x))\n",
    "y_train = torch.FloatTensor(np.array(train_splits_y))\n",
    "x_test= torch.FloatTensor(np.array(test_splits_x))\n",
    "y_test = torch.FloatTensor(np.array(test_splits_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfbdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(x, y=None, weight_samples=None, in_size=1, num_nodes=10, out_size=1, ELBO_BETA=1.):\n",
    "    # sample vector of weights for regression\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    # sample params\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(torch.zeros(total_weights + D_out), 1.).to_event(1))\n",
    "    weights, rho = params[:-D_out], params[-D_out:]\n",
    "\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    \n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) #+ fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "    \n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "\n",
    "    with pyro.plate(\"data\"):\n",
    "        obs = pyro.sample(\"obs\", dist.MultivariateNormal(loc=mu, \n",
    "                                                         covariance_matrix=torch.diag(F.softplus(rho) ** 2)), obs=y)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def KDE_guide(x, y=None, weight_samples=None, in_size=D_in, num_nodes=10, out_size=1, ELBO_BETA=None):\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    iso_noise = pyro.param(\"iso_noise\", torch.tensor(1e-5), constraint=dist.constraints.positive)\n",
    "    assignment = dist.Categorical(probs=torch.ones(weight_samples.shape[0])).sample()\n",
    "\n",
    "    # sample assigmnent\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(weight_samples[assignment], iso_noise).to_event(1))\n",
    "\n",
    "    weights, rho = params[:-D_out], params[-D_out:]\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x)  + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "def make_empirical_gmm(samples, num_nodes, x_test):\n",
    "    rho_noise = samples['params'][:, -D_out:]\n",
    "    noise = F.softplus(rho_noise) ** 2\n",
    "    preds_dict = Predictive(regression_model, samples, return_sites=['_RETURN'])(x_test, None, num_nodes=num_nodes,\n",
    "                                                                                 in_size=D_in, out_size=D_out)\n",
    "    preds = preds_dict['_RETURN']\n",
    "    mix = dist.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = dist.MultivariateNormal(loc=preds.squeeze().permute(1, 0, 2), covariance_matrix=torch.diag_embed(noise))\n",
    "    gmm = dist.MixtureSameFamily(mix, comp)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e035560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deterministic_regression_model(nn.Module):\n",
    "    def __init__(self, params, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(deterministic_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "        weights, rho = params[:-out_size], params[-out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes *self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx +self.out_size].reshape(self.out_size)\n",
    "        idx +=self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params\n",
    "\n",
    "        # compute forward pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def weight_prior_lp(self):\n",
    "        return dist.Normal(loc=0., scale=1.).log_prob(self.params).mean()\n",
    "    \n",
    "    def data_likelihood(self, x, y):\n",
    "        likelihood = dist.Normal(loc=self.forward(x),\n",
    "                              scale=F.softplus(self.rho))\n",
    "        return likelihood.log_prob(y).sum(-1).mean()\n",
    "    \n",
    "    def joint_log_prob(self, x, y):\n",
    "        return self.data_likelihood(x, y) + self.weight_prior_lp(x, y)\n",
    "    \n",
    "    def make_weights_from_sample(self, params):\n",
    "        weights, rho = params[:-self.out_size], params[-self.out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes * self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx + self.out_size].reshape(self.out_size)\n",
    "        idx += self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0aef7f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 2000/2000 [00:06, 294.60it/s, step size=7.03e-02, acc. prob=0.186]\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(0)\n",
    "ELBO_BETA = 1.\n",
    "S=0\n",
    "in_size = x_train.shape[-1]\n",
    "num_nodes = 5\n",
    "\n",
    "# run HMC\n",
    "kernel = HMC(regression_model, step_size=0.001, num_steps=5, target_accept_prob=0.65)\n",
    "nuts_kernel = NUTS(regression_model, step_size=0.1, target_accept_prob=0.5, max_tree_depth=5)\n",
    "mcmc = MCMC(kernel, num_samples=1000, warmup_steps=1000, num_chains=1)\n",
    "mcmc.run(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d708ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_samples = mcmc.get_samples(50)\n",
    "from pyro.infer import Predictive\n",
    "pred = Predictive(regression_model, full_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "HMC_RMSE = ((pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37458d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a3250a59d64bec96916b9fa5e29a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "scheduler = pyro.optim.ExponentialLR({'optimizer': optimizer, 'optim_args': {'lr': 0.5}, 'gamma': .95})\n",
    "# train KDE\n",
    "svi = SVI(regression_model, KDE_guide, scheduler, loss=TraceMeanField_ELBO())\n",
    "\n",
    "num_iterations = 10000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    # randomly sample batch of size 64\n",
    "    a = np.arange(x_train[S].shape[0])\n",
    "    random_idxs = np.random.choice(a, size=64, replace=False)\n",
    "    loss = svi.step(x_train[S][random_idxs], weight_samples=full_samples['params'], y=y_train[S][random_idxs], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "    scheduler.step()\n",
    "kde_noise = pyro.param(\"iso_noise\")\n",
    "flattened_params = full_samples['params']\n",
    "kde_mix = dist.Categorical(probs=torch.ones(flattened_params.shape[0]))\n",
    "kde_comps = dist.MultivariateNormal(loc=flattened_params,\n",
    "                                    covariance_matrix=kde_noise * torch.eye(flattened_params.shape[-1]))\n",
    "kde = dist.MixtureSameFamily(kde_mix, kde_comps)\n",
    "prior = dist.MultivariateNormal(loc=torch.zeros_like(flattened_params[0]),\n",
    "                                covariance_matrix=torch.eye(flattened_params[0].shape[-1]))\n",
    "kl_kde_prior = kl_estimate_with_mc(kde, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3358f2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0065, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3de2bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb24eb61460>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzhElEQVR4nO2deZwU1bXHf0dQ1ChuYERAhygugBplRNwNGEUwwifv+R5Go0+JJIh5ms2AxO1FIolbIm4xqIiiiEHFSEBlUQQGhmEdBmZgYIaZYYbZmBlmX7rP+6Oqh56e7q6la+vq8+UzH6pv3bp1btWtU6fOvfdcYmYIgiAIqcNRbgsgCIIgOIsofkEQhBRDFL8gCEKKIYpfEAQhxRDFLwiCkGL0dFsALfr06cNpaWluiyEIgpBUbNq0qYqZ+0bb53nFn5aWhqysLLfFEARBSCqIaH+sfeLqEQRBSDFE8QuCIKQYovgFQRBSDFH8giAIKYYofkEQhBRDFL8gCEKKIYpfEAQhxRDFL9jKur1V2FfZ4LYYgiCE4fkJXEJy85N/bAAAFM4a57IkgiCEEItfEAQhxRDFLwiCkGKI4hcEQUgxRPELgiCkGKL4BUEQUgxR/IIgCCmGKH5BEIQUQxS/IAhCiiGKXxAEIcXQVPxENJCIVhHRLiLKIaKHIvb/loiYiPqEpU0nonwiyiOim8PShxNRtrrvJSIia6sjCIIgaKHH4u8A8BtmvhDASABTiWgIoLwUAPwQQFEos7pvIoChAMYAeJWIeqi7XwMwGcBg9W+MRfUQBEEQdKKp+Jm5jJk3q9v1AHYB6K/ufhHAIwA47JDxABYwcyszFwDIBzCCiPoB6M3MGczMAOYBmGBZTQRBEARdGPLxE1EagEsBbCCi2wAcYOZtEdn6AygO+12ipvVXtyPTo51nMhFlEVFWZWWlEREFQfA5zIzXvt6Lg3UtbouStOhW/ER0AoBFAB6G4v6ZAeDxaFmjpHGc9O6JzG8wczozp/ft21eviIIgpAB7Kxvw52W5mDJ/k9uiJC26FD8RHQ1F6c9n5o8BnANgEIBtRFQIYACAzUR0BhRLfmDY4QMAlKrpA6KkC4Ig6KYjqNiLTa0BlyVJXvSM6iEAbwLYxcwvAAAzZzPz6cycxsxpUJT6Zcx8EMBnACYSUS8iGgSlEzeTmcsA1BPRSLXMuwEstqdagiAIQiz0WPxXA/gpgFFEtFX9GxsrMzPnAFgIYCeAZQCmMnPo1TwFwBwoHb57ASxNRHjBHYoPNWHkn1bgQG2z26IIgmACzRW4mHkNovvnw/OkRfyeCWBmlHxZAIYZE1HwGgs2FuHg4RZ8srkED44a7LY4giAYRGbuCoKQlHD0sSGCDkTxC4KQVFB8B4SgA1H8giAkFWLpJ44ofkHwKPUt7fh2j0xgjIVY/uYRxS8IHuXhBVvx0zczUX5YZqgK1iKKXxA8yp6KBgBAS7tMVBKsRRS/IAhJifj6zSOKXxCEpEJ8+4kjil8wDYvBJQhJiSh+wTBicQlCciOKXxCEpEJ8+4kjil8QhKREvjzNI4pfEISkRCx/84jiFwQhqRBLP3FE8QuCIKQYovgFQRBSDFH8gqBSWtuMVbkVboshCLYjil8QVG6dvQb3zt3othiCYDui+AXT+G1MxaHGNrdFEARHEMUvGIZkUIUgJDWi+AXDSIweQUhuRPELphHDXxCMUd3Q6rYIAETxC4IgOMLq3ZUY/vRyT4wc01T8RDSQiFYR0S4iyiGih9T0Z4kol4i2E9EnRHRy2DHTiSifiPKI6Oaw9OFElK3ue4lIvMWCEAsJSQB0BIJgn/gWtxbXAgA2F9W4Kwj0WfwdAH7DzBcCGAlgKhENAfAVgGHMfDGA3QCmA4C6byKAoQDGAHiViHqoZb0GYDKAwerfGAvrIgi+JJVDFJw7Yyme+Cwn6j6fvA9cQVPxM3MZM29Wt+sB7ALQn5m/ZOYONdt6AAPU7fEAFjBzKzMXAMgHMIKI+gHozcwZrLzC5wGYYG11BEHwG/My9rstgu8w5OMnojQAlwLYELHrPgBL1e3+AIrD9pWoaf3V7cj0aOeZTERZRJRVWVlpRERB8B3i8omOOIrNo1vxE9EJABYBeJiZD4elz4DiDpofSopyOMdJ757I/AYzpzNzet++ffWKKAi+IpVdPIK99NSTiYiOhqL05zPzx2Hp9wC4FcBoPtIDUwJgYNjhAwCUqukDoqQLSYrYoYKQnOgZ1UMA3gSwi5lfCEsfA+D3AG5j5qawQz4DMJGIehHRICiduJnMXAagnohGqmXeDWCxhXURHEI+sQUvIJ275tFj8V8N4KcAsoloq5r2KICXAPQC8JU6KnM9M/+CmXOIaCGAnVBcQFOZOaAeNwXAXADHQekTCPULCIIg6EIMj8TRVPzMvAbR/fP/jnPMTAAzo6RnARhmREBBEAQ/4YUvFZm5KwiC4ABe+lARxS8IQlLhBYs52RHFLwiCJ9EK1SC+fvOI4hcEISkRy988ovgFQUgqxNJPHFH8giAIKYYofsE08qktCMmJKH7BMPKlLTiBGBb24VvFX1rbjIr6FrfFEARB6IIXoq36VvHf/VYmnoyxgIMgCEIq41vFT5BPRbuQy+oMXrAMU52yumbLy/RCuG3/Kn4SxW83MqzOGbygKFKR9fuqceUzK7F46wG3RbEc/yp+kFhMgpDEuP305pYp601t3u/+4uhW41/FLxa/IAhCVHyr+AH3LQZBEAQv4lvFT0Ri8QuCTazYVY6axjZXZZDH2zz+VfwApGnYi7xYU5OaxjZMeicLk9/NcuX8yd7V7YW+R/8qfvHx20ayP3jJhhcURTjtgSAAoLC6SSNnYsQKy+ytq6EfL42C87fid1sIQVD5Iucg0qYtQU5pHTpUxamFDOOMj1wd8/hX8YM0F3IQ7GVPeb3bIniGd9YVAgDGvbQGT/5LZpQL7uJfxS8Wv+sUVDW6LYInKKlpwrq91Z2/V+VWuiiNYCUH61rwZc5Bt8UwjH8VP8THL3iDH81e47YISYnW4+uFx/vHr67F5Hc3uS2GYXyr+EHkiYYhCDVN7W6LYAtuGVZe8u2X1iVnBGBNxU9EA4loFRHtIqIcInpITT+ViL4ioj3q/6eEHTOdiPKJKI+Ibg5LH05E2eq+l4js6+dWLH5R/YJgOV7SvIIp9Fj8HQB+w8wXAhgJYCoRDQEwDcAKZh4MYIX6G+q+iQCGAhgD4FUi6qGW9RqAyQAGq39jLKxLF7w0dEoQBOsQcy5xNBU/M5cx82Z1ux7ALgD9AYwH8I6a7R0AE9Tt8QAWMHMrMxcAyAcwgoj6AejNzBmsmOLzwo6xHPHxJxfBIOse5ih4i8Mt7Sg+ZO+Y/mgkq23nBb1kyMdPRGkALgWwAcB3mbkMUF4OAE5Xs/UHUBx2WIma1l/djkyPdp7JRJRFRFmVleZGQBBJdE67sfL63jlnA86dsdSy8gTnGP/yWlz7l1WWl6ulIO1+urXKLz9szL9vo2fbMLoVPxGdAGARgIeZ+XC8rFHSOE5690TmN5g5nZnT+/btq1fEbkJ44c3qS3Q2YCMNPWNftXYmwZM4PWzXafUZqx1/lFUcNd0ozW0BS8oxgi7FT0RHQ1H685n5YzW5XHXfQP2/Qk0vATAw7PABAErV9AFR0m3BzZANq3Ir8HOX4pgIgqDN+n3VqNBpsVs1SCRaOTmldbjw8WX4d3aZJefQi55RPQTgTQC7mPmFsF2fAbhH3b4HwOKw9IlE1IuIBkHpxM1U3UH1RDRSLfPusGMsx82FWO6duxFf5JS7cm5BsIILH1uGt9cWxM3T0h7AvIxCS8/7x8934uEFWywtM5yK+hYcrGvBxDfWY+xL38bNa9eXRfgHxI4DdQCAr/MqYuS2h5468lwN4KcAsoloq5r2KIBZABYS0SQARQBuBwBmziGihQB2QhkRNJWZQ98yUwDMBXAcgKXqnz1IkDYhyXGzj6q5PYCn/rUT9149qNu+UAyhhtYOPL7Y2vATb65RXjZ/nXippeWGGDFzRed2VYO7YaXdRFPxM/MaxH75jY5xzEwAM6OkZwEYZkRAsxBk2JfgHh2BIG7/ewZ+/cPzEi7La8HanHohyeAM+/DtzF0Szd+Nf6zeh/vmbky8IPmU0qSqoQ1bimrx24+2uS1K0uOhwTC+wb+K32NWkheY+e9dWJlrnS8x0Wvc3BbAXXM2IL+iwSKJBEHQg28VPyCfil4nY18V1uRXYeaSnW6L4ita2gP4ILPINyFLvFoNs+PyvVAfPZ27SYmswCWkKi9+tRt/X70PJx13NMZe1M9tcQSVaC8Kt3SUby1+icdvP/JF5U2q1UXQG1o7bCnfKTdqshtuB2qb8bfle3R9eTntmvav4pcVuOxDetsEHTy+eAfSpi1JuJxkbW5T3tuEF5fv9mQflr9dPW4LYZD752Wh30nHorS2Ba/eeRmO6enb93LKYMT2qKhvQXuA0f/k4+wTyEHmZey3tXyvG3ahUAxelNK3ih9Ivk/Fr3Yeme27vaQW6WmnuiiNkAhmrNTQ5KLCWeMslsZfJOsXgJfwrUlJsgJX0pAs94mZsXjrAbR1OBs+WvpSupJsBp0X8a/iB1K2hXy1sxzbS2rdFkOzuyrZ5lp8ubMcDy3Yitkr9zhyvmS7Pk7jpTDHyYZ/FX8S+vit4v55Wbjt5bUJl7NiVzla2p0PGetVapuU0TJG47ALieGWejeiP7ze3xCJfxU//Gnwl9U1o92Blaq2Ftdi0jtZeFomVwkRpJqhneiXRaQe8oJa8q/i92HrbGjtwJXPrMQfPtkRN48V1DW3AwD2Vzu/pJ4ghBNLUXrdyvayCvKt4gf81ynWpCr1lXFid1c3tDoljuBTRKF2xevXwwy+VfzJ7urxsrUQwu01UQV/4/bzmwSPoGn8q/hTNFaPE3X28wPhJMnace70cxXZ3pL9ufbC8+NbxQ/IOH7Bu2zaX4MLHluGb3ZX2ncSnz8AXu/H8/ILyreKX7H4PXzlUwAvPpaV9a0oqXG/wzqr8BAAYG1+Vcw8Xu2j8ri+dYV4qibe9XLrDvtX8bstQIKEGlLxoSakTVuCnNK6bvtSgZb2ABotjDJ5+czluObPqywrzwkaWjtw3oylqDA6f8CChyC/oj7xQmwiWQw7PWI6/TL1r+L3iY9/xS4lfs/CjcW2vs22FtdiVZzRQm5xzZ9XYegTX7gthmmsaIJT3tuMtkAQI/60Qjuzxdz4wmrHzwkAgSDH/OKxQ0keamxD2rQl+HTLAcvKjCWnF9SSfxU/yLOfynpw2gKY8Mpa3Pu2BevxmiDeC7oqSYenWnn7rPzi0YPXDCYnfPn7KpXQye+utzeiaCS7yg47er4Q/lX8PrH4jbDjQB3ezyxyWwz9RHmeb399nWc/4T0qlpDE2B26Oha+DcucirF6bp29xrKyYinfu9/KxGobR6JsLKxBkIEeyd5JoxOvvuS8hFevUTJ3cmta/ET0FhFVENGOsLTvE9F6ItpKRFlENCJs33QiyieiPCK6OSx9OBFlq/teIpu/3/wW2dArTT9c6Sdzww/nQG1z56IZ8bCyvn65dqlGS3vAlheR0+82Pa6euQDGRKT9BcBTzPx9AI+rv0FEQwBMBDBUPeZVIuqhHvMagMkABqt/kWVajlctBSNEfz/aXy8972Wty5ssyu3qWStx79xMt8XQhZ4XlN2syjU2CKCpzXgfBTNbpgxb2gO6J8vF0xl1ze244LFl+NuK7mG5k03TaCp+Zl4N4FBkMoDe6vZJAErV7fEAFjBzKzMXAMgHMIKI+gHozcwZrFzZeQAmWCB/bHS4eoJBNhzb5v0NRfjxq4mHPNZDfkU9NhRUd/526yvmw41FmDwvy7bytxTV2Fa2Xtbvi2zi3iH8BXqg1v05CL/75/ao6ZX1rVEV55DH9Y3KirU2baLOgfSnl+OCx5bFzRPtFJE1OaQuYm905I+eQSZOG0lmffwPA/iCiJ6D8vK4Sk3vD2B9WL4SNa1d3Y5MjwoRTYbydYCzzjrLlIDKQizx88xemY8Xl+/G+umjccZJx+oq99FPsk3JYxzqNpTOrVFKv19kb50Ptzg7asVJrLFak+PT6fKZyzHrxxdh4gjjz2xHIIgbX/jGBqkSj1gb+eLRe0u97G42O6pnCoBfMfNAAL8C8KaaHssvYchfwcxvMHM6M6f37dvXlIChpRfX5VehrK45ap4VucoY+eRbWMO7DcoK/OCiS1Uy9lVrZ4pCIAnuuZ+eOrOK/x4AH6vbHwEIde6WABgYlm8AFDdQibodmW4bSnROxk/mbMDNLzo3CcUupZUEz0U3klFmq0mWfo5w5LZZQ+gLvfhQc5c+Bi88F2YVfymA69XtUQBCvR2fAZhIRL2IaBCUTtxMZi4DUE9EI9XRPHcDWJyA3JqED+f0nyvBAy1HcJDUvN9atbbjqkQrM1Fj7v55WfjfD7Z4ygjQM5zzAwAZAM4nohIimgTgfgDPE9E2AH+C6o9n5hwACwHsBLAMwFRmDr3qpgCYA6XDdy+ApRbXpavc8Mab1SyR7qlPthww7DOcOn8zPkimCV1CVMLbsaE27dH2n3ewHi+HLVifU1qHB97bHDN/91bvjAa18izhUVidnokdDc3OXWa+I8au4THyzwQwM0p6FoBhhqRLAMXH73zLt+pl8+D7W7r8NtNBtSS7DEuyy3CHic42K3Dbwnl88Q5UN7ThlTsvc+ycT3++E5cPOhWXDjw54bLMdg56yLCMyoRX1qK5PYAxw87AuaefiIcXbMWeGCN6omPfc63n2pl5xls7jqyT/e76/fjjBMdUYVT8G7IB+m+QRw0jIUHmZezHkuwyR885Z00Bfv7upoTK+NHsNV1e9EZfoFa35+ySOu1MoXPrOHlLh+IEmPDKOuUYU1I5/4KLG145SsWNvLglOqdV6IjVY8e19stLREbWdMfMJdFcnjLK/uwDdcgsMDc6pgsWNfBmm1YK0/qK9Vsb9FJ1fKv49bxttxmwZFKVeJNnEm3Hyfpg67LkNLKEl5GsSzCapftSit3bgVstIzlbpHF8q/itpqU90Dlzz22c1Jd2KufJ84y5RDoCQU8oSSv7jjL2VeOCx5Zh3d7YK3H5DavCdFnbMr3eM2ItvlX8RpZeDOrId/vrGbjsj19p5rNTUTrpB3QiBnpHMPa1amzt6Kbk7/jHes2p93ZixyXJKVXisW+ICBnBHP6COXLieEs1WkVkG7a63keFlTf2b99ib2WjwRLiC1Tf0o7tJbWG5dJL6L54eWauFv5V/NBvEQTjKKAQ2Qf86RZal1+lq/5OM/SJL3D9s12XSNxY6H5MH7uIdwfCFW+1jV+dRdVNaA8EtTOaIL+iHmnTlqCwqrGLwtxpw0IkP393E257ea3lX4d2KnovRudMSpJhIZai6iZXoy2uzC3HT+ZswD++3WdL+WYtxdBtKz9s3epb+RX1OG+GrVNHbMMJu/JQYxuue3YVHl+cY0v5izYrgc2WZJfpbhdmH98tRbUA9H3Jm8FssW4Pbw7Hv4o/YunFhtYOHKiNHrPHSoy0ieueXeVqOOCyOiVGUWG1+xEf7WZhVgnaDFizVQ2tKKlx8LpEaBOnjZb6lnYA0V1JZvRVbVPsLxM9CjC8/t3zx784ifTBxLvucYdzGsyfSF4r8PcKXGF3Y5i6YHfhrHFR87qFkXDAXv+CCaeuuR33zbUvlLPdpD+9HACw/cmb0PvYow0f3xEI3Sx9Ny1eLrdvu5nzPzA/9kxcq4j12IaeE6tdM0afPy8/r/61+FNk6cXZK/bgD5/aFza5st6cu+WLnINdfv9m4TbkHay3QiRTmFUBa/ccsYCNhKd++MOths4TqSTCjRHTIRssZMeBOkydvxkBnf1BRYfs/1qy41J0ue42lO8VfKv4AXLlIen6kFo84CyK9nr+q914b32i8Xhiy5lrVllHFLlocwkefN8aK3Bbca0nO6TDySwwtrBLpHsiVtMJz/eP1fuQNm0JWjvM9RM9/flO3PHGeu2MAB58fzOWZJfpVuh1Te0x9yVuiTv7iR4a4eYlH32i+Fbxk56VWFIcrw5H03pfjn9lLd4w2iEdUdWXV+7Bvx0J56DvGpvxLb/2zV4AQEOs6LMa13HOmoKo8fMjDzPSSkLH1kfMyg0vQ3fnLnf93yh2KepOV5I3Hx9d+Ffxw0CsHgvfD26tkmU1y3Yc1M4UATPjn5tKlAWpbb4OibqNnvtytyN+aCswql+8ro90BUILaz9Oxioyogui5V2+sxwVCSzs1BEI4oucg7bPavet4rcSo+vyavHVzvK4ox68wIcbjbuPvtldid9+tA2zlubaIFFXPtlyAAfr9D9gpiNdErBoUwmKbB75FPmYM5QFPPxCeP2MTg50wmVrhfUeDDJ+Ni8L/63TfRYhAQDgjW/34efvburWR2Y1vlX8Rjp3tW76cHWERzwWbixGlY4XxKHGNtw/L8twuAIv8OrX+XH3v7OuEABQ2dDqyMN679yNuvMm8mD/5qNtGP/KmiNlmXJ+GJMnNLzSzBmsvvRWuzQSL8/Zr2o91rcy01phf7UyE9nMcpIHapSXfWWDvYahfxU/yLEgYCU1TXhk0Xb84t1NMRVeS3sAf/g0u/PlsP+Q0WnqR3ArONpfluXF3b8q78hiE05ceSe/mmridFZaQeQt0TODVlN/uuDzIUAzppVRsQy3JYsaX6Scdc3G2kB+xBoDXupT8/c4fofO1a6O2Y5n8S/ILMJ764sSCvRmVbMJMtBDK3pkAlOfdxyoQ7kBN0yyYUf/xetqR60TPP9lHtJO+46hY/TWuLC6MWpMq66du4lO3e1+/NtrC3DlOafhgjN66yvbBLfOXqOdKUnwr+KHvZ27Fz3xBbKfull3/tDow6BqyDn99jfqo05Euv3VTdifgE/cLx3kVqGlJ42239kr47vsEkHPfbdjNMxT/9oJQJmgmdDMXQN5Y9XDktYrnbvmIErc1RNvrHjkcDWv89bagpj7vDzDMB7x5M492DX4l3c+svWhxzCIpXjsmCjn9PXbFBGQb1Veha0hucPr1xEI4tFPsg2HeLHiGjk1RNS3Fj+Q2Jt3bX4V7pyzAe9NuiJmnua2AI47pkfn74bWgKZv1gvWrPJCpLiNLF7I5GTgWY3+CP3EvkjBIKO4pglnq24Tu/qUwoPVac3irW5oTTiSrBcMgSXZZRh65kkAgECQce/bG3HnFWdhVW6FLUZXqMqNrR34aFMJ3t+Q6KRIb+Njix9xNf/eyiMdL9GyzVVHqNz15oaYZfx5Wddhi1UNrbjoyS9jywNvPFReZ5qB0Ah6scOSeu2bvbj+2a+xu1yxsD/aVNItj9n7HctA0AoGprWcodsws2nLeH91E0rrWlAfmrAWa3ZzAs9YfkUDpn8cv/3FesFrndYLRl8I/yp+UNzLPPr5b+Ie39qhPaoi1MtvxtJLRBF5ZcnCDptit3+y5YDlZdrRpxIKyxByCeSWdXex2Bk/P4Se5qA3xk509F87oyNf4hGpKEujuF5aOwK2tcNw0qYtibtfj1LXM+DBqUfbt64eIytwRct2lE2+NrdUth3Bp1rajzxwTW36LM1N+2vw3d69MOCU4w2da/6G/d3SvGRBuYFe46GougnXPbsKf/6Pi3DWqcZG81gNEeka1RPtzu6r6j4E+vw/LMPg00+IXobHmsc7Gd3bsFtoKn4iegvArQAqmHlYWPovATwIoAPAEmZ+RE2fDmASgACA/2XmL9T04QDmAjgOwL8BPMQ2mq5OhIEKiZ/oMoWHW9pRYWDRESJC3sF6S62rcPRMRAvn9tfX6V4d6z9eWwcgenjseMz4ZIeh/JG3xEtxVfR0Glr5ZPxhsXLtYkUXLdYReM3KB1Xfs6W/oD0R4+XNYKZ57LJh9TCn2qkeV89cAGPCE4joBwDGA7iYmYcCeE5NHwJgIoCh6jGvElGo9/M1AJMBDFb/upRpB406V7eKdrGPsvAOaIUW+K/XM3DjC/FdT5Hc/NfV+K+/ZyQiVkz0rusaukRuLYkYz33jpLV379vKDGInHtqiQ0342/I9Xb5mtb58ajTcTeUGYsskWkUn3JRO3frFW0sdOpP1aCp+Zl4NIDLG7BQAs5i5Vc1ToaaPB7CAmVuZuQBAPoARRNQPQG9mzlCt/HkAJlhUh6gk+hBasdg4M/CvbaUY+cwKrI+IghheuunQxy6TyBVyJjLmEZwwpKzUabGa35LtZXhx+W6U1rVAs1Z657EYkMtsFcPr46WvLz1E6gJG/KHeVrSDxxbn2Dp81Wzn7nkAriWiDUT0DRFdrqb3B1Aclq9ETeuvbkemR4WIJhNRFhFlVVZWxsoWl1iKe4fOoW56fPx6Xg6b9ivW8K6Ijj8zbeNbdVEQo1bTR1nFcRujG2FvrYiM6YSPP1odQ18aiZx99R59X1WxaGztiOqSi3YvrZgA5oau1pQr5qge+9vFk/+yZ23icAqrzYd10cKs4u8J4BQAIwH8DsBCUrRgtPbBcdKjwsxvMHM6M6f37dvXlICxGmq0adfRO3d1dECpB8ZraJ3DOBHKq1lsTIyu6hTid//c3jk8NZyE+0E8bLpZJZqR+xVvklwkq3crBo1ZOaeGvThb2hIf1fLKqiOzeSNfqOEyNlowXNQpN5xdhgEzsCCzOEr6kfNFTiDUInSNnZrRb1bxlwD4mBUyAQQB9FHTB4blGwCgVE0fECXdPgxcv2iK+yiLBrp2WoccmZ787Cw9jOySxCYLWcWrX+fj8pmxo6g26ezvMYIlMzVNHhfeofnYYmMd39FYmNV9DkI0zMarMa7snR2SE8+IiWY0RRK5OPyYv35rWIayumbDs4XNYla9fQpgFAAQ0XkAjgFQBeAzABOJqBcRDYLSiZvJzGUA6olopPplcDeAxYkKH494Fvuts7VvilWdu92LcX+MWeRDWFxjLq7Omvwq/OhlbwSu+suyvC7rA0fW0c7x5W4Tbl1Ga7ZaSldX2GGjQsVgX1Wj7XMbzMi6pUj/AAW7PnSvfGYlVuZWaGe0AE3FT0QfAMgAcD4RlRDRJABvAfgeEe0AsADAPar1nwNgIYCdAJYBmMrMIVNrCoA5UDp89wJYanltwugZx0m/44D2Z5gRN0asvB3B7rMU7frM3VZca/rYdXuPdDwXVDXioQVbExfIAULX8us87YfF7MPqljfLSDspjzUUOOQ+8MDnZUiGjzfrm5yXyHMSOjZjb/dlJWMRCvJmpHyz+/XyTZ65/k096BnVcwcz92Pmo5l5ADO/ycxtzHwXMw9j5suYeWVY/pnMfA4zn8/MS8PSs9T85zDzg3aO4QesHY4Zi0+3lqI5jgvh07AZqHav0xk5asgsibxA3CJaSGMvKDs9ONFPkiSXohuaCkKjYpHt4pMt0d1ZO0utH49vBc/YuJKdb0M2OKH4AeCvy3fH3NcaCIbF6InsMDMvX6KLgrjlqqiPtSi4hewsPRx1HoIdnWZWXMVYUjn54vKW4+oImus+GxT8Vx9u65bWHggajm/E6r9wyg+36ArzErNMh2+Cr0M2OEG8TsPW9kDnIi0h7LrBCUViMb/miiEOJrAItV7GvqT039x44emWlPfeeu9Ms7eLWptXFzMDszNzPabO34yfXfu9hMu5/tmvce3gPhZI5Ay+tfidnGEYK+/TS3Z1jggI5fCidRU5IiHZiG7Nd00zW69vExxvr4XV7cHMC7wmYgnLyDKYE3+eXlllfIUxJ9riCpOdqdHaXCJtxennzr+K38hwTvX/wqrGuD77aHy586AnlbkeklHJ60ffXVm4sft4bL3YefmcXKHN181AB16Idut0/H8fu3qMN+cbnvsaVww6Fb+44Rx8vl3fZ2b54VZ8vFnfGGjAG43MAyI4Tqzm8Mii7c4KEkHs2O7O3SStMzm5frWV6GnnXnge3cC3Fn9HwNgNXbxVGYGzoeBQZ9AtveiJrBlqX15oZh9k+nt1oWQiVntwI4yGoA9m783lMIpvFf+GAmPDGxMZu65n4ZB40+CdxsiYZS8TZEZ+RawAd10vcPEh62ZEZuyrRvGhJnyz275x1o9/ZkEsmFCT02hsXnxXOKlYvRx6xC586+pxajgnYG59Wqu/MBMpz6lRPVZT1dCGG19YjZOOOzpuvpKaJqzRGWpaD8WHmnHtX1ZZVl402hIYGhiJ1twMTVePZZLox6n2SEQp6e7xrcVvqHPXgfseml35tY2z8azAjpg2dhM9HMORmzrhlXW2y7DZwJR/OzGz0LrmTFSTsiRCXnm9I5a42SUpnex8twPfKn4nLX4zuC1erNg1WgtNJyNGVxQzw49fNfdyscroCEX7fHttYUT52ifQ0xadbq7bS+rixrwHtBeWTz07Xj++VfxuK1avc8lTXyale0c/qdUA7n4rE1uLa7sp+g0FkWsodcer7UDLz19Rb/8LPdZ5k71z17c+/tR67M0Rmrzi1QdfMEZNU1s318VSi2a/utFE1uZbE3/Ki9w6+1vsLk98rWCz+Ffxp5jJb8YCsXNpt2QmtCB8svFlTsRkQp2PgNajklpPkjPoiRBsJ7519ehZOjFEsn+2AUDA4LwFITah5TKTjQ8yi7spaT0GUOQX3w+e+9oymZzmcMuRvquiQ+bWmUgFfKv4jdgppbX2Bw+LxOgEMy2e/yp2lFAhhTDxpbt0R1d3UFmd88+DVTz/RV7ndmV9a0oO1dSDb109W4v1W22//ah7uFa7cSJSpRZ+dodl7dfu1PQ78zIKdfXfhAcXS3YruS3CoFqqFdoZ5vovlOGcyftS8a3ir2qwd3k3P7DaxpmnbuPFUMOOEKbprfIjJ5d66yptqU1r2Ca7e9jHrh5BSD3qDS4qooddZYexvzo5vgQ+yOwabVXPF4/ZSVzJjCh+QfAR+yobLS9zxic7LC/TKfRY5nO+3eeAJN5CFL8gCL5Fj8Vf3Zh6bmFR/IIg+BY9TpygiZE/kUuqJhui+AVB8C16lHoqjvgUxS8Igm/Ro9RzSt2dResGmoqfiN4iogoi6tbDQ0S/JSImoj5hadOJKJ+I8ojo5rD04USUre57ifw8iFwQBMHD6LH45wIYE5lIRAMB/BBAUVjaEAATAQxVj3mViHqou18DMBnAYPWvW5mCIAhW0tRm/fBWP6Cp+Jl5NYBo0yBfBPAIuvafjAewgJlbmbkAQD6AEUTUD0BvZs5gZQ71PAATEhVeEAQhHq+s2uu2CJ7ElI+fiG4DcICZI2Md9AcQPoOiRE3rr25HpscqfzIRZRFRVmWlf2eXCoIguIFhxU9ExwOYAeDxaLujpHGc9Kgw8xvMnM7M6X379jUqoiAIghAHM7F6zgEwCMA2tX92AIDNRDQCiiU/MCzvAAClavqAKOmCIAiCwxi2+Jk5m5lPZ+Y0Zk6DotQvY+aDAD4DMJGIehHRICiduJnMXAagnohGqqN57gaw2LpqdOc/LhugnUkQBCEF0TOc8wMAGQDOJ6ISIpoUKy8z5wBYCGAngGUApjJzaJmnKQDmQOnw3QtgaYKyx2VQn+PtLF4QBMF27FpPQNPVw8x3aOxPi/g9E8DMKPmyAAwzKJ8gCELKwmxqbR1NfDtzt645ReOxC4LgG+yKJuFbxd/WEXRbBEEQhISwy9XjW8V/dA/fVk0QhBRBLH6DnHnycW6LIAiCkBB2RQ71reI/SkLACYIgRMW3il+CfwqCkOzYtai7bxX/UWLyC4KQ5IirxyA9RfELgiBExbeKvz0gwzkFQUhuxOI3yIaCaEsICIIgCL5V/JcOPNltEQRBEBJCOncNcokofkEQkpyguHqMcXnaqW6LIAiCkBBBCdkgCIKQWgRtMvlF8QuCIHgUcfUIgo18t3cvt0UQkpQPJ4+0rexjj7ZHRYvi9wmjLjgdANDnhGNcliQ28392hSXl3HPl2ZaUE86a34/Cl7+6Tlfem4d+F8P69074nD+65MyEy/j8l9egcNa4hMsxw/3XDrKsrLNOjb1iXnj0lQduOMdw2a/fNRzvTboCxxiM2Hvc0T2ipl93Xt/O7dfuvAxXfO80wzLp5fhjzCyLrk3KKP77rx2E3D+OwcrfXA8AeGj04M59u5++pVv+If16o3DWONx3tdK4f3XjeVg7bRRe+cll3fJueHQ0CmeNQ+GscbhjxFkxZdgz8xZkPjoaADD6gtOx46mbcecVZyHnqZtROGscZv34Inx/4MmYd9+Ibseee/oJePOe9E75h/TrjW1P3IS100Yh89HReOt/LkfhrHG4+tw+AID/HD4AP760P1b/7gcAgIsHnNRZ1reP/AD/OXwAHrjhHDw69gIAwFXnnIY9M2/B3j+N7XLerY//EHPuTu+yhvHnv7ymc7vgmbEonDUOvXoqTemxW4fg1ov74evf3oC//vf3sW7aKCyaciXynh6Dq8/tgwd/cC4AoN9Jx+LvPx2OcRf1wynHHx3zml2edgreV18Yvxx1LhZMHoknbxuKXf83Bu9NUtJP7NUThbPGIXPGaNx2yZl4/a6u92jjjBuxfvroLrO5X/zvSzCoz3c66350j6Nw3ndPRN8Te+GXo87FHyfEXixuzLAzMPaifjH3A8C2J27C3Hsvx6IpV+GBG87BB/ePxLRbLujcf+ZJx2L2HZdi2+M34b6rB3WxGi8ZeDLWThvVpbyQwnv+9kuw909jcdU5p+G9SVdgWP+TuuTrfWxPzBh7IbY9cVM3mf5v/FAUzhqHt++9HPdceTYKnhmLM086tlu+s049Hrde3A///MWVnWnZT3Yt78YLT8eMcUNQ8MxYLJpyFe6/dhBGDDoVj469AC/81yWd+dLPPgVXDOo60GLSNYOQ/eRN6HtiL8y7bwQKZ43DN7+7AdlP3oRPHriqM99ztyvlPHXb0M60Wy9WXpbjLu56/d+bdEVnG1/+6+sx6ZpBWPrQtSh4ZizGDDsD1wzug90zb8HyX1+H9392Bc4+TXnRPHyjogd+OepcnNirJ+b/7Ar0P/k4XHDGiXj73ss7yx98+gmd23PuTsfb916OJ340BLeo7WDTH27s3J8xfRQuOOPELvJN+P6ZWD99NK46R3lJvPU/6bgt7MU/ZugZAIAnfjSkMy33j2NgG8zs6b/hw4ezWc7+/ed89u8/j7l/b0U97yk/zMzM+RX1/K9tB7itI8Bltc3c3NbRma+0tqnLcUXVjbx858EueUI0t3XwlzkHua0jwOV1zZxZUM3bims47+BhQ7IfamjljkCQV+WW86GG1i771uVXcU1ja9Tjmts6eHtxbZe0QCDIgUCQ95TXc26Zthw1ja28dk8l17e0d0kP/11Z38LFhxo7fweDQS6satAsm5m5qr6FG1u7lv3Z1gPc1NrBlfUtvKWohrNLann93iqubWqLW1Zdc1u3skJ1CASC3e7RqtxyLqpu7KzD+r1VMcv+Jq+Cc8sO86GGVi6qbuQN+6q5pb2js77Fhxq5+FAj51fU86rccg4Gg9zQ0s5bi2pilpl38HC39hSisbWdV+WWd0nbVVbHeyvqORgM8urdFRwMBqMeu3ZPJS/aVNwl7UBNExdVKzKG5Iuk4nALb9hXzUXVjVzX3Mbr8qu4I3AkX21jG5cfbu78HQgEeV5GYed1iEd1WLttbQ/wh5lFXFnfonlcMBjkw83Kfd9eXMvBYJD3VTZ0tt29FfUcCAS5oLKBi6obO69nQ0t7573VIhAIcsbeqpjXM8SnW0q4tlGRpbG1nfMr6mPmPVDT1OWZKKxq6Dw2RGNre5fnc8Wug1xxuOs1aesI6KqDFgCyOIZeJbZrTrBFpKenc1ZWlqljv86rQGNroJt1IAiC4HeIaBMzp0fbZ48DySPccP7pbosgCILgOVLGxy8IgiAoiOIXBEFIMTQVPxG9RUQVRLQjLO1ZIsolou1E9AkRnRy2bzoR5RNRHhHdHJY+nIiy1X0vkSyRJQiC4Ap6LP65ACLHFX0FYBgzXwxgN4DpAEBEQwBMBDBUPeZVIgoNhn0NwGQAg9U/G8cqCYIgCLHQVPzMvBrAoYi0L5m5Q/25HkBokPd4AAuYuZWZCwDkAxhBRP0A9GbmDHWY0TwAEyyqgyAIgmAAK3z89wFYqm73B1Actq9ETeuvbkemC4IgCA6TkOInohkAOgDMDyVFycZx0mOVO5mIsogoq7KyMhERBUEQhAhMK34iugfArQDu5COzwEoADAzLNgBAqZo+IEp6VJj5DWZOZ+b0vn37xsomCIIgmMDUBC4iGgPg9wCuZ+amsF2fAXifiF4AcCaUTtxMZg4QUT0RjQSwAcDdAGbrOdemTZuqiGi/GTkB9AFQZfLYZEXqnBqkWp1Trb5A4nWOGc1QU/ET0QcAbgDQh4hKADwBZRRPLwBfqaMy1zPzL5g5h4gWAtgJxQU0lZkDalFToIwQOg5Kn8BS6ICZTZv8RJQVa8qyX5E6pwapVudUqy9gb501FT8z3xEl+c04+WcCmBklPQtA7JCHgiAIgiPIzF1BEIQUw++K/w23BXABqXNqkGp1TrX6AjbW2fNhmQVBEARr8bvFLwiCIEQgil8QBCHF8KXiJ6IxanTQfCKa5rY8iUBEA4loFRHtIqIcInpITT+ViL4ioj3q/6eEHZP0EVKJqAcRbSGiz9Xfvq4vABDRyUT0TzXy7S4iutLP9SaiX6ltegcRfUBEx/qtvjGiG1tWRyLqRUQfqukbiChNl2Cx1mRM1j8APQDsBfA9AMcA2AZgiNtyJVCffgAuU7dPhBINdQiAvwCYpqZPA/BndXuIWudeAAap16KHui8TwJVQQmgsBXCL2/WLU+9fA3gfwOfqb1/XV5X3HQA/U7ePAXCyX+sNJVZXAYDj1N8LAfyP3+oL4DoAlwHYEZZmWR0BPADgdXV7IoAPdcnl9oWx4UJfCeCLsN/TAUx3Wy4L67cYwA8B5AHop6b1A5AXrb4AvlCvST8AuWHpdwD4u9v1iVHHAQBWABiFI4rft/VV5eutKkKKSPdlvXEkoOOpUOYTfQ7gJj/WF0BahOK3rI6hPOp2TygzfUlLJj+6emJFCE161M+4S6GEvfguM5cBgPp/aIFhP0RI/SuARwAEw9L8XF9A+UKtBPC26uKaQ0TfgU/rzcwHADwHoAhAGYA6Zv4SPq1vBFbWsfMYVkLl1wE4TUsAPyp+Q5FAkwUiOgHAIgAPM/PheFmjpBmOkOoWRHQrgApm3qT3kChpSVPfMHpCcQm8xsyXAmiE4gaIRVLXW/Vrj4fi0jgTwHeI6K54h0RJS5r66sRMHU3V34+KP1aE0KSFiI6GovTnM/PHanI5KQvcQP2/Qk23JEKqi1wN4DYiKgSwAMAoInoP/q1viBIAJcy8Qf39TygvAr/W+0YABcxcycztAD4GcBX8W99wrKxj5zFE1BPASYhYOCsaflT8GwEMJqJBRHQMlA6Pz1yWyTRq7/2bAHYx8wthuz4DcI+6fQ8U338ofaLa2z8IRyKklgGoJ6KRapl3hx3jGZh5OjMPYOY0KPduJTPfBZ/WNwQzHwRQTETnq0mjoQQ79Gu9iwCMJKLjVTlHA9gF/9Y3HCvrGF7Wf0J5XrS/eNzu+LCpM2UslNEvewHMcFueBOtyDZRPt+0Atqp/Y6H48VYA2KP+f2rYMTPUuuchbIQDgHQAO9R9L0NHJ5DLdb8BRzp3U6G+3weQpd7rTwGc4ud6A3gKQK4q67tQRrP4qr4APoDSh9EOxTqfZGUdARwL4CMoy9xmAvieHrkkZIMgCEKK4UdXjyAIghAHUfyCIAgphih+QRCEFEMUvyAIQoohil8QBCHFEMUvCIKQYojiFwRBSDH+H2N7SlQdPOD2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10d153c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_sample = kde.sample((50,))\n",
    "kde_samples = {\"params\" : kde_sample}\n",
    "kde_pred = Predictive(regression_model, kde_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                     out_size=D_out)\n",
    "KDE_RMSE = ((kde_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a31e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5425f38f74fe41a8955620d382701c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "ELBO_BETA = 1.\n",
    "# train Factored Gaussian approx\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(regression_model)\n",
    "svi = SVI(regression_model, guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_iterations = 50000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    # randomly sample batch of size 64\n",
    "    a = np.arange(x_train[S].shape[0])\n",
    "    random_idxs = np.random.choice(a, size=64, replace=False)\n",
    "    loss = svi.step(x_train[S][random_idxs], y_train[S][random_idxs], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fab2f19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb23a1ca400>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc9a2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = params\n",
    "variational_posterior = dist.MultivariateNormal(loc=means, covariance_matrix=torch.diag(stds ** 2))\n",
    "variational_sample = variational_posterior.sample((50,))\n",
    "variational_samples = {\"params\" : variational_sample}\n",
    "kl_var_prior = kl_estimate_with_mc(variational_posterior, prior)\n",
    "var_pred = Predictive(regression_model, variational_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)\n",
    "VAR_RMSE = ((var_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1b1d81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final KLs are: KDE 717.5315551757812, VAR 103.27446746826172\n",
      "The final RMSE are: HMC 1.7962852716445923, KDE 1.891493558883667, VAR 0.011681713163852692\n",
      "The final LLs are: HMC -3.839434862136841, KDE -4.089629650115967, VAR 6.17456579208374.\n"
     ]
    }
   ],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_test[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_test[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_test[S]).mean()}, KDE {kde_gmm.log_prob(y_test[S]).mean()}, VAR {var_gmm.log_prob(y_test[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80c0db5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final KLs are: KDE 717.5315551757812, VAR 103.27446746826172\n",
      "The final RMSE are: HMC 1.7962852716445923, KDE 1.891493558883667, VAR 0.011681713163852692\n",
      "The final LLs are: HMC -3.814208507537842, KDE -5.461190700531006, VAR 6.170717716217041.\n"
     ]
    }
   ],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_train[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_train[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_train[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_train[S]).mean()}, KDE {kde_gmm.log_prob(y_train[S]).mean()}, VAR {var_gmm.log_prob(y_train[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a0740",
   "metadata": {},
   "source": [
    "# Compress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dd607f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f50d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = deterministic_regression_model(full_samples['params'][10], in_size=D_in, num_nodes=num_nodes, out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad97f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = full_samples['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9bff399",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p = kl_kde_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ac21b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
      "The mean loss is 1240915.87500. The mean KL is: 66.93314:   0%|          | 0/5000 [00:09<?, ?it/s]\u001b[A\n",
      "The mean loss is 1240915.87500. The mean KL is: 66.93314:   0%|          | 1/5000 [00:10<14:02:21, 10.11s/it]\u001b[A\n",
      "The mean loss is 1108877.37500. The mean KL is: 63.71086:   0%|          | 1/5000 [00:20<14:02:21, 10.11s/it]\u001b[A\n",
      "The mean loss is 1108877.37500. The mean KL is: 63.71086:   0%|          | 2/5000 [00:20<14:08:55, 10.19s/it]\u001b[A\n",
      "The mean loss is 980658.37500. The mean KL is: 60.38692:   0%|          | 2/5000 [00:30<14:08:55, 10.19s/it] \u001b[A\n",
      "The mean loss is 980658.37500. The mean KL is: 60.38692:   0%|          | 3/5000 [00:30<14:04:58, 10.15s/it]\u001b[A\n",
      "The mean loss is 862405.68750. The mean KL is: 57.14411:   0%|          | 3/5000 [00:40<14:04:58, 10.15s/it]\u001b[A\n",
      "The mean loss is 862405.68750. The mean KL is: 57.14411:   0%|          | 4/5000 [00:40<14:05:05, 10.15s/it]\u001b[A\n",
      "The mean loss is 797901.25000. The mean KL is: 55.27096:   0%|          | 4/5000 [00:50<14:05:05, 10.15s/it]\u001b[A\n",
      "The mean loss is 797901.25000. The mean KL is: 55.27096:   0%|          | 5/5000 [00:50<14:03:37, 10.13s/it]\u001b[A\n",
      "The mean loss is 699928.37500. The mean KL is: 52.28914:   0%|          | 5/5000 [01:00<14:03:37, 10.13s/it]\u001b[A\n",
      "The mean loss is 699928.37500. The mean KL is: 52.28914:   0%|          | 6/5000 [01:04<14:59:30, 10.81s/it]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-390119e175ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprior_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0memp_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinalJointOptimiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_auxiliaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_q_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trajectories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0maux_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memp_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/km817/iREC/rec/OptimisingVars/FinalJointOptimiser.py\u001b[0m in \u001b[0;36mrun_optimiser\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_auxiliaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m# compute loss for a_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_kl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremaining_kl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mkls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/rec/OptimisingVars/FinalJointOptimiser.py\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(self, index, remaining_kl)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_kl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# kl = kl_estimate_with_mc(self.aux_posterior, self.aux_prior, rsample=True, num_samples=100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0maux_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mkl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maux_kl\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mremaining_kl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_kl\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maux_kl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_auxiliaries\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/rec/OptimisingVars/FinalJointOptimiser.py\u001b[0m in \u001b[0;36maux_posterior\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munscaled_mean\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmean_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_softmax_aux_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvariance_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_kl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mevent_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale_tril\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy_property\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py\u001b[0m in \u001b[0;36m_PositiveDefinite_check\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mflattened_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatrix_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n\u001b[0m\u001b[1;32m     82\u001b[0m                         for v in flattened_value]).view(batch_shape)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mflattened_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatrix_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n\u001b[0m\u001b[1;32m     82\u001b[0m                         for v in flattened_value]).view(batch_shape)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = samples.mean(0)\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1.\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0daa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dummy_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c846557",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = torch.zeros([0])\n",
    "for w in compressed_weights_emp_low_eps:\n",
    "    weight_samples = torch.cat([weight_samples, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = {'params':weight_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm = make_empirical_gmm(weight_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE_BNN import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_target = kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train[S],\n",
    "                         y_data=y_train[S],\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1.,\n",
    "                        total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    weight_samples_kde = torch.cat([weight_samples_kde, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07405071",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = {'params':weight_samples_kde}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_kde, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb968dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde = make_empirical_gmm(weight_samples_kde, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde_train = make_empirical_gmm(weight_samples_kde, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_kde_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f1203",
   "metadata": {},
   "source": [
    "# Variational Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1.)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = torch.zeros([0])\n",
    "for w in compressed_weights_var_high_eps:\n",
    "    weight_samples_var = torch.cat([weight_samples_var, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = {'params':weight_samples_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_var, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var = make_empirical_gmm(weight_samples_var, num_nodes, x_test[S])\n",
    "\n",
    "compressed_gmm_var.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e91fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var_train = make_empirical_gmm(weight_samples_var, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_var_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d44aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(full_samples, open(f\"PickledStuff/BNN_UCI/NAVAL/full_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kde_samples, open(f\"PickledStuff/BNN_UCI/NAVAL/kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(variational_samples, open(f\"PickledStuff/BNN_UCI/NAVAL/variational_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_kde, open(f\"PickledStuff/BNN_UCI/NAVAL/compressed_kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples, open(f\"PickledStuff/BNN_UCI/NAVAL/compressed_emp_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_var, open(f\"PickledStuff/BNN_UCI/NAVAL/compressed_var_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_kde_prior, open(f\"PickledStuff/BNN_UCI/NAVAL/kde_kl_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_var_prior, open(f\"PickledStuff/BNN_UCI/NAVAL/var_kl_split{S}.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
