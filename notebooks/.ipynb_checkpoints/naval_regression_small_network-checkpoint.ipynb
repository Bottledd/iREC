{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1aa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "np.random.seed(0)\n",
    "# np.random.seed(0)\n",
    "#!wget http://archive.ics.uci.edu/ml/machine-learning-databases/00316/UCI%20CBM%20Dataset.zip\n",
    "zipped = zipfile.ZipFile(\"UCI CBM Dataset.zip\")\n",
    "data = np.loadtxt(zipped.open('UCI CBM Dataset/data.txt'), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240997c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from torch import nn\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import HMC, MCMC, SVI, NUTS, TraceMeanField_ELBO\n",
    "from pyro import poutine\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange\n",
    "from rec.utils import kl_estimate_with_mc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c84bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = data[:, :-2]\n",
    "y_ = data[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f476367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_idxs = []\n",
    "for d in range(x_.shape[-1]):\n",
    "    sorted_x = np.argsort(x_[:,d], axis=-1)\n",
    "    total_points = sorted_x.shape[0]\n",
    "    lower_third = total_points // 3\n",
    "    upper_third = total_points * 2 // 3\n",
    "    test_index = sorted_x[lower_third: upper_third]\n",
    "    test_splits_idxs.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6b102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_x, test_splits_y = [], []\n",
    "train_splits_x, train_splits_y = [], []\n",
    "for d in range(x_.shape[-1]):\n",
    "    a = np.arange(x_.shape[0])\n",
    "    test_index = test_splits_idxs[d]\n",
    "    train_index = np.delete(a, test_index, axis=0)\n",
    "    x_train = x_[train_index]\n",
    "    y_train = y_[train_index]\n",
    "    x_test = x_[test_index][:]\n",
    "    y_test = y_[test_index][:]\n",
    "    x_m = x_train.mean(0)\n",
    "    x_s = x_train.std(0)\n",
    "    # 8th dim in this problem has equal values\n",
    "    x_s[8] = 1\n",
    "    x_train = (x_train - x_m) / x_s\n",
    "    x_test = (x_test - x_m) / x_s\n",
    "    test_splits_x.append(x_test)\n",
    "    test_splits_y.append(y_test)\n",
    "    train_splits_x.append(x_train)\n",
    "    train_splits_y.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2b3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = x_train.shape[-1]\n",
    "D_out = y_test.shape[-1]\n",
    "x_train = torch.FloatTensor(np.array(train_splits_x))\n",
    "y_train = torch.FloatTensor(np.array(train_splits_y))\n",
    "x_test= torch.FloatTensor(np.array(test_splits_x))\n",
    "y_test = torch.FloatTensor(np.array(test_splits_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfbdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(x, y=None, weight_samples=None, in_size=1, num_nodes=10, out_size=1, ELBO_BETA=1.):\n",
    "    # sample vector of weights for regression\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    # sample params\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(torch.zeros(total_weights + D_out), 1.).to_event(1))\n",
    "    weights, rho = params[:-D_out], params[-D_out:]\n",
    "\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    \n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) #+ fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "    \n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "\n",
    "    with pyro.plate(\"data\"):\n",
    "        obs = pyro.sample(\"obs\", dist.MultivariateNormal(loc=mu, \n",
    "                                                         covariance_matrix=torch.diag(F.softplus(rho) ** 2)), obs=y)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def KDE_guide(x, y=None, weight_samples=None, in_size=D_in, num_nodes=10, out_size=1, ELBO_BETA=None):\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    iso_noise = pyro.param(\"iso_noise\", torch.tensor(1e-5), constraint=dist.constraints.positive)\n",
    "    assignment = dist.Categorical(probs=torch.ones(weight_samples.shape[0])).sample()\n",
    "\n",
    "    # sample assigmnent\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(weight_samples[assignment], iso_noise).to_event(1))\n",
    "\n",
    "    weights, rho = params[:-D_out], params[-D_out:]\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x)  + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "def make_empirical_gmm(samples, num_nodes, x_test):\n",
    "    rho_noise = samples['params'][:, -D_out:]\n",
    "    noise = F.softplus(rho_noise) ** 2\n",
    "    preds_dict = Predictive(regression_model, samples, return_sites=['_RETURN'])(x_test, None, num_nodes=num_nodes,\n",
    "                                                                                 in_size=D_in, out_size=D_out)\n",
    "    preds = preds_dict['_RETURN']\n",
    "    mix = dist.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = dist.MultivariateNormal(loc=preds.squeeze().permute(1, 0, 2), covariance_matrix=torch.diag_embed(noise))\n",
    "    gmm = dist.MixtureSameFamily(mix, comp)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e035560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deterministic_regression_model(nn.Module):\n",
    "    def __init__(self, params, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(deterministic_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "        weights, rho = params[:-out_size], params[-out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes *self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx +self.out_size].reshape(self.out_size)\n",
    "        idx +=self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params\n",
    "\n",
    "        # compute forward pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def weight_prior_lp(self):\n",
    "        return dist.Normal(loc=0., scale=1.).log_prob(self.params).mean()\n",
    "    \n",
    "    def data_likelihood(self, x, y):\n",
    "        likelihood = dist.Normal(loc=self.forward(x),\n",
    "                              scale=F.softplus(self.rho))\n",
    "        return likelihood.log_prob(y).sum(-1).mean()\n",
    "    \n",
    "    def joint_log_prob(self, x, y):\n",
    "        return self.data_likelihood(x, y) + self.weight_prior_lp(x, y)\n",
    "    \n",
    "    def make_weights_from_sample(self, params):\n",
    "        weights, rho = params[:-self.out_size], params[-self.out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes * self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx + self.out_size].reshape(self.out_size)\n",
    "        idx += self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0aef7f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 2000/2000 [00:05, 360.76it/s, step size=1.49e-02, acc. prob=0.222]\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(0)\n",
    "ELBO_BETA = 1.\n",
    "S=0\n",
    "in_size = x_train.shape[-1]\n",
    "num_nodes = 3\n",
    "\n",
    "# run HMC\n",
    "kernel = HMC(regression_model, step_size=0.001, num_steps=5, target_accept_prob=0.65)\n",
    "nuts_kernel = NUTS(regression_model, step_size=0.1, target_accept_prob=0.5, max_tree_depth=5)\n",
    "mcmc = MCMC(kernel, num_samples=1000, warmup_steps=1000, num_chains=1)\n",
    "mcmc.run(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d708ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   2%|▏         | 37/2000 [36:49, 59.72s/it, step size=6.49e-05, acc. prob=0.641]\n"
     ]
    }
   ],
   "source": [
    "full_samples = mcmc.get_samples(50)\n",
    "from pyro.infer import Predictive\n",
    "pred = Predictive(regression_model, full_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "HMC_RMSE = ((pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37458d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5463813ff54b71aecbec47536d6e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "scheduler = pyro.optim.ExponentialLR({'optimizer': optimizer, 'optim_args': {'lr': 0.5}, 'gamma': .95})\n",
    "# train KDE\n",
    "svi = SVI(regression_model, KDE_guide, scheduler, loss=TraceMeanField_ELBO())\n",
    "\n",
    "num_iterations = 10000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    # randomly sample batch of size 64\n",
    "    a = np.arange(x_train[S].shape[0])\n",
    "    random_idxs = np.random.choice(a, size=64, replace=False)\n",
    "    loss = svi.step(x_train[S][random_idxs], weight_samples=full_samples['params'], y=y_train[S][random_idxs], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "    scheduler.step()\n",
    "kde_noise = pyro.param(\"iso_noise\")\n",
    "flattened_params = full_samples['params']\n",
    "kde_mix = dist.Categorical(probs=torch.ones(flattened_params.shape[0]))\n",
    "kde_comps = dist.MultivariateNormal(loc=flattened_params,\n",
    "                                    covariance_matrix=kde_noise * torch.eye(flattened_params.shape[-1]))\n",
    "kde = dist.MixtureSameFamily(kde_mix, kde_comps)\n",
    "prior = dist.MultivariateNormal(loc=torch.zeros_like(flattened_params[0]),\n",
    "                                covariance_matrix=torch.eye(flattened_params[0].shape[-1]))\n",
    "kl_kde_prior = kl_estimate_with_mc(kde, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3358f2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0112, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3de2bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb23ab3e130>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAneUlEQVR4nO3de5QV1Z0v8O9P8DVJnGiCLAZ00AkrCboSo1wvGZN7R43KTDLBu/IYzM3ITcwi43UmZsxdETTxJpNoNBr1+sI4vvAJGFFQBMQGgmjzaKSheTXdvLobmu7m0dA8+nX6d/84+zTVp6tO1TmnTlWdqu+Hxepz9qmqs3dVnV/t2rVrl6gqiIgoOU4JOwNERBQsBn4iooRh4CciShgGfiKihGHgJyJKmKFhZ8DNpz/9aR09enTY2SAiKitr167dr6rD7D6LfOAfPXo0qqqqws4GEVFZEZHdTp+xqYeIKGEY+ImIEoaBn4goYTwFfhHZJSI1IlItIlUm7RwRWSwidebv2Zbpp4lIvYjUish1lvTLzHLqReQRERH/i0RERLnkU+O/UlUvUdVx5v1UABWqOgZAhXkPERkLYBKAiwBMAPCEiAwx80wHMAXAGPN/QvFFICKifBTT1DMRwAzzegaA6y3pM1W1S1V3AqgHcLmIjABwlqpWanpkuBcs8xARUUC8Bn4F8K6IrBWRKSZtuKo2A4D5e65JHwmg0TJvk0kbaV5npxMRUYC89uO/QlX3isi5ABaLyNYc09q122uO9MELSB9cpgDA+eef7zGLg1U3tmPoKYKLR/5lwcsgIoobTzV+Vd1r/rYCeAPA5QBaTPMNzN9WM3kTgPMss48CsNekj7JJt/u+p1R1nKqOGzbM9sYzT65//AN849EVBc9PRBRHroFfRD4mIp/IvAZwLYCNAOYBmGwmmwxgrnk9D8AkETldRC5A+iLuatMc1CEi401vnhst8xARUUC8NPUMB/CG6Xk5FMArqrpQRNYAmC0iNwFoAPAdAFDVTSIyG8BmAL0AblHVlFnWzQCeB3AmgAXmPxERBcg18KvqDgBftEk/AOBqh3nuBnC3TXoVgIvzzyYREfmFd+4SESUMAz8RUcIw8BMRJQwDPxFRwjDwExElDAM/EVHCMPATESUMAz8RUcIw8BMRJQwDPxFRwjDwExElDAM/EVHCMPATESUMAz8RUcIw8BMRJQwDPxFRwjDwExElDAM/EVHCMPATESUMAz8RUcIw8BMRJQwDPxFRwjDwExElDAM/EVHCMPATESUMAz8RUcIw8BMRJQwDPxFRwjDwExElDAM/EVHCMPATESUMAz8RUcIw8BMRJQwDPxFRwjDwExElDAM/EVHCeA78IjJERNaJyNvm/TkislhE6szfsy3TThORehGpFZHrLOmXiUiN+ewRERF/i0NERG7yqfHfCmCL5f1UABWqOgZAhXkPERkLYBKAiwBMAPCEiAwx80wHMAXAGPN/QlG5JyKivHkK/CIyCsDXATxtSZ4IYIZ5PQPA9Zb0marapao7AdQDuFxERgA4S1UrVVUBvGCZh4iIAuK1xv8wgJ8D6LOkDVfVZgAwf8816SMBNFqmazJpI83r7PRBRGSKiFSJSFVbW5vHLBIRkReugV9EvgGgVVXXelymXbu95kgfnKj6lKqOU9Vxw4YN8/i1/lJVLN3ailSfbRaJiMqWlxr/FQC+KSK7AMwEcJWIvASgxTTfwPxtNdM3ATjPMv8oAHtN+iib9EhauHEffvD8Gjy7YmfYWSEi8pVr4FfVaao6SlVHI33Rdomqfh/APACTzWSTAcw1r+cBmCQip4vIBUhfxF1tmoM6RGS86c1zo2WeyGk50gkAaDp0POScEBH5a2gR894LYLaI3ASgAcB3AEBVN4nIbACbAfQCuEVVU2aemwE8D+BMAAvMfyIiClBegV9VlwFYZl4fAHC1w3R3A7jbJr0KwMX5ZpKIiPzDO3eJiBKGgZ+IKGEY+ImIEoaBn4goYRj4iYgShoGfiChhGPhdcMAGIoobBn4HfFQAEcUVAz8RUcIw8BMRJQwDPxFRwjDwU6CmL9uO0VPnI/0QNiIKAwM/Beq+hVvDzgJR4jHwExElDAO/AzZFEFFcMfC7YG9+IoobBn4XrPcTUdww8DvgnbtEFFcM/ERECcPAT0SUMAz8FAp2miIKDwM/BYqXTojCx8BPRJQwDPxERAnDwE++Od7di8eW1KE31Rd2VgboTfXhl29uRNOh42FnhSgSGPjJNw+/V4cH3t2GOev2hJ2VAap2H8KLK3fjttnrw84KUSQw8Ltg7xPvjnX1AgC6eqNV4yeigRj4HbD3CRHFFQM/hYInUkThYeCnQPFEiih8DPwUKNb0icLHwB+CXfuPYd76vWFng4gSioE/BNc+tBw/eXVd2NkoHXaFojzUt3Zg2pwNSPVxvwkKA7+DUsau7ojd4OQX9oSiQtz80kd4dXUjtrcdDTsricHA74LBjIjihoGfiChhXAO/iJwhIqtFZL2IbBKRX5v0c0RksYjUmb9nW+aZJiL1IlIrItdZ0i8TkRrz2SNSBs83ZHM1EcWNlxp/F4CrVPWLAC4BMEFExgOYCqBCVccAqDDvISJjAUwCcBGACQCeEJEhZlnTAUwBMMb8n+BfUfwV/UNSeVMeUYlC4xr4NS1z1eVU818BTAQww6TPAHC9eT0RwExV7VLVnQDqAVwuIiMAnKWqlZr+1b9gmYcSgsfT8tHZk4rcSKvkD09t/CIyRESqAbQCWKyqqwAMV9VmADB/zzWTjwTQaJm9yaSNNK+z0+2+b4qIVIlIVVtbWx7FIRqMJxeF+dwvF+Jb0z8MOxtUAp4Cv6qmVPUSAKOQrr1fnGNyu0qd5ki3+76nVHWcqo4bNmyYlyxShDDOxsf6psNhZ4FKIK9eParaDmAZ0m3zLab5BuZvq5msCcB5ltlGAdhr0kfZpFNMSEQbcni9hmggL716honIJ83rMwF8DcBWAPMATDaTTQYw17yeB2CSiJwuIhcgfRF3tWkO6hCR8aY3z42WeSgGlHV9orIw1MM0IwDMMD1zTgEwW1XfFpFKALNF5CYADQC+AwCquklEZgPYDKAXwC2qmjLLuhnA8wDOBLDA/KeYYQWbKNpcA7+qbgDwJZv0AwCudpjnbgB326RXAch1fYCIiEqMd+5SKNgoRBQeBn4XbLf2VxncrE0Uewz8DhieCsdDJVG0MfCTb6LanZOIBmLgJyJKGAZ+ChQHZyMKHwO/A4YnIoorBn4XbLemOFu6tRWjp87Hrv3Hws4KBYiBn0IRZIsPW5ecvVm9BwBQ3dgebkYoUAz8FKgw+/Hz3I0ojYGffBfVGnZEs0UUOAZ+F7xz17uo3pQbdL5Ulb2XKNIY+B1ENIZRGbhg2ju48dnVYWeDyFEiAv+GpnbWwChQ79ftDzsLeeGZbbIkIvB/87EPMG89H/ZVajy2lh+e2SZTIgI/AGxvYz/loES1rZ+I0hIT+AFgbvUezFrTEHY2iIhC5eXRi7Fx68xqAMA//Zfzw80IsU2ZKESJqvFTMHK19bMViCh8DPzkG7btly9emE8WBn6iBOOjMJOJgd8Fa0IUZ17ub/nuHyvRePB4ALmhoDDwO2FNKDZ48HaXa3dfvfMgHl1SF1xmQnLwWLfjgbC7tw/dvX0B56h0GPgpMQo9lE99fQNGT53va14oWrY0H8Glv1mM16qabD+/5D/exRd+vSjgXJUOAz8Fqhwr3zPXNIadBSqxbS0dAID36+2H2jjenUJnD2v85Sff8322D3iyeudBLK1tHZDmpd04jNXLLeqMu3uyJOoGrkKwqT+37/6xEgCw696ve2pKCWN1chs6Y6+eZEpOjT/EHbytowtPLd/OEUKpbPHZ0/HCGn8AfvLqOlTuOICvfGYYxv7VWWFnh4gcJKVylpwaf4g6unoAAKm+ZOxURFG2cGMzWo90DkhLWpMXAz8RJUZnTwr/8tJH+N7Tq8LOSqgY+F0k5MyvZHpTfejjmU7kJWU/7zMF3XPoRMg5CRcDv5OEnfr5wS52fObOBfje0ysDzwt5w708mkrdLMzAX6TnP9iJP29r8zRtUsegX7njYNhZICobK3ccwN/c8Q7W7i7d74aBv0i/emszJj+7Ouc0SekKl4xSxksyqyLR9n5duiJZuf1Ayb4jOYE/KY2YEccWtGjidkkW18AvIueJyFIR2SIim0TkVpN+jogsFpE68/dsyzzTRKReRGpF5DpL+mUiUmM+e0SS1oeKQsFjvjuuo2TxUuPvBfAzVf08gPEAbhGRsQCmAqhQ1TEAKsx7mM8mAbgIwAQAT4jIELOs6QCmABhj/k/wsSxEObGWMZjXdcIqWry4Bn5VbVbVj8zrDgBbAIwEMBHADDPZDADXm9cTAcxU1S5V3QmgHsDlIjICwFmqWqnp2+NesMxDREQWpTwLy6uNX0RGA/gSgFUAhqtqM5A+OAA410w2EoB1HNsmkzbSvM5Ot/ueKSJSJSJVbW3eesx4yLw/yyGisufUwy4KLV5BdAbxHPhF5OMAXgfwU1U9kmtSmzTNkT44UfUpVR2nquOGDRvmNYuedfWmcNfcjTh0rLs/bef+Y6hubPf9u5IoCj8eonwkrVroKfCLyKlIB/2XVXWOSW4xzTcwfzODsjcBOM8y+ygAe036KJv0wM2t3osXKnfjvoVb+9OufGAZrn/8g0HTMoh5F/Vr9VHdlvWtRzF66nys3X0o7KwkRpS7WKdMG09HV2/JvsNLrx4B8AyALar6oOWjeQAmm9eTAcy1pE8SkdNF5AKkL+KuNs1BHSIy3izzRss8gcqMwNeXoxGtFLsFe06cFOS6iPjxCMvNDYBvrS99PejxpfUY99v3BqVz14yOii0tAICnlu8o2Xd4GZb5CgD/DKBGRKpN2h0A7gUwW0RuAtAA4DsAoKqbRGQ2gM1I9wi6RVVTZr6bATwP4EwAC8z/SPLzhxD1wEPJcf+i2oEJ3DcBROvAF8RD3V0Dv6qugPPucbXDPHcDuNsmvQrAxflksJS81Dr5u7B3vLsXW/d1hJ0NioEoBd2kSOSDWKLcvlcubpu1Hgs37Qs7G0S+iFJECOJaGYdsiPdXl0zNnsNhZ4FiIkpBNymSE/iJEupEdwotWU+c6uexUpJdCa1r6fA8Ki3lJ4gDIQN/luPd/nehStrF3Tie4ZSzSU9V4r/eU+HrMq95aLnrqLRRFukh0gOIFwz8WcbetQhdvSn3CYnKxPqmHM1yCauUuF7fi/DxwE8M/Da6AuhOlUt9awd+/dam/vsNyk3SznCofDjV9CO1zwbws09O4C9wy4YReic/uwbPfbALTTF+Lqj1B3ikswd1LcV1DU31KV5Z1YDe1OCDdpkeP6mEkt6zLzmB30aueFCSO3fznD5StRCf2P3gbnhqJa55aHlRy3151W7c8UYNnv9wV47vHqy7tw///MwqrOc4TYkWqcoB2/hLxGXF+r3eYxi/fbVpb64x/7xpP94DADh8oiev+epbj+L9uv24/fUNReeByseJnlT/Iw4HyPPHqqpFn60WmYWCJDPwU9HieDaSZOV6PakYD7y7bXBinqvhmRU7cc1Dy/FRQ3kNsMfAXyLrG9v725uT9pNKYAwpW0lv684otCKT6THVePC4j3nhnbtlaeOew5j4+Ad4cPHAGgV/YuGyOx7xzCXBElxDSU7gD3Ajt3ak75Lc0jyw7Tq5u1m48g3uG/ccxuHj+V0riD/7ldh6pDOQ0STJX8kJ/CFyijvl3K4at5qydVN849EVuOE/V4aXmTJy+T0VuG12df/7VJ/irrkb0XDAe9NHkL8Cv5u2SvEz4MXdEit13C3fsF56duve70df7jvcOeDxmvnY3Fx8T6OkWLjx5CitG5ra8ULlbvzbzHUh5qi8BRE3Ehn43Y6oxV5c4QWzHHKsGrtHXxZj/O8qcNlvF3uaNm5nMPkKs5IS5Kp3G6MnCmP4sMYfAWXcGkMA+jxuv0K38xX3LsEtL39U2MwxEYefSJQqa0FUQhj4A5Tdpl+5/UBIOSlelH4oxSj2R7an/QTm1zT7k5k8tRzpxCMVdb5cK4rH1syPDngdh8OXd8kJ/AX+wn05+jos5K0NxT1c+0R3Cmt3R+/GkZw/oRB/X82HT+D2P21Aj814PmEqdJX85NV1eHDxNmzcw+sRfim0QuNny0AQlarkBP4Q9O8MJWov+vnrG/Ct6R9i32GHh2wELOrt5I0HT2BWVSNW1O0f9Fk51vhO9KSHD++LUHtkdHISjFLs80Hsiwz8peCwM/h9R94m8/jDYz49PGZ9Y3tZdzF1MqhIETtAFZud+G2x8EShAsAaf0iCigt+xVg/llOxpQUTH/8Ar6xu8DR9mLX7Q8e6cfufNqCzp8AH5tisr3K8ZuFnjt12oVzb21pZKL+1mBal7c+Lu36yiY5+Ht33tLuPne97bdrHHWS3ueGmruWop+mb2wc3L+VTvHzWROPB49hrWb/3v1uLWVWNeP2jpjyW4paf8Gt6+cqVY7vnEtiJevOcHzbuOYw73qiBqhYU4Lfui981lOQEfotSDIJ0xb1Lcn2h7983UDBBqyfVh6W1rdjedhTdOQJLztIWsCq++vul+FvL+i23C2lBW76tDZ+5c0FgzxiI+iHzxmdX45VVDTiYdTOf1/2odp/7sMs/nVWN+xZuLSR7oUhk4I+6qLazP/zeNvzguTWYXdUYdlYA8B4Lp0PWstr0OPNrdh0MLjNGKTdJy5FOPOpT99VSmL5se9hZ8IyBv4SC2z2DqbXuMs1BB48WNgyCX4o9gbJr1oloLPEk7EBotzlKsUf+2yvr8IfF2wp+cI/Cw527dtd/cuxw5Xq+yMDvwm5HUFW8uW6PYztqsTtD/k1RuXfmRyrq8GH94C6MpVLGMbS8+NmEWMRGs5u1FPvA8Z5077V8j3Ne1pLXi9d+qGvpsO1SHKShoX57hOXaEeat34ufzqpG0yH3EQiXbG1B65H0hVC/fwyZLC6rbcOiTS0452On4YbLzx80Xea5ALvu/bov3+f4eZ5xqDfVh+OF9szJg5d8leVFToeAFOaF6kJWY765LbR8G5raMf7CT9kvM8BVlnm+dLG/x2Kwxm/DLQhkRnxs6+hyXdYPn69Cs8MNVn7tbL+dvwX3L6rFtDk1/iwwID97bT2+8Kt3C57fz99qqX74nT0p/ObtzTja5c+9Fvnwcubox/EuqKCZuRA/scDB/H74fJX7d9iskCCeiBX09zHwu+jKUSMNsl515xs1uHfByV4DjQePY3vbMV+W3XTouOPdn/WtR/Gt6R+WJHDNrS5syArrz2LsXQvxLy+uLTgPpf6NvbKqAc+s2IlHl9T5v3CT+ZU7DvY//AdAXr15/N6HC1le3g2bft3/4pDbmqbDWL0z+AvjQUpO4Lf7hTvsQKonn541Z90em0UVOO5PQXOlvbyqAU/++WSvga/+fmkRS0vrSfVhb/sJfOW+pbh/Ua3tNPct3Iq1uw8NaJPs6Ay+9urkeHcKCzftc5/QIsjT+pQZHrQ3VbovvW/hVkx87GQt+KOGdgB57m9F7Jy2teTCF+c7a/7cuu+qAv/42Ap894+VJc6VMw7LXCLNHm62OnKi+OAWdm+LXGZXNWLMnQvwUUN6kLcul8fniZx8OEm+gdaO3+um2MWVakuV8ozCumin5sRSfFe2CO/mnhW6ndwqgak+jeQovIkM/H/Iegh6oZx2eKedIezfhzXYzt+QHkp4e2vu5iJrGTu7i78Q62cc3OyxW9/hEwOfnxuHQOU7n9dJKVZxWBfgc31tXWvum7ueWFqPG/5zJT4IsFedF7EN/P/jiawLQLZDNiTLyh2D2y29/pgE3pu4iqnNP1rh3haeycbO/UcHpdn5cRHXAIIQh6dfPbh4Gw4d645UE0+pbWk+4jok9o796YpVPiPocqyeIpzwoXYaN8cKukDrPSz5MfyBX2djuYRRcyzFWYbbM4qDLOcjFXX45dyNwX1hBDQfdm8yjuqB0DXwi8izItIqIhstaeeIyGIRqTN/z7Z8Nk1E6kWkVkSus6RfJiI15rNHpMR9lk4b6n5My9lumWu+EuZ8e9tRTwO+5TJ7TSNGT51fYKAfKBOw8tlcRzp70ef1mYdF8OOhGX5tyu1tR3HzS2vR7XKtxE5Ug0O+OntSZXUWbX9zZvD5CIOXGv/zACZkpU0FUKGqYwBUmPcQkbEAJgG4yMzzhIgMMfNMBzAFwBjzP3uZvjp1SOlPZvy8UaazJ4XeVB9W7hh8IcitZpftiWX1AIBWh/sM+vpO5txr0MknOD1SUdd/01ixDh0LZniIYi82T5tTgwUb9/VfLM+2uflwUcsvB6U4oFr5cs+Bw282SgffSDT1qOpyANmNwxMBzDCvZwC43pI+U1W7VHUngHoAl4vICABnqWqlpn9hL1jmKYlTh7ivPaefuqLwHeFYV6/jvNmxxboTfu6XC/HdP1ba1mL/Kc+uZU7l2nv4BD7cvh8X3vEOlm9ry3tZ+eyQTs+hzTe8em2fLzRu51Om0VPn552PA+bAZXd9ZUXd/kEXnuNCAcyt3oPOnhReq2rEd5780PfvuG1WNR5fWu9hSvuNnLKclZa6op9ZfkdnNLZ3oUM2DFfVZgBQ1WYROdekjwSw0jJdk0nrMa+z00umlDX+5z/YBQCDBova0XYUV/3hz/j6F0YUtNyPGtrx7cvOKzZ7ju6au6ngef2uhTxn1qGbRpthMfwcStmvU3unHDmltx/vxvefWYUvX/gpXDN2uD+ZcJHK0fzm9zAP6xvbcevMakz+8l9jRuVuX5edkbnH5pYrP1PQ/Ftthlv2vbadtbzfvr3Fwyzld+euXY6dKtCOe5qITBGRKhGpamvzVjPNdloJA3/mSn3DgYFBqb413ctk8eYW2/kK7yuc5/SFfY2tAU9XcllwPsHDa1OQ56aoPApdytpd9jpwylfmWkB9m7cH33jVfty5aey4zSM6s/O3oKYZo6fOx0srnYP1Iof7OOx+6C1H3Ic1KYVUn/aPkVUs6zr67pOVRT3noKMrGjX+QqNji2m+gfnbatKbAFirrKMA7DXpo2zSbanqU6o6TlXHDRs2rKAMFlvjt7tJqbWjE/8+q7r/fbG1g9lVTahpGtj2G3SPE8/dOV2m6+xJYYdlCAmnNvMotaUCg8tVaFt//3IKmN3LLLsPHPPUU+3KB5adzFPWZ9n7mp1bZ1YDAH7xpnMPnV/Ncz5zzKf421o68PaGgWGgu7cPW5qP4BG7cfdz7IQnulMYPXU+Xl6VPmDdv6gWl99TMWAoCz+s3nWwoN5LmbJE5cE/hUbHeQAmm9eTAcy1pE8SkdNF5AKkL+KuNs1CHSIy3vTmudEyT0mc6qFXT0dnr+MIm9beGXvaT+DD+v24d8FWvGEzhEMx/vGxFa7ThLmzeP0h3/76BvzZ43WDfJSi85dTcO/rU4z77XsFLdNpG/m17f77/csw5UX3QcYOHXeuUX7v6VXuX+SQXS+bYcnWVmzz8LSqjGsfWo5/fWXdgH3s+0+vwt//v/fx4OJt/Y8D9WL/0fSZxRNL08OaLN2aroseONqd39lg1q6xa/8xxyayg8eiUXsvhJfunK8CqATwWRFpEpGbANwL4BoRqQNwjXkPVd0EYDaAzQAWArhFVTPVlJsBPI30Bd/tABb4XJYBsi/u9tpsvPe2tOAr97mPeXPFvUvwvadX2fyIB77PDlLvZ4257aUy6U/PBf/0d+c0/5x8mHVbeimaUyq2pJvQMqvZz3ZpBdCd6uu/GJuvTM0yO0euzWPqfZtn709+yGzf5dv8WfaLOZqInDQcTAf4to4urLY8NSyzLne0HcWcPJ+v7Efz6L7Dnfi7B5bh7vlbbKf9P6+tz+9LnL4oBK4Xd1X1BoePrnaY/m4Ad9ukVwG4OK/cFSG7jd9tLBovsnemUjTLBN/U4/3W3VyTelnKq6sbitoON82oGjCGufVAlH1QzdVbZmCZ/VnhTiOl+nIgD6Bz+fyaZjzucdpCy9TXp1i8pQXXjh0+YBtkzq7/p8MZyYSH30d3qg9fPO+TeX9nPgfWbJln9GZ3i97W4v26TGYfzWcLRqI7Z7kqpo0/U7PMV6kGYyrljuB0oS7DusPmc+ptJ8jnBTz8nvPF44GBtMRB1WXjedm2Qd5UVMqY8/LqBvz4xbV4bW1+tfdu86S7XHnL+QStvL7NfZknSvzwoCDqfgz8NjIXuLK5bZD+XhNF/FBvfz3Yh6ls8HDBDwhvzHQ7M9cMftj74Iu0xX+PU6+Q+tYOLK1ttf1s0PVIl+/o7u3D9D+X5iHdVbvtbyazKqRSkessMdd6z4yK+/uFW0s2aFn22ZGX5sCu3uCGd8m1uqt2HcSRgPr5xzbw7ztS3LAHdrKD5KAWf5cfkd1duV4UUwPI1XfbC6/NDKU4K7lw2nzb4Su8DIvgvQboPOHl91TYpn/tweX4wXNrHJbt3J2zsyeF22ZVDzigHD7RM+BJbgePdeNHM6pw2HKRttAt+PYG+5vocin+Qfbun+0/2u3YrFOo7IOR9b31k+zd+coHluGzv1jY30Xbuv1yrYuDDteCXqjcNaCZ0W19jp46H6Onzsdv3t6Mbz9ZiR+/sDaQtp7YBv53agY2YSzcWPwY8rUtuXssuMXI+xfV4vU8T3PzZb279MoHluFv7njHl+Xm27vGjwuvdscs64FobY4aba4L0W+u21PwOEZuB8J15iEodvl4p6YZc9btwe8sT1LLdulvFuO9LS14yXRLLLYv+u1/2lDU/OUme+u4/SZ3moBfa9MbKdczOY46PIzorrmbMG3O4HX+1vp0t1Wn39EzK3YCACp3HEBvqvjrkW5iG/gvPf+TA97nGvis0BXtdLG3O8fyfpZHT4BjXalAT0Ozpfq0vyeJW9gP6kYd6w/Zbj23dXS59ndfsHEfLvq/i7IWDBzxMHzChIffz/l59o1phVbeVBVzq/fg8nsqBgx/kTnwzK321q14VtXgZjEnL63cjc4e53338PEe10cS5jowFtv8Zl2X2YMAOvW3u+ONGk9nvZkmFuuB+sZnnc9KclVsDtl088ynR1b2iAClUOiQDZH3rctG9T+Czs1PLTdl5cOte2exrnt4ua/Ly0dfn+K5D3b2vw/rIRjZLvkP+4ezZ4LKzDWNqG3pwGXnn+1pedZyPfTe4GcB9GQdXKxnfW0Og+DZ5QsAbpudPuj39imO2NQYNzS197+eXdXU381xraWL43tbWnHN2OG216G8jCV0Ml8KERmQv1w3bQHAD2eswdrdh3DuJ073/D3tJ042iTxZ5LWMzJ3xgHMFKvvg4vUa1rLawfeg5DoI5jqIVe44gCVbW3DV54bnjBD5jNHvt9gG/nyGbCikLRQYHAxr95X+SH3oWPeAgOy3+tajqGvpwDUPFXfQKdXFXbuACQzsnbSuoX1Qk4sTaz7tzvyuf/yDQWkZhT7z4a31e/tP/a2sFZVM0AcGNl/41aPknZp9uO6i4Z572Ly0sqH/dV8eG9ducLpCWZ/1bL2R8qnl29Fjnmm8zzSNOVVUBp3pZent83b277YGfvnmJlw1NfcYTON/Z38NKQjxDfwe7twtVva+5fUMI9tjS9yfOpXxpd8sdp2mmG6XK+r32wb9udWOI2zYOtGd8lQjtvPZXyzIu79/5nnA+Vi982D/Q7X3tJ/AkFMGR4tcp91uZ0E/eG41Pn7GqXnnK9sLlkHOVBWNB4vrVgsAt7zyEd76168UNO/+o843udkNfFYor02w97wz8JpJod2xgfQZlRduo43uaT8x6PrKr+ZtiswjGCXKDwQHgHHjxmlVlfut6tnueKMGr6xqcJ+QiCLrtCGn5LxmFnfWGxbzJSJrVXWc3Wexvbh74Gg4owISkX+SHPSB0t21HdvAX9fq73C3RERBK1WDTGwD/7cuHeU+ERFRhKVY48/Pty9j4Cei8pZPD6p8xDbwf+KM2HZYIqKEKNWzOGIbHU8fOqT/dTFXxq2OdfVCAXz89GistuPdvfiL0/LLi6qiq7cPZ5w6xH3iMqSqUAVOsemamXT9T4GKyt14FJpoRLASGHKK4Bdf/zw+P+Is35b5sYgE/Ix8gz6Q/tHHNegD6fIxrtljwKeMaEUyn/3oqxeGnQUiosiJbRs/ERHZY+AnIkoYBn4iooRh4CciShgGfiKihGHgJyJKGAZ+IqKEYeAnIkqYyD+IRUTaAOx2ndDepwFE45E3wWGZkyFpZU5aeYHiy/zXqjrM7oPIB/5iiEiV0xNo4oplToaklTlp5QVKW2Y29RARJQwDPxFRwsQ98D8VdgZCwDInQ9LKnLTyAiUsc6zb+ImIaLC41/iJiCgLAz8RUcLEMvCLyAQRqRWRehGZGnZ+iiEi54nIUhHZIiKbRORWk36OiCwWkTrz92zLPNNM2WtF5DpL+mUiUmM+e0Qi/EgmERkiIutE5G3zPtblBQAR+aSI/ElEtprt/eU4l1tE/t3s0xtF5FUROSNu5RWRZ0WkVUQ2WtJ8K6OInC4is0z6KhEZ7Slj6WeUxuc/gCEAtgO4EMBpANYDGBt2vooozwgAl5rXnwCwDcBYAL8HMNWkTwVwn3k91pT5dAAXmHUxxHy2GsCXAQiABQD+Puzy5Sj3bQBeAfC2eR/r8pr8zgDwI/P6NACfjGu5AYwEsBPAmeb9bAD/K27lBfDfAFwKYKMlzbcyAvjfAJ40rycBmOUpX2GvmBKs6C8DWGR5Pw3AtLDz5WP55gK4BkAtgBEmbQSAWrvyAlhk1skIAFst6TcA+GPY5XEo4ygAFQCuwsnAH9vymvydZQKhZKXHstwm8DcCOAfpR8C+DeDaOJYXwOiswO9bGTPTmNdDkb7TV9zyFMemnswOldFk0sqeOY37EoBVAIarajMAmL/nmsmcyj/SvM5Oj6KHAfwcQJ8lLc7lBdJnqG0AnjNNXE+LyMcQ03Kr6h4ADwBoANAM4LCqvouYljeLn2Xsn0dVewEcBvAptwzEMfDbte+VfZ9VEfk4gNcB/FRVj+Sa1CZNc6RHioh8A0Crqq71OotNWtmU12Io0k0C01X1SwCOId0M4KSsy23atSci3aTxVwA+JiLfzzWLTVrZlNejQspYUPnjGPibAJxneT8KwN6Q8uILETkV6aD/sqrOMcktIjLCfD4CQKtJdyp/k3mdnR41VwD4pojsAjATwFUi8hLiW96MJgBNqrrKvP8T0geCuJb7awB2qmqbqvYAmAPgbxHf8lr5Wcb+eURkKIC/BHDQLQNxDPxrAIwRkQtE5DSkL3jMCzlPBTNX758BsEVVH7R8NA/AZPN6MtJt/5n0SeZq/wUAxgBYbU4pO0RkvFnmjZZ5IkNVp6nqKFUdjfS2W6Kq30dMy5uhqvsANIrIZ03S1QA2I77lbgAwXkT+wuTzagBbEN/yWvlZRuuyvo3078X9jCfsCx8lupjyD0j3ftkO4M6w81NkWb6C9KnbBgDV5v8/IN2OVwGgzvw9xzLPnabstbD0cAAwDsBG89lj8HARKOSy/x1OXtxNQnkvAVBltvWbAM6Oc7kB/BrAVpPXF5HuzRKr8gJ4FelrGD1I185v8rOMAM4A8BqAeqR7/lzoJV8csoGIKGHi2NRDREQ5MPATESUMAz8RUcIw8BMRJQwDPxFRwjDwExElDAM/EVHC/H/iydfHfyc2TQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10d153c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_sample = kde.sample((50,))\n",
    "kde_samples = {\"params\" : kde_sample}\n",
    "kde_pred = Predictive(regression_model, kde_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                     out_size=D_out)\n",
    "KDE_RMSE = ((kde_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a31e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de79dca295cd4a9fa107e6e232955fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "ELBO_BETA = 1.\n",
    "# train Factored Gaussian approx\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(regression_model)\n",
    "svi = SVI(regression_model, guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_iterations = 50000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    # randomly sample batch of size 64\n",
    "    a = np.arange(x_train[S].shape[0])\n",
    "    random_idxs = np.random.choice(a, size=64, replace=False)\n",
    "    loss = svi.step(x_train[S][random_idxs], y_train[S][random_idxs], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fab2f19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb24eb58280>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc9a2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = params\n",
    "variational_posterior = dist.MultivariateNormal(loc=means, covariance_matrix=torch.diag(stds ** 2))\n",
    "variational_sample = variational_posterior.sample((50,))\n",
    "variational_samples = {\"params\" : variational_sample}\n",
    "kl_var_prior = kl_estimate_with_mc(variational_posterior, prior)\n",
    "var_pred = Predictive(regression_model, variational_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)\n",
    "VAR_RMSE = ((var_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1b1d81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final KLs are: KDE 374.9828796386719, VAR 88.62844848632812\n",
      "The final RMSE are: HMC 0.39117613434791565, KDE 0.3502674996852875, VAR 0.01169885415583849\n",
      "The final LLs are: HMC -0.9394441246986389, KDE -2.428762674331665, VAR 6.206996440887451.\n"
     ]
    }
   ],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_test[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_test[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_test[S]).mean()}, KDE {kde_gmm.log_prob(y_test[S]).mean()}, VAR {var_gmm.log_prob(y_test[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80c0db5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final KLs are: KDE 374.9828796386719, VAR 88.62844848632812\n",
      "The final RMSE are: HMC 0.39117613434791565, KDE 0.3502674996852875, VAR 0.01169885415583849\n",
      "The final LLs are: HMC -0.9382113814353943, KDE -2.7321274280548096, VAR 6.204782485961914.\n"
     ]
    }
   ],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_train[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_train[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_train[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_train[S]).mean()}, KDE {kde_gmm.log_prob(y_train[S]).mean()}, VAR {var_gmm.log_prob(y_train[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a0740",
   "metadata": {},
   "source": [
    "# Compress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dd607f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f50d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = deterministic_regression_model(full_samples['params'][10], in_size=D_in, num_nodes=num_nodes, out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad97f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = full_samples['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9bff399",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p = kl_kde_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ac21b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
      "The mean loss is 1240915.87500. The mean KL is: 66.93314:   0%|          | 0/5000 [00:09<?, ?it/s]\u001b[A\n",
      "The mean loss is 1240915.87500. The mean KL is: 66.93314:   0%|          | 1/5000 [00:10<14:02:21, 10.11s/it]\u001b[A\n",
      "The mean loss is 1108877.37500. The mean KL is: 63.71086:   0%|          | 1/5000 [00:20<14:02:21, 10.11s/it]\u001b[A\n",
      "The mean loss is 1108877.37500. The mean KL is: 63.71086:   0%|          | 2/5000 [00:20<14:08:55, 10.19s/it]\u001b[A\n",
      "The mean loss is 980658.37500. The mean KL is: 60.38692:   0%|          | 2/5000 [00:30<14:08:55, 10.19s/it] \u001b[A\n",
      "The mean loss is 980658.37500. The mean KL is: 60.38692:   0%|          | 3/5000 [00:30<14:04:58, 10.15s/it]\u001b[A\n",
      "The mean loss is 862405.68750. The mean KL is: 57.14411:   0%|          | 3/5000 [00:40<14:04:58, 10.15s/it]\u001b[A\n",
      "The mean loss is 862405.68750. The mean KL is: 57.14411:   0%|          | 4/5000 [00:40<14:05:05, 10.15s/it]\u001b[A\n",
      "The mean loss is 797901.25000. The mean KL is: 55.27096:   0%|          | 4/5000 [00:50<14:05:05, 10.15s/it]\u001b[A\n",
      "The mean loss is 797901.25000. The mean KL is: 55.27096:   0%|          | 5/5000 [00:50<14:03:37, 10.13s/it]\u001b[A\n",
      "The mean loss is 699928.37500. The mean KL is: 52.28914:   0%|          | 5/5000 [01:00<14:03:37, 10.13s/it]\u001b[A\n",
      "The mean loss is 699928.37500. The mean KL is: 52.28914:   0%|          | 6/5000 [01:04<14:59:30, 10.81s/it]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-390119e175ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprior_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0memp_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinalJointOptimiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_auxiliaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_q_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trajectories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0maux_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memp_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimiser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/km817/iREC/rec/OptimisingVars/FinalJointOptimiser.py\u001b[0m in \u001b[0;36mrun_optimiser\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_auxiliaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m# compute loss for a_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_kl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremaining_kl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mkls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/rec/OptimisingVars/FinalJointOptimiser.py\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(self, index, remaining_kl)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_kl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# kl = kl_estimate_with_mc(self.aux_posterior, self.aux_prior, rsample=True, num_samples=100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0maux_kl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mkl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maux_kl\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mremaining_kl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_kl\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maux_kl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_auxiliaries\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/iREC/rec/OptimisingVars/FinalJointOptimiser.py\u001b[0m in \u001b[0;36maux_posterior\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munscaled_mean\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmean_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcovariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_softmax_aux_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvariance_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_kl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mevent_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscale_tril\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy_property\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py\u001b[0m in \u001b[0;36m_PositiveDefinite_check\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mflattened_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatrix_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n\u001b[0m\u001b[1;32m     82\u001b[0m                         for v in flattened_value]).view(batch_shape)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mflattened_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmatrix_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n\u001b[0m\u001b[1;32m     82\u001b[0m                         for v in flattened_value]).view(batch_shape)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = samples.mean(0)\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1.\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0daa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dummy_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c846557",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = torch.zeros([0])\n",
    "for w in compressed_weights_emp_low_eps:\n",
    "    weight_samples = torch.cat([weight_samples, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = {'params':weight_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm = make_empirical_gmm(weight_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE_BNN import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_target = kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train[S],\n",
    "                         y_data=y_train[S],\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1.,\n",
    "                        total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    weight_samples_kde = torch.cat([weight_samples_kde, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07405071",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = {'params':weight_samples_kde}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_kde, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb968dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde = make_empirical_gmm(weight_samples_kde, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde_train = make_empirical_gmm(weight_samples_kde, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_kde_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f1203",
   "metadata": {},
   "source": [
    "# Variational Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1.)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = torch.zeros([0])\n",
    "for w in compressed_weights_var_high_eps:\n",
    "    weight_samples_var = torch.cat([weight_samples_var, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = {'params':weight_samples_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_var, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var = make_empirical_gmm(weight_samples_var, num_nodes, x_test[S])\n",
    "\n",
    "compressed_gmm_var.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e91fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var_train = make_empirical_gmm(weight_samples_var, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_var_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d44aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(full_samples, open(f\"PickledStuff/BNN_UCI/NAVAL/full_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kde_samples, open(f\"PickledStuff/BNN_UCI/NAVAL/kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(variational_samples, open(f\"PickledStuff/BNN_UCI/NAVAL/variational_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_kde, open(f\"PickledStuff/BNN_UCI/NAVAL/compressed_kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples, open(f\"PickledStuff/BNN_UCI/NAVAL/compressed_emp_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_var, open(f\"PickledStuff/BNN_UCI/NAVAL/compressed_var_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_kde_prior, open(f\"PickledStuff/BNN_UCI/NAVAL/kde_kl_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_var_prior, open(f\"PickledStuff/BNN_UCI/NAVAL/var_kl_split{S}.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
