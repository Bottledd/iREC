{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1aa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# !wget \"http://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\" --no-check-certificate\n",
    "data = pd.read_excel('ENB2012_data.xlsx', header=0).iloc[:, :10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240997c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from torch import nn\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import HMC, MCMC, SVI, NUTS, TraceMeanField_ELBO\n",
    "from pyro import poutine\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange\n",
    "from rec.utils import kl_estimate_with_mc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c84bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = data[:, :-2]\n",
    "y_ = data[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f476367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_idxs = []\n",
    "for d in range(x_.shape[-1]):\n",
    "    sorted_x = np.argsort(x_[:,d], axis=-1)\n",
    "    total_points = sorted_x.shape[0]\n",
    "    lower_third = total_points // 3\n",
    "    upper_third = total_points * 2 // 3\n",
    "    test_index = sorted_x[lower_third: upper_third]\n",
    "    test_splits_idxs.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6b102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_x, test_splits_y = [], []\n",
    "train_splits_x, train_splits_y = [], []\n",
    "for d in range(x_.shape[-1]):\n",
    "    a = np.arange(x_.shape[0])\n",
    "    test_index = test_splits_idxs[d]\n",
    "    train_index = np.delete(a, test_index, axis=0)\n",
    "    x_train = x_[train_index]\n",
    "    y_train = y_[train_index]\n",
    "    x_test = x_[test_index][:]\n",
    "    y_test = y_[test_index][:]\n",
    "    x_m = x_train.mean(0)\n",
    "    x_s = x_train.std(0)\n",
    "    x_train = (x_train - x_m) / x_s\n",
    "    x_test = (x_test - x_m) / x_s\n",
    "    test_splits_x.append(x_test)\n",
    "    test_splits_y.append(y_test)\n",
    "    train_splits_x.append(x_train)\n",
    "    train_splits_y.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2b3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = x_train.shape[-1]\n",
    "D_out = y_test.shape[-1]\n",
    "x_train = torch.FloatTensor(np.array(train_splits_x))\n",
    "y_train = torch.FloatTensor(np.array(train_splits_y))\n",
    "x_test= torch.FloatTensor(np.array(test_splits_x))\n",
    "y_test = torch.FloatTensor(np.array(test_splits_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfbdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(x, y=None, weight_samples=None, in_size=1, num_nodes=10, out_size=1, ELBO_BETA=1.):\n",
    "    # sample vector of weights for regression\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    # sample params\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(torch.zeros(total_weights + D_out), 1.).to_event(1))\n",
    "    weights, rho = params[:-D_out], params[-D_out:]\n",
    "\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "    with pyro.plate(\"data\"):\n",
    "        obs = pyro.sample(\"obs\", dist.MultivariateNormal(loc=mu, \n",
    "                                                         covariance_matrix=torch.diag(F.softplus(rho) ** 2)), obs=y)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def KDE_guide(x, y=None, weight_samples=None, in_size=D_in, num_nodes=10, out_size=1, ELBO_BETA=None):\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    iso_noise = pyro.param(\"iso_noise\", torch.tensor(1e-5), constraint=dist.constraints.positive)\n",
    "    assignment = dist.Categorical(probs=torch.ones(weight_samples.shape[0])).sample()\n",
    "\n",
    "    # sample assigmnent\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(weight_samples[assignment], iso_noise).to_event(1))\n",
    "\n",
    "    weights, rho = params[:-1], params[-1]\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "def make_empirical_gmm(samples, num_nodes, x_test):\n",
    "    rho_noise = samples['params'][:, -D_out:]\n",
    "    noise = F.softplus(rho_noise) ** 2\n",
    "    preds_dict = Predictive(regression_model, samples, return_sites=['_RETURN'])(x_test, None, num_nodes=num_nodes,\n",
    "                                                                                 in_size=D_in, out_size=D_out)\n",
    "    preds = preds_dict['_RETURN']\n",
    "    mix = dist.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = dist.MultivariateNormal(loc=preds.squeeze().permute(1, 0, 2), covariance_matrix=torch.diag_embed(noise))\n",
    "    gmm = dist.MixtureSameFamily(mix, comp)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e035560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deterministic_regression_model(nn.Module):\n",
    "    def __init__(self, params, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(deterministic_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "        weights, rho = params[:-out_size], params[-out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes *self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx +self.out_size].reshape(self.out_size)\n",
    "        idx +=self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params\n",
    "\n",
    "        # compute forward pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def weight_prior_lp(self):\n",
    "        return dist.Normal(loc=0., scale=1.).log_prob(self.params).mean()\n",
    "    \n",
    "    def data_likelihood(self, x, y):\n",
    "        likelihood = dist.Normal(loc=self.forward(x),\n",
    "                              scale=F.softplus(self.rho))\n",
    "        return likelihood.log_prob(y).sum(-1).mean()\n",
    "    \n",
    "    def joint_log_prob(self, x, y):\n",
    "        return self.data_likelihood(x, y) + self.weight_prior_lp(x, y)\n",
    "    \n",
    "    def make_weights_from_sample(self, params):\n",
    "        weights, rho = params[:-self.out_size], params[-self.out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes * self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx + self.out_size].reshape(self.out_size)\n",
    "        idx += self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aef7f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 2000/2000 [00:28, 71.19it/s, step size=3.02e-01, acc. prob=0.881] \n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(10)\n",
    "ELBO_BETA = 1.\n",
    "S=5\n",
    "in_size = x_train.shape[-1]\n",
    "num_nodes = 3\n",
    "\n",
    "# run HMC\n",
    "kernel = HMC(regression_model, step_size=0.001, num_steps=5, target_accept_prob=0.8)\n",
    "nuts_kernel = NUTS(regression_model, step_size=0.1, target_accept_prob=0.5, max_tree_depth=5)\n",
    "mcmc = MCMC(kernel, num_samples=1000, warmup_steps=1000, num_chains=1)\n",
    "mcmc.run(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d708ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py:81: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n"
     ]
    }
   ],
   "source": [
    "full_samples = mcmc.get_samples(50)\n",
    "from pyro.infer import Predictive\n",
    "pred = Predictive(regression_model, full_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "HMC_RMSE = ((pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37458d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313fcdde811046d9a7f08a1b9e6b052f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "scheduler = pyro.optim.ExponentialLR({'optimizer': optimizer, 'optim_args': {'lr': 1}, 'gamma': .95})\n",
    "# train KDE\n",
    "svi = SVI(regression_model, KDE_guide, scheduler, loss=TraceMeanField_ELBO())\n",
    "\n",
    "num_iterations = 1000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train[S], y_train[S], full_samples['params'], \n",
    "                    ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "    scheduler.step()\n",
    "kde_noise = pyro.param(\"iso_noise\")\n",
    "flattened_params = full_samples['params']\n",
    "kde_mix = dist.Categorical(probs=torch.ones(flattened_params.shape[0]))\n",
    "kde_comps = dist.MultivariateNormal(loc=flattened_params,\n",
    "                                    covariance_matrix=kde_noise * torch.eye(flattened_params.shape[-1]))\n",
    "kde = dist.MixtureSameFamily(kde_mix, kde_comps)\n",
    "prior = dist.MultivariateNormal(loc=torch.ones_like(flattened_params[0]),\n",
    "                                covariance_matrix=torch.eye(flattened_params[0].shape[-1]))\n",
    "kl_kde_prior = kl_estimate_with_mc(kde, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3358f2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0282, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de2bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fde6c1d9d90>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d153c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_sample = kde.sample((50,))\n",
    "kde_samples = {\"params\" : kde_sample}\n",
    "kde_pred = Predictive(regression_model, kde_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                     out_size=D_out)\n",
    "KDE_RMSE = ((kde_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2763f2821eb43a99a8c031c57139536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "# train Factored Gaussian approx\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(regression_model)\n",
    "svi = SVI(regression_model, guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_iterations = 50000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = params\n",
    "variational_posterior = dist.MultivariateNormal(loc=means, covariance_matrix=torch.diag(stds ** 2))\n",
    "variational_sample = variational_posterior.sample((50,))\n",
    "variational_samples = {\"params\" : variational_sample}\n",
    "kl_var_prior = kl_estimate_with_mc(variational_posterior, prior)\n",
    "var_pred = Predictive(regression_model, variational_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)\n",
    "VAR_RMSE = ((var_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_test[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_test[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_test[S]).mean()}, KDE {kde_gmm.log_prob(y_test[S]).mean()}, VAR {var_gmm.log_prob(y_test[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_train[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_train[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_train[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_train[S]).mean()}, KDE {kde_gmm.log_prob(y_train[S]).mean()}, VAR {var_gmm.log_prob(y_train[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a0740",
   "metadata": {},
   "source": [
    "# Compress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd607f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f50d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = deterministic_regression_model(full_samples['params'][10], in_size=D_in, num_nodes=num_nodes, out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = full_samples['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bff399",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p = kl_kde_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac21b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = samples.mean(0)\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1.\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0daa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dummy_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c846557",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = torch.zeros([0])\n",
    "for w in compressed_weights_emp_low_eps:\n",
    "    weight_samples = torch.cat([weight_samples, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = {'params':weight_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm = make_empirical_gmm(weight_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE_BNN import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_target = kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train[S],\n",
    "                         y_data=y_train[S],\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1.,\n",
    "                        total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    weight_samples_kde = torch.cat([weight_samples_kde, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07405071",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = {'params':weight_samples_kde}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_kde, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb968dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde = make_empirical_gmm(weight_samples_kde, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde_train = make_empirical_gmm(weight_samples_kde, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_kde_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f1203",
   "metadata": {},
   "source": [
    "# Variational Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1.)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = torch.zeros([0])\n",
    "for w in compressed_weights_var_high_eps:\n",
    "    weight_samples_var = torch.cat([weight_samples_var, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = {'params':weight_samples_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_var, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var = make_empirical_gmm(weight_samples_var, num_nodes, x_test[S])\n",
    "\n",
    "compressed_gmm_var.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e91fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var_train = make_empirical_gmm(weight_samples_var, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_var_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d44aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(full_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/full_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kde_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(variational_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/variational_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_kde, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_emp_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_var, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_var_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_kde_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_kl_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_var_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/var_kl_split{S}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbb927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
