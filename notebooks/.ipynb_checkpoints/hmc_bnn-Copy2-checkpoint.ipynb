{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25fda7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cf83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037cc729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1984273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31634b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7307c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltorch.set_random_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370e89d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95942b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BNNs.DeterministicNN import Deterministic_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40cf5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=16\n",
    "# create toy dataset\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.manual_seed(20)\n",
    "x = torch.cat([torch.Tensor(75).uniform_(-5, -2).sort()[0].reshape(-1, 1),\n",
    "               torch.Tensor(50).uniform_(2, 5).sort()[0].reshape(-1, 1)])\n",
    "i = 30\n",
    "x_data = torch.cat([x[0:i - 15], x[i + 14:]])\n",
    "\n",
    "# generate some data\n",
    "alpha, beta, num_nodes = 1., 100., 4\n",
    "\n",
    "# generate some data\n",
    "data_generator_model = Deterministic_NN(alpha=alpha, beta=beta, num_nodes=num_nodes)\n",
    "sampled_weights = data_generator_model.sample_weights_from_prior()\n",
    "data_generator_model.make_weights_from_sample(sampled_weights)\n",
    "y_data = data_generator_model(x_data).detach() + (\n",
    "            1 / data_generator_model.likelihood_beta ** 0.5) * torch.randn_like(\n",
    "    data_generator_model(x_data).detach())\n",
    "\n",
    "xs = torch.linspace(-10, 10, 100)\n",
    "ys = data_generator_model(xs).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0708c008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(x_data,y_data, 'k*')\n",
    "plt.plot(xs, ys, 'r')\n",
    "plt.legend(['Observed Data', 'Ground Truth'], fontsize = fs)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0da46a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device  =torch.device('cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x.view(-1, 1)))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e062db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.005\n",
    "num_samples = 5000\n",
    "L = 10\n",
    "burn = 1000\n",
    "store_on_GPU = False\n",
    "debug = False\n",
    "model_loss = 'regression'\n",
    "mass = 1.0\n",
    "\n",
    "# Effect of tau\n",
    "# Set to tau = 1000. to see a function that is less bendy (weights restricted to small bends)\n",
    "# Set to tau = 1. for more flexible\n",
    "\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = beta # Output Precision\n",
    "r = 0 # Random seed\n",
    "\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "# Set initial weights\n",
    "params_init = hamiltorch.util.flatten(net).to(device).clone()\n",
    "# Set the Inverse of the Mass matrix\n",
    "inv_mass = torch.ones(params_init.shape) / mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e3379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33])\n",
      "Sampling (Sampler.HMC; Integrator.IMPLICIT)\n",
      "Time spent  | Time remain.| Progress             | Samples   | Samples/sec\n",
      "0d:00:00:19 | 0d:00:00:46 | ######-------------- | 1455/5000 | 75.92       \r"
     ]
    }
   ],
   "source": [
    "print(params_init.shape)\n",
    "integrator = hamiltorch.Integrator.EXPLICIT\n",
    "sampler = hamiltorch.Sampler.HMC\n",
    "\n",
    "hamiltorch.set_random_seed(r)\n",
    "params_hmc_f = hamiltorch.sample_model(net, x_data.to(device), y_data.to(device), params_init=params_init,\n",
    "                                       model_loss=model_loss, num_samples=num_samples,\n",
    "                                       burn = burn, inv_mass=inv_mass.to(device),step_size=step_size,\n",
    "                                       num_steps_per_sample=L,tau_out=tau_out, tau_list=tau_list,\n",
    "                                       debug=debug, store_on_GPU=store_on_GPU,\n",
    "                                       sampler = sampler)\n",
    "\n",
    "# At the moment, params_hmc_f is on the CPU so we move to GPU\n",
    "\n",
    "params_hmc_gpu = [ll.to(device) for ll in params_hmc_f[1:]]\n",
    "\n",
    "\n",
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=params_hmc_gpu,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "# Let's evaluate the performance over the training data\n",
    "pred_list_tr, log_probs_split_tr = hamiltorch.predict_model(net, x = x_data.to(device), y=y_data.to(device),\n",
    "                                                            samples=params_hmc_gpu, model_loss=model_loss,\n",
    "                                                            tau_out=tau_out, tau_list=tau_list)\n",
    "ll_full = torch.zeros(pred_list_tr.shape[0])\n",
    "ll_full[0] = - 0.5 * tau_out * ((pred_list_tr[0].cpu() - y_data) ** 2).sum(0)\n",
    "for i in range(pred_list_tr.shape[0]):\n",
    "    ll_full[i] = - 0.5 * tau_out * ((pred_list_tr[:i].mean(0).cpu() - y_data) ** 2).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3281da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_full = torch.zeros(pred_list_tr.shape[0])\n",
    "ll_full[0] = - 0.5 * tau_out * ((pred_list_tr[0].cpu() - y_data) ** 2).sum(0)\n",
    "for i in range(pred_list_tr.shape[0]):\n",
    "    ll_full[i] = - 0.5 * tau_out * ((pred_list_tr[:i].mean(0).cpu() - y_data) ** 2).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f36c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots(1,1, figsize = (10,5))\n",
    "ax1.set_title('Training Log-Likelihood')\n",
    "ax1.plot(ll_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e749b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16\n",
    "\n",
    "m = pred_list[2000:].mean(0).to('cpu')\n",
    "s = pred_list[2000:].std(0).to('cpu')\n",
    "s_al = (pred_list[2000:].var(0).to('cpu') + tau_out ** -1) ** 0.5\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Get upper and lower confidence bounds\n",
    "lower, upper = (m - s*2).flatten(), (m + s*2).flatten()\n",
    "# + aleotoric\n",
    "lower_al, upper_al = (m - s_al*2).flatten(), (m + s_al*2).flatten()\n",
    "\n",
    "# Plot training data as black stars\n",
    "ax.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "# Plot predictive means as blue line\n",
    "ax.plot(xs.numpy(), m.numpy(), 'b', rasterized=True)\n",
    "ax.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)\n",
    "# Shade between the lower and upper confidence bounds\n",
    "ax.fill_between(xs.flatten().numpy(), lower.numpy(), upper.numpy(), alpha=0.5, rasterized=True)\n",
    "ax.fill_between(xs.flatten().numpy(), lower_al.numpy(), upper_al.numpy(), alpha=0.2, rasterized=True)\n",
    "plt.grid()\n",
    "ax.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax.set_title('Full HMC Posterior', fontsize=fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/full_hmc.pdf', rasterized=True)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f12931",
   "metadata": {},
   "source": [
    "# Draw subset of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "subset = random.sample(params_hmc_gpu[2000:], 50)\n",
    "# Let's predict over the entire test range [-2,2]\n",
    "pred_list, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=subset,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "# plot the fit\n",
    "fs = 16\n",
    "\n",
    "m = pred_list.mean(0).to('cpu')\n",
    "s = pred_list.std(0).to('cpu')\n",
    "s_al = (pred_list.var(0).to('cpu') + tau_out ** -1) ** 0.5\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Get upper and lower confidence bounds\n",
    "lower, upper = (m - s*2).flatten(), (m + s*2).flatten()\n",
    "# + aleotoric\n",
    "lower_al, upper_al = (m - s_al*2).flatten(), (m + s_al*2).flatten()\n",
    "\n",
    "# Plot training data as black stars\n",
    "ax.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "# Plot predictive means as blue line\n",
    "ax.plot(xs.numpy(), m.numpy(), 'b', rasterized=True)\n",
    "ax.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)\n",
    "# Shade between the lower and upper confidence bounds\n",
    "ax.fill_between(xs.flatten().numpy(), lower.numpy(), upper.numpy(), alpha=0.5, rasterized=True)\n",
    "ax.fill_between(xs.flatten().numpy(), lower_al.numpy(), upper_al.numpy(), alpha=0.2, rasterized=True)\n",
    "plt.grid()\n",
    "ax.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/full_hmc.pdf', rasterized=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from models.BNNs.BNN_for_HMC import BNN_for_HMC\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c68221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = BNN_for_HMC(alpha=alpha, beta=beta, num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_samples = torch.empty([0])\n",
    "for s in subset:\n",
    "    emp_samples = torch.cat([emp_samples, s[None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22beb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_dist = dist.Empirical(emp_samples, log_weights=torch.ones(emp_samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "kl_q_p = 70\n",
    "initial_seed = 0\n",
    "beamwidth = 5\n",
    "epsilon = 0.2\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = emp_dist.mean\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1./alpha\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c6b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf2d314a2774673b0dac9072b4bc5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 5\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 250\n",
    "compressed_weights = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "# plot the fit\n",
    "fs = 16\n",
    "\n",
    "m = pred_list.mean(0).to('cpu')\n",
    "s = pred_list.std(0).to('cpu')\n",
    "s_al = (pred_list.var(0).to('cpu') + tau_out ** -1) ** 0.5\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Get upper and lower confidence bounds\n",
    "lower, upper = (m - s*2).flatten(), (m + s*2).flatten()\n",
    "# + aleotoric\n",
    "lower_al, upper_al = (m - s_al*2).flatten(), (m + s_al*2).flatten()\n",
    "\n",
    "# Plot training data as black stars\n",
    "ax.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "# Plot predictive means as blue line\n",
    "ax.plot(xs.numpy(), m.numpy(), 'b', rasterized=True)\n",
    "ax.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)# Shade between the lower and upper confidence bounds\n",
    "ax.fill_between(xs.flatten().numpy(), lower.numpy(), upper.numpy(), alpha=0.5, rasterized=True)\n",
    "ax.fill_between(xs.flatten().numpy(), lower_al.numpy(), upper_al.numpy(), alpha=0.2, rasterized=True)\n",
    "plt.grid()\n",
    "ax.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax.set_title('Compressed Empirical Posterior, BW=5, Epsilon=0.', fontsize=fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/full_hmc.pdf', rasterized=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 5\n",
    "epsilon = 0.1\n",
    "num_compressed_samples = 50\n",
    "compressed_weights = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3147e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "# plot the fit\n",
    "fs = 16\n",
    "\n",
    "m = pred_list.mean(0).to('cpu')\n",
    "s = pred_list.std(0).to('cpu')\n",
    "s_al = (pred_list.var(0).to('cpu') + tau_out ** -1) ** 0.5\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Get upper and lower confidence bounds\n",
    "lower, upper = (m - s*2).flatten(), (m + s*2).flatten()\n",
    "# + aleotoric\n",
    "lower_al, upper_al = (m - s_al*2).flatten(), (m + s_al*2).flatten()\n",
    "\n",
    "# Plot training data as black stars\n",
    "ax.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "# Plot predictive means as blue line\n",
    "ax.plot(xs.numpy(), m.numpy(), 'b', rasterized=True)\n",
    "ax.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)# Shade between the lower and upper confidence bounds\n",
    "ax.fill_between(xs.flatten().numpy(), lower.numpy(), upper.numpy(), alpha=0.5, rasterized=True)\n",
    "ax.fill_between(xs.flatten().numpy(), lower_al.numpy(), upper_al.numpy(), alpha=0.2, rasterized=True)\n",
    "plt.grid()\n",
    "ax.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax.set_title('Compressed Empirical Posterior, BW=5, Epsilon=0.1', fontsize=fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/full_hmc.pdf', rasterized=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f6ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 5\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 50\n",
    "compressed_weights = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "# plot the fit\n",
    "fs = 16\n",
    "\n",
    "m = pred_list.mean(0).to('cpu')\n",
    "s = pred_list.std(0).to('cpu')\n",
    "s_al = (pred_list.var(0).to('cpu') + tau_out ** -1) ** 0.5\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Get upper and lower confidence bounds\n",
    "lower, upper = (m - s*2).flatten(), (m + s*2).flatten()\n",
    "# + aleotoric\n",
    "lower_al, upper_al = (m - s_al*2).flatten(), (m + s_al*2).flatten()\n",
    "\n",
    "# Plot training data as black stars\n",
    "ax.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "# Plot predictive means as blue line\n",
    "ax.plot(xs.numpy(), m.numpy(), 'b', rasterized=True)\n",
    "ax.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)# Shade between the lower and upper confidence bounds\n",
    "ax.fill_between(xs.flatten().numpy(), lower.numpy(), upper.numpy(), alpha=0.5, rasterized=True)\n",
    "ax.fill_between(xs.flatten().numpy(), lower_al.numpy(), upper_al.numpy(), alpha=0.2, rasterized=True)\n",
    "plt.grid()\n",
    "ax.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax.set_title('Compressed Empirical Posterior, BW=5, Epsilon=0.2', fontsize=fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/full_hmc.pdf', rasterized=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765864ea",
   "metadata": {},
   "source": [
    "# thinning the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545fb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 5\n",
    "epsilon = 0.\n",
    "num_compressed_samples = 50\n",
    "compressed_weights = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_data,\n",
    "                     y_data,\n",
    "                     emp_samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1./alpha,\n",
    "                     total_kl=200.)\n",
    "    \n",
    "    #encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0750dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "# plot the fit\n",
    "fs = 16\n",
    "\n",
    "m = pred_list.mean(0).to('cpu')\n",
    "s = pred_list.std(0).to('cpu')\n",
    "s_al = (pred_list.var(0).to('cpu') + tau_out ** -1) ** 0.5\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Get upper and lower confidence bounds\n",
    "lower, upper = (m - s*2).flatten(), (m + s*2).flatten()\n",
    "# + aleotoric\n",
    "lower_al, upper_al = (m - s_al*2).flatten(), (m + s_al*2).flatten()\n",
    "\n",
    "# Plot training data as black stars\n",
    "ax.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "# Plot predictive means as blue line\n",
    "ax.plot(xs.numpy(), m.numpy(), 'b', rasterized=True)\n",
    "ax.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)# Shade between the lower and upper confidence bounds\n",
    "ax.fill_between(xs.flatten().numpy(), lower.numpy(), upper.numpy(), alpha=0.5, rasterized=True)\n",
    "ax.fill_between(xs.flatten().numpy(), lower_al.numpy(), upper_al.numpy(), alpha=0.2, rasterized=True)\n",
    "plt.grid()\n",
    "ax.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax.set_title('Compressed Empirical Posterior, BW=5, Epsilon=0.', fontsize=fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/full_hmc.pdf', rasterized=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615de6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = torch.empty([0])\n",
    "for w in compressed_weights:\n",
    "    #make model\n",
    "    dummy_model.make_weights_from_sample(w)\n",
    "    log_probs = torch.cat([log_probs, dummy_model.joint_log_prob(x_data, y_data)[None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fea636",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, idxs = torch.topk(log_probs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thinned_weights = []\n",
    "for i in idxs:\n",
    "    j = int(i)\n",
    "    thinned_weights.append(compressed_weights[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e086afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=thinned_weights,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "# plot the fit\n",
    "fs = 16\n",
    "\n",
    "m = pred_list.mean(0).to('cpu')\n",
    "s = pred_list.std(0).to('cpu')\n",
    "s_al = (pred_list.var(0).to('cpu') + tau_out ** -1) ** 0.5\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Get upper and lower confidence bounds\n",
    "lower, upper = (m - s*2).flatten(), (m + s*2).flatten()\n",
    "# + aleotoric\n",
    "lower_al, upper_al = (m - s_al*2).flatten(), (m + s_al*2).flatten()\n",
    "\n",
    "# Plot training data as black stars\n",
    "ax.plot(x_data.numpy(), y_data.numpy(), 'k*', rasterized=True)\n",
    "# Plot predictive means as blue line\n",
    "ax.plot(xs.numpy(), m.numpy(), 'b', rasterized=True)\n",
    "ax.plot(xs.numpy(), ys.numpy(), 'r', rasterized=True)# Shade between the lower and upper confidence bounds\n",
    "ax.fill_between(xs.flatten().numpy(), lower.numpy(), upper.numpy(), alpha=0.5, rasterized=True)\n",
    "ax.fill_between(xs.flatten().numpy(), lower_al.numpy(), upper_al.numpy(), alpha=0.2, rasterized=True)\n",
    "plt.grid()\n",
    "ax.legend(['Observed Data', 'Mean', 'Ground Truth', 'Epistemic', 'Aleatoric'], fontsize = fs)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=14)\n",
    "ax.set_title('Compressed Empirical Posterior, BW=5, Epsilon=0., big kl', fontsize=fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('plots/full_hmc.pdf', rasterized=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb899cb",
   "metadata": {},
   "source": [
    "# How to compute KL(p(W|D)||p(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define placeholder model\n",
    "dummy_model = BNN_for_HMC(alpha=alpha, beta=beta, num_nodes=num_nodes)\n",
    "compressed_weights = []\n",
    "num_compressed_samples = 2\n",
    "\n",
    "emp_samples = torch.empty([0])\n",
    "for s in params_hmc_gpu[1000:]:\n",
    "    emp_samples = torch.cat([emp_samples, s[None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6761b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_samples = torch.empty([0])\n",
    "for s in params_hmc_gpu:\n",
    "    emp_samples = torch.cat([emp_samples, s[None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dimension = emp_samples.shape[-1]\n",
    "empirical_samples = emp_samples\n",
    "# create dummy coding object to compute kl with target\n",
    "coding_z_prior = coding_sampler(problem_dimension=problem_dimension, n_auxiliary=1, var=(1./alpha))\n",
    "\n",
    "# for each empirical sample, compute MC KL estimate\n",
    "# first need to compute estimate of KL with joint\n",
    "likelihoods = torch.empty([0])\n",
    "for sample in empirical_samples:\n",
    "    # make a model\n",
    "    dummy_model.make_weights_from_sample(sample)\n",
    "\n",
    "    likelihood = dummy_model.data_likelihood(x_data, y_data)\n",
    "    likelihoods = torch.cat([likelihoods, likelihood[None]])\n",
    "\n",
    "kl_term_1 = likelihoods.mean()\n",
    "\n",
    "# to work out second KL term p(D) need to sample from prior and measure likelihood\n",
    "n_samples = 10000\n",
    "prior_samples = coding_z_prior.sample((n_samples,))\n",
    "log_marginal_data = torch.zeros([0])\n",
    "for sample in prior_samples:\n",
    "    # make a model\n",
    "    dummy_model.make_weights_from_sample(sample)\n",
    "\n",
    "    log_marginal = dummy_model.data_likelihood(x_data, y_data)\n",
    "    log_marginal_data = torch.cat([log_marginal_data, log_marginal[None]])\n",
    "\n",
    "kl_term_2 = - torch.log(torch.tensor(n_samples)) + torch.logsumexp(log_marginal_data, dim=0)\n",
    "\n",
    "\n",
    "total_kl = kl_term_1 - kl_term_2\n",
    "print(total_kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eff2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to work out second KL term p(D) need to sample from prior and measure likelihood\n",
    "n_samples = 10000\n",
    "prior_samples = coding_z_prior.sample((n_samples,))\n",
    "log_marginal_data = torch.zeros([0])\n",
    "for sample in prior_samples:\n",
    "    # make a model\n",
    "    dummy_model.make_weights_from_sample(sample)\n",
    "\n",
    "    log_marginal = dummy_model.data_likelihood(x_data, y_data)\n",
    "    log_marginal_data = torch.cat([log_marginal_data, log_marginal[None]])\n",
    "\n",
    "kl_term_2 = - torch.log(torch.tensor(n_samples)) + torch.logsumexp(log_marginal_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ffb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_term_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "- kl_term_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b7483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.data_likelihood(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8875dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = torch.empty([0])\n",
    "for sample in empirical_samples:\n",
    "    # make a model\n",
    "    dummy_model.make_weights_from_sample(sample)\n",
    "\n",
    "    likelihood = dummy_model.data_likelihood(x_data, y_data)\n",
    "    likelihoods = torch.cat([likelihoods, likelihood[None]])\n",
    "\n",
    "kl_term_1 = likelihoods.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.data_likelihood(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9423cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-688897.0289, -665453.5515, -642418.1957, -619790.9615, -597571.8490,\n",
       "         -575760.8581, -554357.9888, -533363.2411, -512776.6150, -492598.1106,\n",
       "         -472827.7278, -453465.4666, -434511.3270, -415965.3090, -397827.4127,\n",
       "         -380097.6380, -362775.9849, -345862.4534, -329357.0435, -313259.7553,\n",
       "         -297570.5887, -282289.5437, -267416.6203, -252951.8185, -238895.1384,\n",
       "         -225246.5799, -212006.1430, -199173.8277, -186749.6341, -174733.5620,\n",
       "         -163125.6116, -151925.7828, -141134.0756, -130750.4901, -120775.0261,\n",
       "         -111207.6838, -102048.4631,  -93297.3641,  -84954.3866,  -77019.5308,\n",
       "          -69492.7966,  -62374.1840,  -55663.6930,  -49361.3237,  -43467.0759,\n",
       "          -37980.9498,  -32902.9453,  -28233.0624,  -23971.3012,  -20117.6616,\n",
       "          -16672.1436,  -13634.7472,  -11005.4724,   -8784.3192,   -6971.2877,\n",
       "           -5566.3778,   -4569.5895,   -3980.9228,   -3800.3778,   -4027.9544,\n",
       "           -4663.6526,   -5707.4724,   -7159.4138,   -9019.4769,  -11287.6615,\n",
       "          -13963.9678,  -17048.3957,  -20540.9453,  -24441.6164,  -28750.4092,\n",
       "          -33467.3236,  -38592.3596,  -44125.5172,  -50066.7965,  -56416.1974,\n",
       "          -63173.7199,  -70339.3640,  -77913.1297,  -85895.0171,  -94285.0261,\n",
       "         -103083.1567, -112289.4089, -121903.7827, -131926.2782, -142356.8952,\n",
       "         -153195.6339, -164442.4943, -176097.4762, -188160.5798, -200631.8049,\n",
       "         -213511.1517, -226798.6202, -240494.2102, -254597.9219, -269109.7551,\n",
       "         -284029.7100, -299357.7866, -315093.9847, -331238.3045, -347790.7458]),\n",
       " tensor([-698034.4056, -674489.1527, -651352.0215, -628623.0119, -606302.1239,\n",
       "         -584389.3575, -562884.7128, -541788.1896, -521099.7881, -500819.5082,\n",
       "         -480947.3500, -461483.3133, -442427.3983, -423779.6049, -405539.9331,\n",
       "         -387708.3829, -370284.9544, -353269.6474, -336662.4621, -320463.3984,\n",
       "         -304672.4564, -289289.6359, -274314.9371, -259748.3599, -245589.9043,\n",
       "         -231839.5703, -218497.3580, -205563.2672, -193037.2981, -180919.4507,\n",
       "         -169209.7248, -157908.1205, -147014.6379, -136529.2769, -126452.0375,\n",
       "         -116782.9198, -107521.9236,  -98669.0491,  -90224.2962,  -82187.6649,\n",
       "          -74559.1552,  -67338.7672,  -60526.5008,  -54122.3560,  -48126.3328,\n",
       "          -42538.4312,  -37358.6513,  -32586.9930,  -28223.4562,  -24268.0412,\n",
       "          -20720.7477,  -17581.5759,  -14850.5256,  -12527.5970,  -10612.7901,\n",
       "           -9106.1047,   -8007.5410,   -7317.0988,   -7034.7783,   -7160.5795,\n",
       "           -7694.5022,   -8636.5466,   -9986.7125,  -11745.0001,  -13911.4094,\n",
       "          -16485.9402,  -19468.5927,  -22859.3668,  -26658.2625,  -30865.2798,\n",
       "          -35480.4187,  -40503.6793,  -45935.0615,  -51774.5653,  -58022.1907,\n",
       "          -64677.9377,  -71741.8064,  -79213.7967,  -87093.9086,  -95382.1421,\n",
       "         -104078.4973, -113182.9740, -122695.5724, -132616.2924, -142945.1341,\n",
       "         -153682.0973, -164827.1822, -176380.3887, -188341.7168, -200711.1665,\n",
       "         -213488.7378, -226674.4308, -240268.2454, -254270.1816, -268680.2394,\n",
       "         -283498.4189, -298724.7200, -314359.1426, -330401.6870, -346852.3529]),\n",
       " tensor([-683594.8837, -660220.1990, -637253.6360, -614695.1946, -592544.8748,\n",
       "         -570802.6766, -549468.6001, -528542.6452, -508024.8119, -487915.1002,\n",
       "         -468213.5101, -448920.0417, -430034.6948, -411557.4696, -393488.3661,\n",
       "         -375827.3841, -358574.5237, -341729.7850, -325293.1679, -309264.6724,\n",
       "         -293644.2986, -278432.0463, -263627.9157, -249231.9067, -235244.0193,\n",
       "         -221664.2536, -208492.6094, -195729.0869, -183373.6860, -171426.4067,\n",
       "         -159887.2491, -148756.2130, -138033.2986, -127718.5058, -117811.8346,\n",
       "         -108313.2851,  -99222.8571,  -90540.5508,  -82266.3661,  -74400.3030,\n",
       "          -66942.3616,  -59892.5418,  -53250.8435,  -47017.2669,  -41191.8120,\n",
       "          -35774.4786,  -30765.2669,  -26164.1768,  -21971.2083,  -18186.3614,\n",
       "          -14809.6361,  -11841.0325,   -9280.5505,   -7128.1901,   -5383.9513,\n",
       "           -4047.8342,   -3119.8386,   -2599.9647,   -2488.2124,   -2784.5818,\n",
       "           -3489.0727,   -4601.6853,   -6122.4195,   -8051.2753,  -10388.2527,\n",
       "          -13133.3517,  -16286.5724,  -19847.9147,  -23817.3786,  -28194.9641,\n",
       "          -32980.6713,  -38174.5001,  -43776.4505,  -49786.5225,  -56204.7161,\n",
       "          -63031.0313,  -70265.4682,  -77908.0267,  -85958.7068,  -94417.5086,\n",
       "         -103284.4319, -112559.4769, -122242.6435, -132333.9317, -142833.3415,\n",
       "         -153740.8730, -165056.5260, -176780.3007, -188912.1971, -201452.2150,\n",
       "         -214400.3545, -227756.6157, -241520.9985, -255693.5029, -270274.1290,\n",
       "         -285262.8766, -300659.7459, -316464.7368, -332677.8493, -349299.0835]),\n",
       " tensor([-720760.7576, -696969.5698, -673586.5036, -650611.5590, -628044.7361,\n",
       "         -605886.0348, -584135.4550, -562792.9970, -541858.6605, -521332.4456,\n",
       "         -501214.3524, -481504.3808, -462202.5308, -443308.8024, -424823.1957,\n",
       "         -406745.7106, -389076.3471, -371815.1052, -354961.9849, -338516.9862,\n",
       "         -322480.1092, -306851.3538, -291630.7200, -276818.2079, -262413.8173,\n",
       "         -248417.5484, -234829.4011, -221649.3754, -208877.4713, -196513.6889,\n",
       "         -184558.0281, -173010.4889, -161871.0713, -151139.7753, -140816.6010,\n",
       "         -130901.5482, -121394.6171, -112295.8077, -103605.1198,  -95322.5535,\n",
       "          -87448.1089,  -79981.7859,  -72923.5845,  -66273.5048,  -60031.5466,\n",
       "          -54197.7101,  -48771.9952,  -43754.4019,  -39144.9303,  -34943.5802,\n",
       "          -31150.3518,  -27765.2450,  -24788.2598,  -22219.3963,  -20058.6543,\n",
       "          -18306.0340,  -16961.5353,  -16025.1582,  -15496.9028,  -15376.7689,\n",
       "          -15664.7567,  -16360.8661,  -17465.0972,  -18977.4498,  -20897.9241,\n",
       "          -23226.5199,  -25963.2374,  -29108.0766,  -32661.0373,  -36622.1197,\n",
       "          -40991.3237,  -45768.6493,  -50954.0965,  -56547.6653,  -62549.3558,\n",
       "          -68959.1679,  -75777.1016,  -83003.1569,  -90637.3339,  -98679.6324,\n",
       "         -107130.0526, -115988.5944, -125255.2579, -134930.0429, -145012.9496,\n",
       "         -155503.9779, -166403.1278, -177710.3993, -189425.7925, -201549.3072,\n",
       "         -214080.9436, -227020.7016, -240368.5813, -254124.5825, -268288.7054,\n",
       "         -282860.9499, -297841.3160, -313229.8037, -329026.4131, -345231.1440]),\n",
       " tensor([-748906.5013, -724559.6508, -700620.9218, -677090.3145, -653967.8288,\n",
       "         -631253.4647, -608947.2222, -587049.1014, -565559.1021, -544477.2245,\n",
       "         -523803.4685, -503537.8342, -483680.3214, -464230.9303, -445189.6608,\n",
       "         -426556.5129, -408331.4866, -390514.5820, -373105.7989, -356105.1375,\n",
       "         -339512.5977, -323328.1796, -307551.8830, -292183.7081, -277223.6548,\n",
       "         -262671.7231, -248527.9130, -234792.2246, -221464.6578, -208545.2126,\n",
       "         -196033.8890, -183930.6870, -172235.6067, -160948.6480, -150069.8108,\n",
       "         -139599.0954, -129536.5015, -119882.0293, -110635.6786, -101797.4496,\n",
       "          -93367.3423,  -85345.3565,  -77731.4923,  -70525.7498,  -63728.1289,\n",
       "          -57338.6296,  -51357.2520,  -45783.9959,  -40618.8615,  -35861.8487,\n",
       "          -31512.9575,  -27572.1880,  -24039.5400,  -20915.0137,  -18198.6090,\n",
       "          -15890.3259,  -13990.1645,  -12498.1246,  -11414.2064,  -10738.4098,\n",
       "          -10470.7349,  -10611.1815,  -11159.7498,  -12116.4396,  -13481.2511,\n",
       "          -15254.1843,  -17435.2390,  -20024.4154,  -23021.7134,  -26427.1330,\n",
       "          -30240.6742,  -34462.3370,  -39092.1215,  -44130.0276,  -49576.0553,\n",
       "          -55430.2046,  -61692.4756,  -68362.8681,  -75441.3823,  -82928.0181,\n",
       "          -90822.7756,  -99125.6546, -107836.6553, -116955.7776, -126483.0215,\n",
       "         -136418.3870, -146761.8741, -157513.4829, -168673.2133, -180241.0653,\n",
       "         -192217.0389, -204601.1342, -217393.3511, -230593.6896, -244202.1497,\n",
       "         -258218.7314, -272643.4348, -287476.2597, -302717.2063, -318366.2745]),\n",
       " tensor([-734547.8316, -710514.1836, -686888.6572, -663671.2524, -640861.9692,\n",
       "         -618460.8076, -596467.7677, -574882.8494, -553706.0527, -532937.3776,\n",
       "         -512576.8242, -492624.3923, -473080.0821, -453943.8935, -435215.8266,\n",
       "         -416895.8812, -398984.0575, -381480.3554, -364384.7749, -347697.3160,\n",
       "         -331417.9788, -315546.7631, -300083.6691, -285028.6967, -270381.8460,\n",
       "         -256143.1168, -242312.5093, -228890.0234, -215875.6591, -203269.4164,\n",
       "         -191071.2954, -179281.2959, -167899.4181, -156925.6619, -146360.0274,\n",
       "         -136202.5144, -126453.1231, -117111.8534, -108178.7053,  -99653.6788,\n",
       "          -91536.7740,  -83827.9908,  -76527.3292,  -69634.7892,  -63150.3708,\n",
       "          -57074.0741,  -51405.8989,  -46145.8454,  -41293.9136,  -36850.1033,\n",
       "          -32814.4147,  -29186.8476,  -25967.4022,  -23156.0784,  -20752.8763,\n",
       "          -18757.7957,  -17170.8368,  -15991.9995,  -15221.2838,  -14858.6898,\n",
       "          -14904.2173,  -15357.8665,  -16219.6373,  -17489.5297,  -19167.5438,\n",
       "          -21253.6794,  -23747.9367,  -26650.3156,  -29960.8161,  -33679.4383,\n",
       "          -37806.1820,  -42341.0474,  -47284.0344,  -52635.1430,  -58394.3733,\n",
       "          -64561.7252,  -71137.1986,  -78120.7937,  -85512.5105,  -93312.3488,\n",
       "         -101520.3088, -110136.3904, -119160.5936, -128592.9184, -138433.3648,\n",
       "         -148681.9329, -159338.6226, -170403.4339, -181876.3668, -193757.4214,\n",
       "         -206046.5975, -218743.8953, -231849.3147, -245362.8557, -259284.5184,\n",
       "         -273614.3027, -288352.2086, -303498.2361, -319052.3852, -335014.6559]),\n",
       " tensor([-699861.5166, -676338.9151, -653224.4352, -630518.0770, -608219.8404,\n",
       "         -586329.7254, -564847.7320, -543773.8602, -523108.1101, -502850.4815,\n",
       "         -483000.9746, -463559.5894, -444526.3257, -425901.1836, -407684.1632,\n",
       "         -389875.2644, -372474.4872, -355481.8317, -338897.2977, -322720.8854,\n",
       "         -306952.5947, -291592.4256, -276640.3782, -262096.4523, -247960.6481,\n",
       "         -234232.9655, -220913.4045, -208001.9652, -195498.6474, -183403.4513,\n",
       "         -171716.3768, -160437.4239, -149566.5927, -139103.8830, -129049.2950,\n",
       "         -119402.8286, -110164.4838, -101334.2607,  -92912.1591,  -84898.1792,\n",
       "          -77292.3209,  -70094.5842,  -63304.9692,  -56923.4758,  -50950.1039,\n",
       "          -45384.8537,  -40227.7252,  -35478.7182,  -31137.8329,  -27205.0692,\n",
       "          -23680.4271,  -20563.9066,  -17855.5077,  -15555.2305,  -13663.0749,\n",
       "          -12179.0409,  -11103.1285,  -10435.3378,  -10175.6686,  -10324.1211,\n",
       "          -10880.6952,  -11845.3910,  -13218.2083,  -14999.1473,  -17188.2079,\n",
       "          -19785.3901,  -22790.6939,  -26204.1194,  -30025.6664,  -34255.3351,\n",
       "          -38893.1254,  -43939.0374,  -49393.0709,  -55255.2261,  -61525.5029,\n",
       "          -68203.9013,  -75290.4213,  -82785.0630,  -90687.8262,  -98998.7111,\n",
       "         -107717.7176, -116844.8458, -126380.0955, -136323.4669, -146674.9599,\n",
       "         -157434.5745, -168602.3107, -180178.1686, -192162.1481, -204554.2492,\n",
       "         -217354.4719, -230562.8162, -244179.2822, -258203.8698, -272636.5789,\n",
       "         -287477.4098, -302726.3622, -318383.4363, -334448.6319, -350921.9492]),\n",
       " tensor([-744356.8401, -720171.8878, -696395.0572, -673026.3481, -650065.7607,\n",
       "         -627513.2949, -605368.9507, -583632.7281, -562304.6272, -541384.6478,\n",
       "         -520872.7901, -500769.0541, -481073.4396, -461785.9467, -442906.5755,\n",
       "         -424435.3259, -406372.1979, -388717.1916, -371470.3068, -354631.5437,\n",
       "         -338200.9022, -322178.3823, -306563.9840, -291357.7074, -276559.5524,\n",
       "         -262169.5190, -248187.6072, -234613.8170, -221448.1485, -208690.6016,\n",
       "         -196341.1763, -184399.8726, -172866.6905, -161741.6301, -151024.6913,\n",
       "         -140715.8741, -130815.1785, -121322.6045, -112238.1522, -103561.8215,\n",
       "          -95293.6124,  -87433.5249,  -79981.5590,  -72937.7148,  -66301.9922,\n",
       "          -60074.3912,  -54254.9118,  -48843.5541,  -43840.3179,  -39245.2034,\n",
       "          -35058.2105,  -31279.3392,  -27908.5896,  -24945.9615,  -22391.4551,\n",
       "          -20245.0703,  -18506.8072,  -17176.6656,  -16254.6457,  -15740.7474,\n",
       "          -15634.9707,  -15937.3156,  -16647.7821,  -17766.3703,  -19293.0801,\n",
       "          -21227.9115,  -23570.8645,  -26321.9392,  -29481.1354,  -33048.4533,\n",
       "          -37023.8928,  -41407.4540,  -46199.1367,  -51398.9411,  -57006.8671,\n",
       "          -63022.9147,  -69447.0839,  -76279.3748,  -83519.7872,  -91168.3213,\n",
       "          -99224.9770, -107689.7544, -116562.6533, -125843.6739, -135532.8161,\n",
       "         -145630.0799, -156135.4653, -167048.9724, -178370.6011, -190100.3514,\n",
       "         -202238.2233, -214784.2168, -227738.3320, -241100.5687, -254870.9271,\n",
       "         -269049.4071, -283636.0088, -298630.7320, -314033.5769, -329844.5434]),\n",
       " tensor([-733037.2658, -709137.5889, -685646.0336, -662562.5999, -639887.2879,\n",
       "         -617620.0975, -595761.0287, -574310.0815, -553267.2559, -532632.5520,\n",
       "         -512405.9697, -492587.5090, -473177.1699, -454174.9524, -435580.8566,\n",
       "         -417394.8824, -399617.0298, -382247.2988, -365285.6894, -348732.2017,\n",
       "         -332586.8356, -316849.5911, -301520.4682, -286599.4669, -272086.5873,\n",
       "         -257981.8293, -244285.1929, -230996.6781, -218116.2850, -205644.0134,\n",
       "         -193579.8635, -181923.8352, -170675.9285, -159836.1435, -149404.4800,\n",
       "         -139380.9382, -129765.5180, -120558.2195, -111759.0425, -103367.9872,\n",
       "          -95385.0535,  -87810.2414,  -80643.5509,  -73884.9820,  -67534.5348,\n",
       "          -61592.2092,  -56058.0052,  -50931.9228,  -46213.9621,  -41904.1229,\n",
       "          -38002.4054,  -34508.8095,  -31423.3353,  -28745.9826,  -26476.7516,\n",
       "          -24615.6422,  -23162.6544,  -22117.7882,  -21481.0437,  -21252.4207,\n",
       "          -21431.9194,  -22019.5398,  -23015.2817,  -24419.1452,  -26231.1304,\n",
       "          -28451.2372,  -31079.4656,  -34115.8156,  -37560.2873,  -41412.8806,\n",
       "          -45673.5955,  -50342.4320,  -55419.3901,  -60904.4699,  -66797.6712,\n",
       "          -73098.9942,  -79808.4389,  -86926.0051,  -94451.6929, -102385.5024,\n",
       "         -110727.4335, -119477.4862, -128635.6606, -138201.9565, -148176.3741,\n",
       "         -158558.9133, -169349.5741, -180548.3566, -192155.2606, -204170.2863,\n",
       "         -216593.4336, -229424.7025, -242664.0931, -256311.6052, -270367.2390,\n",
       "         -284830.9944, -299702.8714, -314982.8701, -330670.9903, -346767.2322]),\n",
       " tensor([-643747.2889, -621085.7928, -598832.4183, -576987.1654, -555550.0341,\n",
       "         -534521.0244, -513900.1364, -493687.3699, -473882.7251, -454486.2020,\n",
       "         -435497.8004, -416917.5204, -398745.3621, -380981.3254, -363625.4103,\n",
       "         -346677.6169, -330137.9450, -314006.3948, -298282.9662, -282967.6592,\n",
       "         -268060.4739, -253561.4101, -239470.4680, -225787.6475, -212512.9486,\n",
       "         -199646.3714, -187187.9157, -175137.5817, -163495.3693, -152261.2785,\n",
       "         -141435.3094, -131017.4618, -121007.7359, -111406.1316, -102212.6489,\n",
       "          -93427.2879,  -85050.0484,  -77080.9306,  -69519.9344,  -62367.0599,\n",
       "          -55622.3069,  -49285.6756,  -43357.1658,  -37836.7777,  -32724.5113,\n",
       "          -28020.3664,  -23724.3432,  -19836.4416,  -16356.6616,  -13285.0032,\n",
       "          -10621.4664,   -8366.0513,   -6518.7578,   -5079.5859,   -4048.5356,\n",
       "           -3425.6070,   -3210.7999,   -3404.1145,   -4005.5507,   -5015.1086,\n",
       "           -6432.7880,   -8258.5891,  -10492.5118,  -13134.5561,  -16184.7220,\n",
       "          -19643.0096,  -23509.4187,  -27783.9495,  -32466.6019,  -37557.3760,\n",
       "          -43056.2716,  -48963.2889,  -55278.4278,  -62001.6883,  -69133.0704,\n",
       "          -76672.5742,  -84620.1996,  -92975.9465, -101739.8152, -110911.8054,\n",
       "         -120491.9172, -130480.1507, -140876.5058, -151680.9825, -162893.5809,\n",
       "         -174514.3008, -186543.1424, -198980.1056, -211825.1904, -225078.3968,\n",
       "         -238739.7249, -252809.1746, -267286.7459, -282172.4388, -297466.2533,\n",
       "         -313168.1895, -329278.2473, -345796.4266, -362722.7277, -380057.1503]),\n",
       " tensor([-704067.4820, -680482.9512, -657306.5419, -634538.2543, -612178.0883,\n",
       "         -590226.0439, -568682.1211, -547546.3200, -526818.6404, -506499.0825,\n",
       "         -486587.6462, -467084.3316, -447989.1385, -429302.0671, -411023.1173,\n",
       "         -393152.2891, -375689.5825, -358634.9976, -341988.5343, -325750.1926,\n",
       "         -309919.9725, -294497.8740, -279483.8972, -264878.0419, -250680.3083,\n",
       "         -236890.6964, -223509.2060, -210535.8372, -197970.5901, -185813.4646,\n",
       "         -174064.4607, -162723.5785, -151790.8178, -141266.1788, -131149.6614,\n",
       "         -121441.2656, -112140.9915, -103248.8389,  -94764.8080,  -86688.8987,\n",
       "          -79021.1110,  -71761.4449,  -64909.9005,  -58466.4777,  -52431.1765,\n",
       "          -46803.9969,  -41584.9389,  -36774.0026,  -32371.1879,  -28376.4948,\n",
       "          -24789.9233,  -21611.4735,  -18841.1452,  -16478.9386,  -14524.8536,\n",
       "          -12978.8902,  -11841.0485,  -11111.3283,  -10789.7298,  -10876.2529,\n",
       "          -11370.8976,  -12273.6640,  -13584.5519,  -15303.5615,  -17430.6927,\n",
       "          -19965.9456,  -22909.3200,  -26260.8161,  -30020.4338,  -34188.1731,\n",
       "          -38764.0340,  -43748.0165,  -49140.1207,  -54940.3465,  -61148.6939,\n",
       "          -67765.1629,  -74789.7536,  -82222.4658,  -90063.2997,  -98312.2552,\n",
       "         -106969.3324, -116034.5311, -125507.8515, -135389.2935, -145678.8571,\n",
       "         -156376.5423, -167482.3492, -178996.2776, -190918.3277, -203248.4994,\n",
       "         -215986.7928, -229133.2077, -242687.7443, -256650.4025, -271021.1823,\n",
       "         -285800.0837, -300987.1068, -316582.2514, -332585.5177, -348996.9057]),\n",
       " tensor([-696894.1508, -673415.4383, -650344.8474, -627682.3781, -605428.0304,\n",
       "         -583581.8043, -562143.6999, -541113.7170, -520491.8558, -500278.1163,\n",
       "         -480472.4983, -461075.0020, -442085.6272, -423504.3741, -405331.2426,\n",
       "         -387566.2328, -370209.3445, -353260.5779, -336719.9329, -320587.4095,\n",
       "         -304863.0078, -289546.7276, -274638.5691, -260138.5322, -246046.6169,\n",
       "         -232362.8233, -219087.1512, -206219.6008, -193760.1720, -181708.8648,\n",
       "         -170065.6793, -158830.6153, -148003.6730, -137584.8523, -127574.1532,\n",
       "         -117971.5758, -108777.1199,  -99990.7857,  -91612.5731,  -83642.4822,\n",
       "          -76080.5128,  -68926.6651,  -62180.9389,  -55843.3344,  -49913.8516,\n",
       "          -44392.4903,  -39279.2507,  -34574.1327,  -30277.1363,  -26388.2615,\n",
       "          -22907.5083,  -19834.8768,  -17170.3669,  -14913.9786,  -13065.7119,\n",
       "          -11625.5669,  -10593.5434,   -9969.6416,   -9753.8614,   -9946.2029,\n",
       "          -10546.6659,  -11555.2506,  -12971.9569,  -14796.7848,  -17029.7343,\n",
       "          -19670.8055,  -22719.9982,  -26177.3126,  -30042.7486,  -34316.3063,\n",
       "          -38997.9855,  -44087.7864,  -49585.7089,  -55491.7530,  -61805.9187,\n",
       "          -68528.2061,  -75658.6150,  -83197.1456,  -91143.7978,  -99498.5717,\n",
       "         -108261.4671, -117432.4842, -127011.6229, -136998.8832, -147394.2651,\n",
       "         -158197.7687, -169409.3939, -181029.1407, -193057.0091, -205492.9991,\n",
       "         -218337.1108, -231589.3441, -245249.6990, -259318.1755, -273794.7736,\n",
       "         -288679.4934, -303972.3347, -319673.2977, -335782.3824, -352299.5886]),\n",
       " tensor([-702337.9917, -678737.8051, -655545.7402, -632761.7969, -610385.9752,\n",
       "         -588418.2752, -566858.6968, -545707.2399, -524963.9048, -504628.6912,\n",
       "         -484701.5992, -465182.6289, -446071.7802, -427369.0531, -409074.4476,\n",
       "         -391187.9638, -373709.6016, -356639.3609, -339977.2420, -323723.2446,\n",
       "         -307877.3688, -292439.6147, -277409.9822, -262788.4713, -248575.0821,\n",
       "         -234769.8144, -221372.6684, -208383.6440, -195802.7412, -183629.9600,\n",
       "         -171865.3005, -160508.7626, -149560.3462, -139020.0516, -128887.8785,\n",
       "         -119163.8271, -109847.8972, -100940.0890,  -92440.4024,  -84348.8375,\n",
       "          -76665.3941,  -69390.0724,  -62522.8723,  -56063.7938,  -50012.8370,\n",
       "          -44370.0017,  -39135.2881,  -34308.6961,  -29890.2257,  -25879.8770,\n",
       "          -22277.6498,  -19083.5443,  -16297.5604,  -13919.6981,  -11949.9575,\n",
       "          -10388.3384,   -9234.8410,   -8489.4652,   -8152.2110,   -8223.0785,\n",
       "           -8702.0675,   -9589.1782,  -10884.4105,  -12587.7644,  -14699.2400,\n",
       "          -17218.8371,  -20146.5559,  -23482.3963,  -27226.3583,  -31378.4420,\n",
       "          -35938.6472,  -40906.9741,  -46283.4226,  -52067.9928,  -58260.6845,\n",
       "          -64861.4979,  -71870.4329,  -79287.4895,  -87112.6677,  -95345.9675,\n",
       "         -103987.3890, -113036.9321, -122494.5968, -132360.3831, -142634.2911,\n",
       "         -153316.3206, -164406.4718, -175904.7446, -187811.1391, -200125.6551,\n",
       "         -212848.2928, -225979.0521, -239517.9330, -253464.9355, -267820.0597,\n",
       "         -282583.3054, -297754.6728, -313334.1618, -329321.7725, -345717.5047]),\n",
       " tensor([-689559.4691, -666253.2675, -643355.1876, -620865.2292, -598783.3925,\n",
       "         -577109.6774, -555844.0839, -534986.6120, -514537.2617, -494496.0331,\n",
       "         -474862.9261, -455637.9407, -436821.0769, -418412.3348, -400411.7142,\n",
       "         -382819.2153, -365634.8380, -348858.5824, -332490.4483, -316530.4359,\n",
       "         -300978.5451, -285834.7759, -271099.1283, -256771.6024, -242852.1980,\n",
       "         -229340.9153, -216237.7543, -203542.7148, -191255.7969, -179377.0007,\n",
       "         -167906.3261, -156843.7731, -146189.3417, -135943.0320, -126104.8439,\n",
       "         -116674.7774, -107652.8325,  -99039.0092,  -90833.3076,  -83035.7275,\n",
       "          -75646.2691,  -68664.9324,  -62091.7172,  -55926.6236,  -50169.6517,\n",
       "          -44820.8014,  -39880.0727,  -35347.4657,  -31222.9802,  -27506.6164,\n",
       "          -24198.3742,  -21298.2536,  -18806.2547,  -16722.3773,  -15046.6216,\n",
       "          -13778.9875,  -12919.4750,  -12468.0842,  -12424.8149,  -12789.6673,\n",
       "          -13562.6413,  -14743.7369,  -16332.9541,  -18330.2930,  -20735.7535,\n",
       "          -23549.3356,  -26771.0393,  -30400.8647,  -34438.8116,  -38884.8802,\n",
       "          -43739.0704,  -49001.3822,  -54671.8157,  -60750.3707,  -67237.0474,\n",
       "          -74131.8457,  -81434.7656,  -89145.8072,  -97264.9703, -105792.2551,\n",
       "         -114727.6615, -124071.1896, -133822.8392, -143982.6105, -154550.5034,\n",
       "         -165526.5179, -176910.6540, -188702.9117, -200903.2911, -213511.7921,\n",
       "         -226528.4147, -239953.1589, -253786.0248, -268027.0122, -282676.1213,\n",
       "         -297733.3520, -313198.7044, -329072.1783, -345353.7739, -362043.4911]),\n",
       " tensor([-708229.3650, -684406.1696, -660991.0958, -637984.1436, -615385.3131,\n",
       "         -593194.6042, -571412.0169, -550037.5512, -529071.2072, -508512.9847,\n",
       "         -488362.8839, -468620.9047, -449287.0471, -430361.3112, -411843.6969,\n",
       "         -393734.2041, -376032.8330, -358739.5836, -341854.4557, -325377.4495,\n",
       "         -309308.5649, -293647.8019, -278395.1605, -263550.6408, -249114.2426,\n",
       "         -235085.9661, -221465.8112, -208253.7780, -195449.8663, -183054.0763,\n",
       "         -171066.4079, -159486.8611, -148315.4359, -137552.1324, -127196.9504,\n",
       "         -117249.8901, -107710.9515,  -98580.1344,  -89857.4389,  -81542.8651,\n",
       "          -73636.4129,  -66138.0823,  -59047.8733,  -52365.7860,  -46091.8203,\n",
       "          -40225.9762,  -34768.2537,  -29718.6528,  -25077.1736,  -20843.8160,\n",
       "          -17018.5799,  -13601.4656,  -10592.4728,   -7991.6017,   -5798.8521,\n",
       "           -4014.2242,   -2637.7179,   -1669.3333,   -1109.0702,    -956.9288,\n",
       "           -1212.9090,   -1877.0108,   -2949.2343,   -4429.5793,   -6318.0460,\n",
       "           -8614.6343,  -11319.3442,  -14432.1758,  -17953.1289,  -21882.2037,\n",
       "          -26219.4001,  -30964.7181,  -36118.1578,  -41679.7190,  -47649.4019,\n",
       "          -54027.2064,  -60813.1325,  -68007.1803,  -75609.3497,  -83619.6406,\n",
       "          -92038.0532, -100864.5875, -110099.2433, -119742.0208, -129792.9199,\n",
       "         -140251.9406, -151119.0829, -162394.3468, -174077.7324, -186169.2396,\n",
       "         -198668.8684, -211576.6188, -224892.4909, -238616.4845, -252748.5998,\n",
       "         -267288.8367, -282237.1952, -297593.6754, -313358.2772, -329531.0005]),\n",
       " tensor([-642106.3728, -619454.3541, -597210.4570, -575374.6815, -553947.0276,\n",
       "         -532927.4953, -512316.0847, -492112.7957, -472317.6283, -452930.5825,\n",
       "         -433951.6583, -415380.8558, -397218.1749, -379463.6156, -362117.1779,\n",
       "         -345178.8618, -328648.6674, -312526.5946, -296812.6434, -281506.8138,\n",
       "         -266609.1058, -252119.5195, -238038.0548, -224364.7117, -211099.4902,\n",
       "         -198242.3904, -185793.4121, -173752.5555, -162119.8205, -150895.2071,\n",
       "         -140078.7154, -129670.3452, -119670.0967, -110077.9698, -100893.9646,\n",
       "          -92118.0809,  -83750.3189,  -75790.6785,  -68239.1597,  -61095.7625,\n",
       "          -54360.4869,  -48033.3330,  -42114.3007,  -36603.3900,  -31500.6009,\n",
       "          -26805.9335,  -22519.3877,  -18640.9635,  -15170.6609,  -12108.4799,\n",
       "           -9454.4205,   -7208.4828,   -5370.6667,   -3940.9722,   -2919.3993,\n",
       "           -2305.9481,   -2100.6185,   -2303.4105,   -2914.3241,   -3933.3593,\n",
       "           -5360.5162,   -7195.7946,   -9439.1947,  -12090.7164,  -15150.3598,\n",
       "          -18618.1247,  -22494.0113,  -26778.0195,  -31470.1493,  -36570.4007,\n",
       "          -42078.7738,  -47995.2685,  -54319.8848,  -61052.6227,  -68193.4822,\n",
       "          -75742.4634,  -83699.5662,  -92064.7906, -100838.1366, -110019.6042,\n",
       "         -119609.1935, -129606.9043, -140012.7368, -150826.6910, -162048.7667,\n",
       "         -173678.9641, -185717.2830, -198163.7236, -211018.2859, -224280.9697,\n",
       "         -237951.7752, -252030.7022, -266517.7509, -281412.9213, -296716.2132,\n",
       "         -312427.6268, -328547.1619, -345074.8187, -362010.5972, -379354.4972]),\n",
       " tensor([-689325.3443, -665990.1105, -643062.9984, -620544.0079, -598433.1390,\n",
       "         -576730.3918, -555435.7661, -534549.2621, -514070.8797, -494000.6189,\n",
       "         -474338.4798, -455084.4622, -436238.5663, -417800.7920, -399771.1393,\n",
       "         -382149.6083, -364936.1989, -348130.9110, -331733.7448, -315744.7003,\n",
       "         -300163.7773, -284990.9760, -270226.2963, -255869.7382, -241921.3017,\n",
       "         -228380.9868, -215248.7936, -202524.7220, -190208.7720, -178300.9436,\n",
       "         -166801.2369, -155709.6517, -145026.1882, -134750.8463, -124883.6261,\n",
       "         -115424.5274, -106373.5504,  -97730.6950,  -89495.9612,  -81669.3490,\n",
       "          -74250.8585,  -67240.4895,  -60638.2422,  -54444.1165,  -48658.1124,\n",
       "          -43280.2300,  -38310.4692,  -33748.8300,  -29595.3124,  -25849.9164,\n",
       "          -22512.6421,  -19583.4893,  -17062.4582,  -14949.5487,  -13244.7609,\n",
       "          -11948.0946,  -11059.5500,  -10579.1270,  -10506.8256,  -10842.6458,\n",
       "          -11586.5877,  -12738.6512,  -14298.8363,  -16267.1430,  -18643.5713,\n",
       "          -21428.1213,  -24620.7928,  -28221.5860,  -32230.5008,  -36647.5373,\n",
       "          -41472.6953,  -46705.9750,  -52347.3763,  -58396.8992,  -64854.5438,\n",
       "          -71720.3099,  -78994.1977,  -86676.2071,  -94766.3381, -103264.5908,\n",
       "         -112170.9650, -121485.4609, -131208.0784, -141338.8175, -151877.6783,\n",
       "         -162824.6606, -174179.7646, -185942.9902, -198114.3374, -210693.8063,\n",
       "         -223681.3967, -237077.1088, -250880.9425, -265092.8978, -279712.9748,\n",
       "         -294741.1733, -310177.4935, -326021.9353, -342274.4987, -358935.1838]),\n",
       " tensor([-670553.7067, -647417.0736, -624688.5621, -602368.1722, -580455.9039,\n",
       "         -558951.7573, -537855.7323, -517167.8289, -496888.0471, -477016.3870,\n",
       "         -457552.8485, -438497.4315, -419850.1363, -401610.9626, -383779.9105,\n",
       "         -366356.9801, -349342.1713, -332735.4841, -316536.9185, -300746.4746,\n",
       "         -285364.1523, -270389.9516, -255823.8725, -241665.9150, -227916.0792,\n",
       "         -214574.3649, -201640.7723, -189115.3013, -176997.9520, -165288.7242,\n",
       "         -153987.6181, -143094.6336, -132609.7707, -122533.0295, -112864.4098,\n",
       "         -103603.9118,  -94751.5354,  -86307.2806,  -78271.1474,  -70643.1359,\n",
       "          -63423.2460,  -56611.4777,  -50207.8310,  -44212.3059,  -38624.9025,\n",
       "          -33445.6207,  -28674.4605,  -24311.4219,  -20356.5049,  -16809.7096,\n",
       "          -13671.0359,  -10940.4838,   -8618.0533,   -6703.7444,   -5197.5572,\n",
       "           -4099.4916,   -3409.5476,   -3127.7252,   -3254.0244,   -3788.4453,\n",
       "           -4730.9878,   -6081.6519,   -7840.4376,  -10007.3449,  -12582.3739,\n",
       "          -15565.5245,  -18956.7967,  -22756.1905,  -26963.7060,  -31579.3430,\n",
       "          -36603.1017,  -42034.9820,  -47874.9839,  -54123.1075,  -60779.3527,\n",
       "          -67843.7194,  -75316.2078,  -83196.8179,  -91485.5495, -100182.4028,\n",
       "         -109287.3777, -118800.4742, -128721.6923, -139051.0321, -149788.4934,\n",
       "         -160934.0764, -172487.7810, -184449.6073, -196819.5551, -209597.6246,\n",
       "         -222783.8157, -236378.1284, -250380.5627, -264791.1186, -279609.7962,\n",
       "         -294836.5954, -310471.5162, -326514.5587, -342965.7227, -359825.0084]),\n",
       " tensor([-659285.2513, -636426.4380, -613975.7464, -591933.1764, -570298.7279,\n",
       "         -549072.4011, -528254.1960, -507844.1124, -487842.1505, -468248.3102,\n",
       "         -449062.5915, -430284.9944, -411915.5190, -393954.1651, -376400.9329,\n",
       "         -359255.8223, -342518.8333, -326189.9660, -310269.2203, -294756.5961,\n",
       "         -279652.0937, -264955.7128, -250667.4535, -236787.3159, -223315.2999,\n",
       "         -210251.4055, -197595.6327, -185347.9816, -173508.4521, -162077.0441,\n",
       "         -151053.7579, -140438.5932, -130231.5501, -120432.6287, -111041.8289,\n",
       "         -102059.1507,  -93484.5941,  -85318.1592,  -77559.8459,  -70209.6542,\n",
       "          -63267.5841,  -56733.6356,  -50607.8088,  -44890.1035,  -39580.5199,\n",
       "          -34679.0580,  -30185.7176,  -26100.4988,  -22423.4017,  -19154.4262,\n",
       "          -16293.5723,  -13840.8401,  -11796.2294,  -10159.7404,   -8931.3730,\n",
       "           -8111.1272,   -7699.0031,   -7695.0005,   -8099.1196,   -8911.3603,\n",
       "          -10131.7226,  -11760.2065,  -13796.8121,  -16241.5393,  -19094.3881,\n",
       "          -22355.3585,  -26024.4505,  -30101.6642,  -34586.9995,  -39480.4564,\n",
       "          -44782.0349,  -50491.7350,  -56609.5568,  -63135.5002,  -70069.5652,\n",
       "          -77411.7518,  -85162.0601,  -93320.4899, -101887.0414, -110861.7145,\n",
       "         -120244.5092, -130035.4256, -140234.4635, -150841.6231, -161856.9043,\n",
       "         -173280.3071, -185111.8316, -197351.4777, -209999.2453, -223055.1346,\n",
       "         -236519.1456, -250391.2781, -264671.5323, -279359.9081, -294456.4055,\n",
       "         -309961.0245, -325873.7651, -342194.6274, -358923.6113, -376060.7168]),\n",
       " tensor([-736571.4359, -712371.4393, -688579.5644, -665195.8111, -642220.1794,\n",
       "         -619652.6694, -597493.2809, -575742.0141, -554398.8689, -533463.8454,\n",
       "         -512936.9434, -492818.1631, -473107.5043, -453804.9672, -434910.5518,\n",
       "         -416424.2579, -398346.0857, -380676.0351, -363414.1061, -346560.2987,\n",
       "         -330114.6129, -314077.0488, -298447.6063, -283226.2854, -268413.0861,\n",
       "         -254008.0085, -240011.0524, -226422.2180, -213241.5052, -200468.9141,\n",
       "         -188104.4445, -176148.0966, -164599.8703, -153459.7656, -142727.7825,\n",
       "         -132403.9211, -122488.1812, -112980.5630, -103881.0664,  -95189.6915,\n",
       "          -86906.4381,  -79031.3064,  -71564.2963,  -64505.4078,  -57854.6409,\n",
       "          -51611.9957,  -45777.4720,  -40351.0700,  -35332.7897,  -30722.6309,\n",
       "          -26520.5937,  -22726.6782,  -19340.8843,  -16363.2120,  -13793.6614,\n",
       "          -11632.2323,   -9878.9249,   -8533.7391,   -7596.6749,   -7067.7323,\n",
       "           -6946.9114,   -7234.2121,   -7929.6344,   -9033.1783,  -10544.8438,\n",
       "          -12464.6310,  -14792.5397,  -17528.5701,  -20672.7222,  -24224.9958,\n",
       "          -28185.3911,  -32553.9079,  -37330.5464,  -42515.3065,  -48108.1883,\n",
       "          -54109.1916,  -60518.3166,  -67335.5632,  -74560.9314,  -82194.4213,\n",
       "          -90236.0327,  -98685.7658, -107543.6205, -116809.5969, -126483.6948,\n",
       "         -136565.9144, -147056.2555, -157954.7183, -169261.3028, -180976.0088,\n",
       "         -193098.8365, -205629.7858, -218568.8567, -231916.0492, -245671.3633,\n",
       "         -259834.7991, -274406.3565, -289386.0355, -304773.8361, -320569.7583]),\n",
       " tensor([-686674.2280, -663399.1223, -640532.1382, -618073.2758, -596022.5349,\n",
       "         -574379.9157, -553145.4181, -532319.0422, -511900.7878, -491890.6551,\n",
       "         -472288.6440, -453094.7545, -434308.9866, -415931.3404, -397961.8157,\n",
       "         -380400.4127, -363247.1313, -346501.9716, -330164.9334, -314236.0169,\n",
       "         -298715.2220, -283602.5487, -268897.9970, -254601.5670, -240713.2585,\n",
       "         -227233.0717, -214161.0066, -201497.0630, -189241.2410, -177393.5407,\n",
       "         -165953.9620, -154922.5049, -144299.1695, -134083.9556, -124276.8634,\n",
       "         -114877.8928, -105887.0438,  -97304.3164,  -89129.7107,  -81363.2266,\n",
       "          -74004.8641,  -67054.6232,  -60512.5039,  -54378.5063,  -48652.6303,\n",
       "          -43334.8759,  -38425.2431,  -33923.7319,  -29830.3424,  -26145.0745,\n",
       "          -22867.9282,  -19998.9035,  -17538.0004,  -15485.2190,  -13840.5592,\n",
       "          -12604.0210,  -11775.6044,  -11355.3094,  -11343.1361,  -11739.0844,\n",
       "          -12543.1543,  -13755.3458,  -15375.6589,  -17404.0937,  -19840.6501,\n",
       "          -22685.3281,  -25938.1277,  -29599.0489,  -33668.0918,  -38145.2563,\n",
       "          -43030.5424,  -48323.9501,  -54025.4795,  -60135.1304,  -66652.9030,\n",
       "          -73578.7972,  -80912.8131,  -88654.9505,  -96805.2096, -105363.5903,\n",
       "         -114330.0926, -123704.7165, -133487.4620, -143678.3292, -154277.3180,\n",
       "         -165284.4284, -176699.6604, -188523.0141, -200754.4893, -213394.0862,\n",
       "         -226441.8047, -239897.6449, -253761.6066, -268033.6900, -282713.8950,\n",
       "         -297802.2216, -313298.6698, -329203.2397, -345515.9311, -362236.7442]),\n",
       " tensor([-669074.5547, -646036.0653, -623405.6975, -601183.4514, -579369.3269,\n",
       "         -557963.3240, -536965.4428, -516375.6831, -496194.0451, -476420.5287,\n",
       "         -457055.1339, -438097.8607, -419548.7092, -401407.6793, -383674.7709,\n",
       "         -366349.9843, -349433.3192, -332924.7758, -316824.3539, -301132.0537,\n",
       "         -285847.8751, -270971.8182, -256503.8828, -242444.0691, -228792.3770,\n",
       "         -215548.8065, -202713.3577, -190286.0304, -178266.8248, -166655.7408,\n",
       "         -155452.7784, -144657.9377, -134271.2185, -124292.6210, -114722.1451,\n",
       "         -105559.7908,  -96805.5581,  -88459.4471,  -80521.4577,  -72991.5899,\n",
       "          -65869.8437,  -59156.2192,  -52850.7162,  -46953.3349,  -41464.0752,\n",
       "          -36382.9371,  -31709.9207,  -27445.0258,  -23588.2526,  -20139.6010,\n",
       "          -17099.0710,  -14466.6627,  -12242.3759,  -10426.2108,   -9018.1673,\n",
       "           -8018.2455,   -7426.4452,   -7242.7666,   -7467.2095,   -8099.7742,\n",
       "           -9140.4604,  -10589.2682,  -12446.1977,  -14711.2488,  -17384.4215,\n",
       "          -20465.7158,  -23955.1318,  -27852.6693,  -32158.3285,  -36872.1093,\n",
       "          -41994.0117,  -47524.0358,  -53462.1815,  -59808.4488,  -66562.8377,\n",
       "          -73725.3482,  -81295.9803,  -89274.7341,  -97661.6095, -106456.6065,\n",
       "         -115659.7251, -125270.9654, -135290.3273, -145717.8108, -156553.4159,\n",
       "         -167797.1426, -179448.9910, -191508.9609, -203977.0525, -216853.2657,\n",
       "         -230137.6006, -243830.0570, -257930.6351, -272439.3348, -287356.1561,\n",
       "         -302681.0990, -318414.1636, -334555.3498, -351104.6576, -368062.0870]),\n",
       " tensor([-665194.1424, -642288.8494, -619791.6781, -597702.6284, -576021.7003,\n",
       "         -554748.8938, -533884.2090, -513427.6457, -493379.2041, -473738.8841,\n",
       "         -454506.6857, -435682.6090, -417266.6539, -399258.8204, -381659.1085,\n",
       "         -364467.5182, -347684.0495, -331308.7025, -315341.4771, -299782.3733,\n",
       "         -284631.3911, -269888.5306, -255553.7917, -241627.1743, -228108.6787,\n",
       "         -214998.3046, -202296.0521, -190001.9213, -178115.9121, -166638.0245,\n",
       "         -155568.2585, -144906.6142, -134653.0915, -124807.6904, -115370.4109,\n",
       "         -106341.2530,  -97720.2168,  -89507.3021,  -81702.5091,  -74305.8378,\n",
       "          -67317.2880,  -60736.8598,  -54564.5533,  -48800.3684,  -43444.3051,\n",
       "          -38496.3635,  -33956.5434,  -29824.8450,  -26101.2682,  -22785.8130,\n",
       "          -19878.4794,  -17379.2675,  -15288.1772,  -13605.2085,  -12330.3614,\n",
       "          -11463.6359,  -11005.0321,  -10954.5499,  -11312.1893,  -12077.9503,\n",
       "          -13251.8329,  -14833.8372,  -16823.9631,  -19222.2106,  -22028.5797,\n",
       "          -25243.0704,  -28865.6828,  -32896.4168,  -37335.2724,  -42182.2496,\n",
       "          -47437.3484,  -53100.5689,  -59171.9110,  -65651.3747,  -72538.9600,\n",
       "          -79834.6670,  -87538.4955,  -95650.4457, -104170.5175, -113098.7109,\n",
       "         -122435.0260, -132179.4626, -142332.0209, -152892.7008, -163861.5024,\n",
       "         -175238.4255, -187023.4703, -199216.6367, -211817.9247, -224827.3343,\n",
       "         -238244.8655, -252070.5184, -266304.2929, -280946.1890, -295996.2067,\n",
       "         -311454.3461, -327320.6070, -343594.9896, -360277.4938, -377368.1197]),\n",
       " tensor([-585793.3994, -564170.1697, -542955.0616, -522148.0752, -501749.2104,\n",
       "         -481758.4672, -462175.8456, -443001.3457, -424234.9673, -405876.7106,\n",
       "         -387926.5755, -370384.5620, -353250.6702, -336524.9000, -320207.2513,\n",
       "         -304297.7243, -288796.3190, -273703.0352, -259017.8731, -244740.8326,\n",
       "         -230871.9137, -217411.1164, -204358.4408, -191713.8867, -179477.4543,\n",
       "         -167649.1435, -156228.9543, -145216.8868, -134612.9409, -124417.1166,\n",
       "         -114629.4139, -105249.8328,  -96278.3733,  -87715.0355,  -79559.8193,\n",
       "          -71812.7247,  -64473.7517,  -57542.9004,  -51020.1707,  -44905.5626,\n",
       "          -39199.0761,  -33900.7112,  -29010.4680,  -24528.3463,  -20454.3463,\n",
       "          -16788.4679,  -13530.7112,  -10681.0760,   -8239.5625,   -6206.1706,\n",
       "           -4580.9003,   -3363.7516,   -2554.7246,   -2153.8192,   -2161.0354,\n",
       "           -2576.3732,   -3399.8326,   -4631.4137,   -6271.1164,   -8318.9406,\n",
       "          -10774.8866,  -13638.9541,  -16911.1433,  -20591.4540,  -24679.8864,\n",
       "          -29176.4405,  -34081.1161,  -39393.9133,  -45114.8322,  -51243.8727,\n",
       "          -57781.0348,  -64726.3186,  -72079.7239,  -79841.2509,  -88010.8995,\n",
       "          -96588.6697, -105574.5616, -114968.5750, -124770.7101, -134980.9668,\n",
       "         -145599.3452, -156625.8451, -168060.4667, -179903.2098, -192154.0746,\n",
       "         -204813.0611, -217880.1691, -231355.3988, -245238.7501, -259530.2230,\n",
       "         -274229.8175, -289337.5336, -304853.3714, -320777.3308, -337109.4118,\n",
       "         -353849.6144, -370997.9387, -388554.3845, -406518.9520, -424891.6411]),\n",
       " tensor([-714911.0502, -691080.4155, -667657.9024, -644643.5109, -622037.2411,\n",
       "         -599839.0929, -578049.0663, -556667.1613, -535693.3779, -515127.7162,\n",
       "         -494970.1760, -475220.7575, -455879.4606, -436946.2854, -418421.2317,\n",
       "         -400304.2997, -382595.4893, -365294.8005, -348402.2333, -331917.7878,\n",
       "         -315841.4639, -300173.2615, -284913.1809, -270061.2218, -255617.3843,\n",
       "         -241581.6685, -227954.0743, -214734.6017, -201923.2508, -189520.0214,\n",
       "         -177524.9137, -165937.9276, -154759.0631, -143988.3203, -133625.6990,\n",
       "         -123671.1994, -114124.8214, -104986.5650,  -96256.4302,  -87934.4171,\n",
       "          -80020.5256,  -72514.7557,  -65417.1074,  -58727.5807,  -52446.1757,\n",
       "          -46572.8923,  -41107.7305,  -36050.6903,  -31401.7717,  -27160.9748,\n",
       "          -23328.2995,  -19903.7458,  -16887.3137,  -14279.0032,  -12078.8144,\n",
       "          -10286.7472,   -8902.8016,   -7926.9776,   -7359.2753,   -7199.6945,\n",
       "           -7448.2354,   -8104.8979,   -9169.6820,  -10642.5878,  -12523.6151,\n",
       "          -14812.7641,  -17510.0347,  -20615.4270,  -24128.9408,  -28050.5763,\n",
       "          -32380.3334,  -37118.2121,  -42264.2124,  -47818.3343,  -53780.5779,\n",
       "          -60150.9431,  -66929.4299,  -74116.0383,  -81710.7684,  -89713.6200,\n",
       "          -98124.5933, -106943.6882, -116170.9048, -125806.2429, -135849.7027,\n",
       "         -146301.2841, -157160.9871, -168428.8117, -180104.7580, -192188.8258,\n",
       "         -204681.0153, -217581.3264, -230889.7592, -244606.3135, -258730.9895,\n",
       "         -273263.7871, -288204.7063, -303553.7471, -319310.9096, -335476.1937]),\n",
       " tensor([-744328.8531, -720207.9711, -696495.2108, -673190.5721, -650294.0550,\n",
       "         -627805.6595, -605725.3856, -584053.2334, -562789.2027, -541933.2937,\n",
       "         -521485.5063, -501445.8406, -481814.2964, -462590.8739, -443775.5730,\n",
       "         -425368.3937, -407369.3361, -389778.4000, -372595.5856, -355820.8928,\n",
       "         -339454.3216, -323495.8720, -307945.5441, -292803.3378, -278069.2531,\n",
       "         -263743.2900, -249825.4485, -236315.7287, -223214.1305, -210520.6539,\n",
       "         -198235.2989, -186358.0655, -174888.9538, -163827.9637, -153175.0952,\n",
       "         -142930.3483, -133093.7230, -123665.2194, -114644.8374, -106032.5770,\n",
       "          -97828.4382,  -90032.4210,  -82644.5255,  -75664.7516,  -69093.0993,\n",
       "          -62929.5686,  -57174.1596,  -51826.8721,  -46887.7063,  -42356.6621,\n",
       "          -38233.7395,  -34518.9386,  -31212.2592,  -28313.7015,  -25823.2654,\n",
       "          -23740.9510,  -22066.7581,  -20800.6869,  -19942.7373,  -19492.9093,\n",
       "          -19451.2029,  -19817.6181,  -20592.1550,  -21774.8135,  -23365.5936,\n",
       "          -25364.4953,  -27771.5187,  -30586.6636,  -33809.9302,  -37441.3184,\n",
       "          -41480.8283,  -45928.4597,  -50784.2128,  -56048.0875,  -61720.0838,\n",
       "          -67800.2017,  -74288.4413,  -81184.8024,  -88489.2852,  -96201.8896,\n",
       "         -104322.6157, -112851.4633, -121788.4326, -131133.5235, -140886.7360,\n",
       "         -151048.0701, -161617.5259, -172595.1033, -183980.8023, -195774.6229,\n",
       "         -207976.5651, -220586.6290, -233604.8144, -247031.1215, -260865.5502,\n",
       "         -275108.1006, -289758.7725, -304817.5661, -320284.4813, -336159.5181]),\n",
       " tensor([-683677.8318, -660291.9177, -637314.1251, -614744.4542, -592582.9049,\n",
       "         -570829.4772, -549484.1711, -528546.9867, -508017.9239, -487896.9827,\n",
       "         -468184.1631, -448879.4651, -429982.8888, -411494.4341, -393414.1010,\n",
       "         -375741.8895, -358477.7996, -341621.8314, -325173.9848, -309134.2598,\n",
       "         -293502.6564, -278279.1746, -263463.8145, -249056.5760, -235057.4591,\n",
       "         -221466.4638, -208283.5901, -195508.8381, -183142.2077, -171183.6989,\n",
       "         -159633.3117, -148491.0461, -137756.9022, -127430.8799, -117512.9792,\n",
       "         -108003.2001,  -98901.5427,  -90208.0068,  -81922.5926,  -74045.3000,\n",
       "          -66576.1290,  -59515.0797,  -52862.1520,  -46617.3458,  -40780.6613,\n",
       "          -35352.0985,  -30331.6572,  -25719.3376,  -21515.1396,  -17719.0632,\n",
       "          -14331.1084,  -11351.2753,   -8779.5637,   -6615.9738,   -4860.5055,\n",
       "           -3513.1589,   -2573.9338,   -2042.8304,   -1919.8486,   -2204.9884,\n",
       "           -2898.2498,   -3999.6329,   -5509.1375,   -7426.7638,   -9752.5117,\n",
       "          -12486.3813,  -15628.3724,  -19178.4852,  -23136.7196,  -27503.0756,\n",
       "          -32277.5532,  -37460.1525,  -43050.8733,  -49049.7158,  -55456.6800,\n",
       "          -62271.7657,  -69494.9730,  -77126.3020,  -85165.7526,  -93613.3248,\n",
       "         -102469.0187, -111732.8341, -121404.7712, -131484.8299, -141973.0102,\n",
       "         -152869.3121, -164173.7357, -175886.2809, -188006.9477, -200535.7361,\n",
       "         -213472.6461, -226817.6778, -240570.8311, -254732.1060, -269301.5025,\n",
       "         -284279.0206, -299664.6604, -315458.4218, -331660.3048, -348270.3094]),\n",
       " tensor([-652986.3119, -630143.2954, -607708.4005, -585681.6273, -564062.9756,\n",
       "         -542852.4456, -522050.0372, -501655.7504, -481669.5852, -462091.5416,\n",
       "         -442921.6197, -424159.8194, -405806.1407, -387860.5836, -370323.1482,\n",
       "         -353193.8344, -336472.6422, -320159.5716, -304254.6226, -288757.7953,\n",
       "         -273669.0895, -258988.5054, -244716.0429, -230851.7021, -217395.4828,\n",
       "         -204347.3852, -191707.4092, -179475.5548, -167651.8220, -156236.2109,\n",
       "         -145228.7214, -134629.3535, -124438.1072, -114654.9825, -105279.9795,\n",
       "          -96313.0980,  -87754.3382,  -79603.7000,  -71861.1835,  -64526.7885,\n",
       "          -57600.5152,  -51082.3635,  -44972.3334,  -39270.4250,  -33976.6381,\n",
       "          -29090.9729,  -24613.4293,  -20544.0073,  -16882.7070,  -13629.5282,\n",
       "          -10784.4711,   -8347.5356,   -6318.7217,   -4698.0295,   -3485.4588,\n",
       "           -2681.0098,   -2284.6824,   -2296.4766,   -2716.3925,   -3544.4299,\n",
       "           -4780.5890,   -6424.8697,   -8477.2720,  -10937.7960,  -13806.4415,\n",
       "          -17083.2087,  -20768.0975,  -24861.1079,  -29362.2400,  -34271.4937,\n",
       "          -39588.8689,  -45314.3658,  -51447.9844,  -57989.7245,  -64939.5863,\n",
       "          -72297.5697,  -80063.6747,  -88237.9013,  -96820.2495, -105810.7194,\n",
       "         -115209.3109, -125016.0240, -135230.8587, -145853.8151, -156884.8930,\n",
       "         -168324.0926, -180171.4138, -192426.8567, -205090.4211, -218162.1072,\n",
       "         -231641.9149, -245529.8442, -259825.8951, -274530.0677, -289642.3618,\n",
       "         -305162.7776, -321091.3150, -337427.9741, -354172.7547, -371325.6570]),\n",
       " tensor([-729736.5133, -705755.1252, -682181.8586, -659016.7137, -636259.6904,\n",
       "         -613910.7887, -591970.0086, -570437.3502, -549312.8134, -528596.3982,\n",
       "         -508288.1046, -488387.9326, -468895.8823, -449811.9535, -431136.1464,\n",
       "         -412868.4610, -395008.8971, -377557.4549, -360514.1342, -343878.9352,\n",
       "         -327651.8578, -311832.9021, -296422.0679, -281419.3554, -266824.7645,\n",
       "         -252638.2952, -238859.9476, -225489.7215, -212527.6171, -199973.6343,\n",
       "         -187827.7731, -176090.0336, -164760.4156, -153838.9193, -143325.5446,\n",
       "         -133220.2915, -123523.1601, -114234.1502, -105353.2620,  -96880.4954,\n",
       "          -88815.8505,  -81159.3271,  -73910.9254,  -67070.6452,  -60638.4867,\n",
       "          -54614.4499,  -48998.5346,  -43790.7410,  -38991.0690,  -34599.5186,\n",
       "          -30616.0898,  -27040.7826,  -23873.5971,  -21114.5332,  -18763.5909,\n",
       "          -16820.7702,  -15286.0712,  -14159.4937,  -13441.0379,  -13130.7037,\n",
       "          -13228.4912,  -13734.4002,  -14648.4309,  -15970.5832,  -17700.8571,\n",
       "          -19839.2526,  -22385.7697,  -25340.4085,  -28703.1689,  -32474.0509,\n",
       "          -36653.0545,  -41240.1798,  -46235.4267,  -51638.7951,  -57450.2853,\n",
       "          -63669.8970,  -70297.6303,  -77333.4853,  -84777.4619,  -92629.5601,\n",
       "         -100889.7799, -109558.1214, -118634.5845, -128119.1692, -138011.8755,\n",
       "         -148312.7034, -159021.6530, -170138.7241, -181663.9169, -193597.2314,\n",
       "         -205938.6674, -218688.2250, -231845.9043, -245411.7052, -259385.6277,\n",
       "         -273767.6719, -288557.8376, -303756.1250, -319362.5340, -335377.0646]),\n",
       " tensor([-682129.5212, -658937.0061, -636152.6125, -613776.3406, -591808.1904,\n",
       "         -570248.1617, -549096.2547, -528352.4693, -508016.8055, -488089.2633,\n",
       "         -468569.8428, -449458.5438, -430755.3665, -412460.3108, -394573.3768,\n",
       "         -377094.5643, -360023.8735, -343361.3043, -327106.8567, -311260.5307,\n",
       "         -295822.3264, -280792.2436, -266170.2825, -251956.4430, -238150.7252,\n",
       "         -224753.1289, -211763.6543, -199182.3013, -187009.0699, -175243.9601,\n",
       "         -163886.9720, -152938.1055, -142397.3605, -132264.7373, -122540.2356,\n",
       "         -113223.8556, -104315.5971,  -95815.4603,  -87723.4451,  -80039.5516,\n",
       "          -72763.7796,  -65896.1293,  -59436.6006,  -53385.1935,  -47741.9081,\n",
       "          -42506.7442,  -37679.7020,  -33260.7814,  -29249.9824,  -25647.3050,\n",
       "          -22452.7493,  -19666.3152,  -17288.0027,  -15317.8118,  -13755.7425,\n",
       "          -12601.7949,  -11855.9689,  -11518.2645,  -11588.6817,  -12067.2205,\n",
       "          -12953.8810,  -14248.6631,  -15951.5668,  -18062.5921,  -20581.7390,\n",
       "          -23509.0076,  -26844.3978,  -30587.9096,  -34739.5430,  -39299.2980,\n",
       "          -44267.1747,  -49643.1730,  -55427.2929,  -61619.5344,  -68219.8976,\n",
       "          -75228.3823,  -82644.9887,  -90469.7167,  -98702.5663, -107343.5376,\n",
       "         -116392.6305, -125849.8449, -135715.1810, -145988.6388, -156670.2181,\n",
       "         -167759.9191, -179257.7417, -191163.6859, -203477.7517, -216199.9391,\n",
       "         -229330.2482, -242868.6789, -256815.2312, -271169.9051, -285932.7007,\n",
       "         -301103.6179, -316682.6566, -332669.8171, -349065.0991, -365868.5027]),\n",
       " tensor([-723658.8194, -699733.4405, -676216.1833, -653107.0476, -630406.0336,\n",
       "         -608113.1412, -586228.3705, -564751.7213, -543683.1938, -523022.7879,\n",
       "         -502770.5036, -482926.3409, -463490.2999, -444462.3804, -425842.5826,\n",
       "         -407630.9064, -389827.3519, -372431.9189, -355444.6076, -338865.4179,\n",
       "         -322694.3498, -306931.4034, -291576.5785, -276629.8753, -262091.2937,\n",
       "         -247960.8337, -234238.4953, -220924.2786, -208018.1835, -195520.2100,\n",
       "         -183430.3581, -171748.6278, -160475.0192, -149609.5321, -139152.1667,\n",
       "         -129102.9230, -119461.8008, -110228.8003, -101403.9213,  -92987.1640,\n",
       "          -84978.5284,  -77378.0143,  -70185.6219,  -63401.3510,  -57025.2018,\n",
       "          -51057.1743,  -45497.2683,  -40345.4840,  -35601.8212,  -31266.2801,\n",
       "          -27338.8607,  -23819.5628,  -20708.3866,  -18005.3320,  -15710.3990,\n",
       "          -13823.5876,  -12344.8978,  -11274.3297,  -10611.8832,  -10357.5583,\n",
       "          -10511.3550,  -11073.2733,  -12043.3133,  -13421.4749,  -15207.7581,\n",
       "          -17402.1629,  -20004.6894,  -23015.3374,  -26434.1071,  -30260.9984,\n",
       "          -34496.0114,  -39139.1459,  -44190.4021,  -49649.7799,  -55517.2793,\n",
       "          -61792.9003,  -68476.6429,  -75568.5072,  -83068.4931,  -90976.6006,\n",
       "          -99292.8297, -108017.1805, -117149.6528, -126690.2468, -136638.9624,\n",
       "         -146995.7997, -157760.7585, -168933.8390, -180515.0411, -192504.3648,\n",
       "         -204901.8101, -217707.3771, -230921.0657, -244542.8758, -258572.8077,\n",
       "         -273010.8611, -287857.0361, -303111.3328, -318773.7511, -334844.2910]),\n",
       " tensor([-714483.4126, -690643.0763, -667210.8616, -644186.7686, -621570.7972,\n",
       "         -599362.9474, -577563.2192, -556171.6126, -535188.1277, -514612.7643,\n",
       "         -494445.5226, -474686.4026, -455335.4041, -436392.5273, -417857.7720,\n",
       "         -399731.1384, -382012.6264, -364702.2361, -347799.9673, -331305.8202,\n",
       "         -315219.7947, -299541.8908, -284272.1086, -269410.4479, -254956.9089,\n",
       "         -240911.4915, -227274.1958, -214045.0216, -201223.9691, -188811.0381,\n",
       "         -176806.2288, -165209.5412, -154020.9751, -143240.5307, -132868.2079,\n",
       "         -122904.0067, -113347.9271, -104199.9691,  -95460.1328,  -87128.4181,\n",
       "          -79204.8250,  -71689.3535,  -64582.0036,  -57882.7754,  -51591.6688,\n",
       "          -45708.6838,  -40233.8204,  -35167.0787,  -30508.4585,  -26257.9600,\n",
       "          -22415.5831,  -18981.3279,  -15955.1942,  -13337.1822,  -11127.2918,\n",
       "           -9325.5230,   -7931.8758,   -6946.3503,   -6368.9463,   -6199.6640,\n",
       "           -6438.5033,   -7085.4643,   -8140.5468,   -9603.7510,  -11475.0768,\n",
       "          -13754.5242,  -16442.0932,  -19537.7839,  -23041.5961,  -26953.5300,\n",
       "          -31273.5855,  -36001.7627,  -41138.0614,  -46682.4818,  -52635.0238,\n",
       "          -58995.6874,  -65764.4726,  -72941.3795,  -80526.4080,  -88519.5581,\n",
       "          -96920.8298, -105730.2231, -114947.7381, -124573.3746, -134607.1328,\n",
       "         -145049.0126, -155899.0141, -167157.1371, -178823.3818, -190897.7481,\n",
       "         -203380.2360, -216270.8456, -229569.5767, -243276.4295, -257391.4039,\n",
       "         -271914.4999, -286845.7176, -302185.0568, -317932.5177, -334088.1002]),\n",
       " tensor([-710093.7217, -686310.5573, -662935.5146, -639968.5934, -617409.7939,\n",
       "         -595259.1160, -573516.5597, -552182.1250, -531255.8120, -510737.6205,\n",
       "         -490627.5507, -470925.6025, -451631.7760, -432746.0710, -414268.4877,\n",
       "         -396199.0260, -378537.6859, -361284.4674, -344439.3706, -328002.3953,\n",
       "         -311973.5417, -296352.8097, -281140.1994, -266335.7106, -251939.3435,\n",
       "         -237951.0980, -224370.9741, -211198.9719, -198435.0912, -186079.3322,\n",
       "         -174131.6948, -162592.1790, -151460.7848, -140737.5123, -130422.3614,\n",
       "         -120515.3321, -111016.4244, -101925.6383,  -93242.9739,  -84968.4311,\n",
       "          -77102.0098,  -69643.7103,  -62593.5323,  -55951.4760,  -49717.5412,\n",
       "          -43891.7281,  -38474.0367,  -33464.4668,  -28863.0186,  -24669.6919,\n",
       "          -20884.4869,  -17507.4036,  -14538.4418,  -11977.6017,   -9824.8831,\n",
       "           -8080.2862,   -6743.8110,   -5815.4573,   -5295.2253,   -5183.1149,\n",
       "           -5479.1261,   -6183.2589,   -7295.5133,   -8815.8894,  -10744.3871,\n",
       "          -13081.0064,  -15825.7473,  -18978.6098,  -22539.5940,  -26508.6998,\n",
       "          -30885.9272,  -35671.2762,  -40864.7469,  -46466.3391,  -52476.0530,\n",
       "          -58893.8885,  -65719.8457,  -72953.9244,  -80596.1248,  -88646.4468,\n",
       "          -97104.8904, -105971.4556, -115246.1424, -124928.9509, -135019.8810,\n",
       "         -145518.9327, -156426.1060, -167741.4010, -179464.8176, -191596.3557,\n",
       "         -204136.0156, -217083.7970, -230439.7000, -244203.7247, -258375.8710,\n",
       "         -272956.1389, -287944.5284, -303341.0396, -319145.6724, -335358.4268]),\n",
       " tensor([-740536.9267, -716390.2163, -692651.6275, -669321.1603, -646398.8148,\n",
       "         -623884.5909, -601778.4885, -580080.5078, -558790.6488, -537908.9113,\n",
       "         -517435.2955, -497369.8013, -477712.4287, -458463.1777, -439622.0483,\n",
       "         -421189.0406, -403164.1545, -385547.3900, -368338.7471, -351538.2259,\n",
       "         -335145.8263, -319161.5482, -303585.3919, -288417.3571, -273657.4439,\n",
       "         -259305.6524, -245361.9825, -231826.4342, -218699.0075, -205979.7025,\n",
       "         -193668.5190, -181765.4572, -170270.5171, -159183.6985, -148505.0015,\n",
       "         -138234.4262, -128371.9725, -118917.6404, -109871.4299, -101233.3411,\n",
       "          -93003.3739,  -85181.5283,  -77767.8043,  -70762.2019,  -64164.7212,\n",
       "          -57975.3620,  -52194.1245,  -46821.0087,  -41856.0144,  -37299.1417,\n",
       "          -33150.3907,  -29409.7613,  -26077.2535,  -23152.8674,  -20636.6028,\n",
       "          -18528.4599,  -16828.4386,  -15536.5389,  -14652.7609,  -14177.1044,\n",
       "          -14109.5696,  -14450.1564,  -15198.8648,  -16355.6948,  -17920.6465,\n",
       "          -19893.7198,  -22274.9147,  -25064.2312,  -28261.6693,  -31867.2291,\n",
       "          -35880.9105,  -40302.7135,  -45132.6381,  -50370.6843,  -56016.8522,\n",
       "          -62071.1417,  -68533.5528,  -75404.0855,  -82682.7399,  -90369.5158,\n",
       "          -98464.4134, -106967.4326, -115878.5734, -125197.8359, -134925.2199,\n",
       "         -145060.7256, -155604.3529, -166556.1018, -177915.9724, -189683.9646,\n",
       "         -201860.0783, -214444.3137, -227436.6708, -240837.1494, -254645.7497,\n",
       "         -268862.4716, -283487.3151, -298520.2802, -313961.3670, -329810.5753]),\n",
       " tensor([-680044.9094, -656890.9768, -634145.1659, -611807.4765, -589877.9088,\n",
       "         -568356.4627, -547243.1382, -526537.9353, -506240.8541, -486351.8945,\n",
       "         -466871.0565, -447798.3401, -429133.7453, -410877.2722, -393028.9207,\n",
       "         -375588.6908, -358556.5825, -341932.5958, -325716.7308, -309908.9874,\n",
       "         -294509.3656, -279517.8654, -264934.4869, -250759.2299, -236992.0946,\n",
       "         -223633.0809, -210682.1888, -198139.4184, -186004.7695, -174278.2423,\n",
       "         -162959.8367, -152049.5527, -141547.3904, -131453.3497, -121767.4305,\n",
       "         -112489.6330, -103619.9572,  -95158.4029,  -87104.9703,  -79459.6593,\n",
       "          -72222.4699,  -65393.4021,  -58972.4559,  -52959.6314,  -47354.9285,\n",
       "          -42158.3472,  -37369.8875,  -32989.5495,  -29017.3330,  -25453.2382,\n",
       "          -22297.2650,  -19549.4135,  -17209.6835,  -15278.0752,  -13754.5885,\n",
       "          -12639.2234,  -11931.9799,  -11632.8581,  -11741.8578,  -12258.9792,\n",
       "          -13184.2222,  -14517.5869,  -16259.0731,  -18408.6810,  -20966.4105,\n",
       "          -23932.2616,  -27306.2343,  -31088.3287,  -35278.5447,  -39876.8823,\n",
       "          -44883.3415,  -50297.9223,  -56120.6248,  -62351.4488,  -68990.3945,\n",
       "          -76037.4618,  -83492.6508,  -91355.9613,  -99627.3935, -108306.9473,\n",
       "         -117394.6227, -126890.4198, -136794.3384, -147106.3787, -157826.5406,\n",
       "         -168954.8241, -180491.2292, -192435.7560, -204788.4044, -217549.1744,\n",
       "         -230718.0660, -244295.0792, -258280.2141, -272673.4706, -287474.8487,\n",
       "         -302684.3484, -318301.9697, -334327.7127, -350761.5773, -367603.5635]),\n",
       " tensor([-659754.6672, -636919.6327, -614492.7199, -592473.9287, -570863.2591,\n",
       "         -549660.7111, -528866.2847, -508479.9800, -488501.7969, -468931.7354,\n",
       "         -449769.7955, -431015.9773, -412670.2806, -394732.7056, -377203.2522,\n",
       "         -360081.9205, -343368.7103, -327063.6218, -311166.6549, -295677.8096,\n",
       "         -280597.0859, -265924.4838, -251660.0034, -237803.6446, -224355.4074,\n",
       "         -211315.2918, -198683.2979, -186459.4256, -174643.6749, -163236.0458,\n",
       "         -152236.5383, -141645.1525, -131461.8882, -121686.7456, -112319.7246,\n",
       "         -103360.8253,  -94810.0475,  -86667.3914,  -78932.8569,  -71606.4440,\n",
       "          -64688.1527,  -58177.9831,  -52075.9351,  -46382.0086,  -41096.2039,\n",
       "          -36218.5207,  -31748.9592,  -27687.5192,  -24034.2009,  -20789.0042,\n",
       "          -17951.9292,  -15522.9757,  -13502.1439,  -11889.4337,  -10684.8451,\n",
       "           -9888.3782,   -9500.0328,   -9519.8091,   -9947.7070,  -10783.7265,\n",
       "          -12027.8676,  -13680.1304,  -15740.5148,  -18209.0208,  -21085.6484,\n",
       "          -24370.3976,  -28063.2685,  -32164.2610,  -36673.3751,  -41590.6108,\n",
       "          -46915.9681,  -52649.4471,  -58791.0477,  -65340.7699,  -72298.6137,\n",
       "          -79664.5792,  -87438.6662,  -95620.8749, -104211.2052, -113209.6571,\n",
       "         -122616.2307, -132430.9258, -142653.7426, -153284.6810, -164323.7410,\n",
       "         -175770.9227, -187626.2260, -199889.6508, -212561.1973, -225640.8655,\n",
       "         -239128.6552, -253024.5666, -267328.5996, -282040.7542, -297161.0304,\n",
       "         -312689.4282, -328625.9477, -344970.5888, -361723.3515, -378884.2358]),\n",
       " tensor([-669875.1675, -646851.9006, -624236.7553, -602029.7316, -580230.8296,\n",
       "         -558840.0491, -537857.3903, -517282.8531, -497116.4376, -477358.1436,\n",
       "         -458007.9713, -439065.9206, -420531.9915, -402406.1840, -384688.4982,\n",
       "         -367378.9339, -350477.4913, -333984.1703, -317898.9710, -302221.8932,\n",
       "         -286952.9371, -272092.1026, -257639.3897, -243594.7984, -229958.3288,\n",
       "         -216729.9807, -203909.7543, -191497.6495, -179493.6664, -167897.8048,\n",
       "         -156710.0649, -145930.4466, -135558.9499, -125595.5748, -116040.3214,\n",
       "         -106893.1896,  -98154.1794,  -89823.2908,  -81900.5238,  -74385.8785,\n",
       "          -67279.3547,  -60580.9526,  -54290.6722,  -48408.5133,  -42934.4761,\n",
       "          -37868.5604,  -33210.7664,  -28961.0940,  -25119.5433,  -21686.1141,\n",
       "          -18660.8066,  -16043.6207,  -13834.5564,  -12033.6138,  -10640.7927,\n",
       "           -9656.0933,   -9079.5155,   -8911.0593,   -9150.7248,   -9798.5118,\n",
       "          -10854.4205,  -12318.4508,  -14190.6027,  -16470.8763,  -19159.2714,\n",
       "          -22255.7882,  -25760.4266,  -29673.1866,  -33994.0683,  -38723.0715,\n",
       "          -43860.1964,  -49405.4429,  -55358.8111,  -61720.3008,  -68489.9122,\n",
       "          -75667.6451,  -83253.4998,  -91247.4760,  -99649.5738, -108459.7933,\n",
       "         -117678.1344, -127304.5971, -137339.1814, -147781.8874, -158632.7149,\n",
       "         -169891.6641, -181558.7349, -193633.9273, -206117.2414, -219008.6771,\n",
       "         -232308.2343, -246015.9132, -260131.7138, -274655.6359, -289587.6797,\n",
       "         -304927.8451, -320676.1321, -336832.5407, -353397.0710, -370369.7228]),\n",
       " tensor([-689584.3447, -666276.2276, -643376.2320, -620884.3581, -598800.6058,\n",
       "         -577124.9752, -555857.4661, -534998.0787, -514546.8129, -494503.6687,\n",
       "         -474868.6461, -455641.7452, -436822.9658, -418412.3081, -400409.7720,\n",
       "         -382815.3576, -365629.0647, -348850.8935, -332480.8439, -316518.9159,\n",
       "         -300965.1095, -285819.4248, -271081.8616, -256752.4201, -242831.1003,\n",
       "         -229317.9020, -216212.8253, -203515.8703, -191227.0369, -179346.3251,\n",
       "         -167873.7350, -156809.2664, -146152.9195, -135904.6942, -126064.5905,\n",
       "         -116632.6084, -107608.7480,  -98993.0092,  -90785.3920,  -82985.8964,\n",
       "          -75594.5224,  -68611.2701,  -62036.1394,  -55869.1303,  -50110.2428,\n",
       "          -44759.4769,  -39816.8327,  -35282.3101,  -31155.9091,  -27437.6297,\n",
       "          -24127.4719,  -21225.4358,  -18731.5213,  -16645.7284,  -14968.0571,\n",
       "          -13698.5074,  -12837.0794,  -12383.7730,  -12338.5882,  -12701.5250,\n",
       "          -13472.5834,  -14651.7635,  -16239.0652,  -18234.4885,  -20638.0334,\n",
       "          -23449.6999,  -26669.4881,  -30297.3979,  -34333.4293,  -38777.5823,\n",
       "          -43629.8570,  -48890.2532,  -54558.7711,  -60635.4106,  -67120.1717,\n",
       "          -74013.0545,  -81314.0589,  -89023.1848,  -97140.4325, -105665.8017,\n",
       "         -114599.2925, -123940.9050, -133690.6391, -143848.4948, -154414.4721,\n",
       "         -165388.5711, -176770.7916, -188561.1338, -200759.5976, -213366.1831,\n",
       "         -226380.8901, -239803.7188, -253634.6691, -267873.7410, -282520.9345,\n",
       "         -297576.2497, -313039.6864, -328911.2448, -345190.9248, -361878.7265]),\n",
       " tensor([-759806.7248, -735353.0292, -711307.4553, -687670.0031, -664440.6724,\n",
       "         -641619.4634, -619206.3759, -597201.4101, -575604.5660, -554415.8434,\n",
       "         -533635.2425, -513262.7632, -493298.4055, -473742.1694, -454594.0549,\n",
       "         -435854.0621, -417522.1909, -399598.4413, -382082.8133, -364975.3070,\n",
       "         -348275.9222, -331984.6591, -316101.5176, -300626.4977, -285559.5995,\n",
       "         -270900.8229, -256650.1678, -242807.6345, -229373.2227, -216346.9325,\n",
       "         -203728.7640, -191518.7171, -179716.7918, -168322.9881, -157337.3061,\n",
       "         -146759.7456, -136590.3068, -126828.9896, -117475.7941, -108530.7201,\n",
       "          -99993.7678,  -91864.9371,  -84144.2280,  -76831.6405,  -69927.1747,\n",
       "          -63430.8305,  -57342.6078,  -51662.5069,  -46390.5275,  -41526.6697,\n",
       "          -37070.9336,  -33023.3191,  -29383.8262,  -26152.4550,  -23329.2053,\n",
       "          -20914.0773,  -18907.0709,  -17308.1861,  -16117.4229,  -15334.7814,\n",
       "          -14960.2615,  -14993.8632,  -15435.5865,  -16285.4314,  -17543.3980,\n",
       "          -19209.4861,  -21283.6959,  -23766.0274,  -26656.4804,  -29955.0551,\n",
       "          -33661.7513,  -37776.5692,  -42299.5087,  -47230.5699,  -52569.7526,\n",
       "          -58317.0570,  -64472.4830,  -71036.0306,  -78007.6999,  -85387.4907,\n",
       "          -93175.4032, -101371.4373, -109975.5930, -118987.8704, -128408.2693,\n",
       "         -138236.7899, -148473.4321, -159118.1960, -170171.0814, -181632.0885,\n",
       "         -193501.2171, -205778.4674, -218463.8394, -231557.3329, -245058.9481,\n",
       "         -258968.6849, -273286.5433, -288012.5233, -303146.6249, -318688.8482]),\n",
       " tensor([-709898.7556, -686338.6484, -663186.6628, -640442.7989, -618107.0565,\n",
       "         -596179.4358, -574659.9367, -553548.5592, -532845.3034, -512550.1692,\n",
       "         -492663.1566, -473184.2656, -454113.4962, -435450.8484, -417196.3223,\n",
       "         -399349.9178, -381911.6349, -364881.4736, -348259.4340, -332045.5160,\n",
       "         -316239.7196, -300842.0448, -285852.4916, -271271.0600, -257097.7501,\n",
       "         -243332.5618, -229975.4951, -217026.5501, -204485.7266, -192353.0248,\n",
       "         -180628.4446, -169311.9860, -158403.6490, -147903.4337, -137811.3400,\n",
       "         -128127.3678, -118851.5174, -109983.7885, -101524.1813,  -93472.6956,\n",
       "          -85829.3316,  -78594.0892,  -71766.9685,  -65347.9693,  -59337.0918,\n",
       "          -53734.3359,  -48539.7016,  -43753.1890,  -39374.7979,  -35404.5285,\n",
       "          -31842.3807,  -28688.3545,  -25942.4500,  -23604.6670,  -21675.0057,\n",
       "          -20153.4660,  -19040.0479,  -18334.7515,  -18037.5766,  -18148.5234,\n",
       "          -18667.5918,  -19594.7818,  -20930.0935,  -22673.5267,  -24825.0816,\n",
       "          -27384.7581,  -30352.5562,  -33728.4760,  -37512.5173,  -41704.6803,\n",
       "          -46304.9649,  -51313.3711,  -56729.8990,  -62554.5484,  -68787.3195,\n",
       "          -75428.2122,  -82477.2266,  -89934.3625,  -97799.6201, -106072.9993,\n",
       "         -114754.5001, -123844.1225, -133341.8665, -143247.7322, -153561.7195,\n",
       "         -164283.8284, -175414.0589, -186952.4111, -198898.8848, -211253.4802,\n",
       "         -224016.1972, -237187.0359, -250765.9961, -264753.0780, -279148.2815,\n",
       "         -293951.6066, -309163.0533, -324782.6217, -340810.3116, -357246.1232]),\n",
       " tensor([-695434.4598, -672040.6334, -649054.9286, -626477.3455, -604307.8839,\n",
       "         -582546.5440, -561193.3257, -540248.2291, -519711.2540, -499582.4006,\n",
       "         -479861.6688, -460549.0586, -441644.5700, -423148.2031, -405059.9577,\n",
       "         -387379.8340, -370107.8319, -353243.9515, -336788.1926, -320740.5554,\n",
       "         -305101.0398, -289869.6458, -275046.3734, -260631.2227, -246624.1936,\n",
       "         -233025.2860, -219834.5002, -207051.8359, -194677.2932, -182710.8722,\n",
       "         -171152.5728, -160002.3950, -149260.3389, -138926.4043, -129000.5914,\n",
       "         -119482.9001, -110373.3304, -101671.8823,  -93378.5559,  -85493.3511,\n",
       "          -78016.2679,  -70947.3063,  -64286.4663,  -58033.7480,  -52189.1513,\n",
       "          -46752.6761,  -41724.3227,  -37104.0908,  -32891.9806,  -29087.9919,\n",
       "          -25692.1249,  -22704.3796,  -20124.7558,  -17953.2537,  -16189.8731,\n",
       "          -14834.6142,  -13887.4770,  -13348.4613,  -13217.5673,  -13494.7948,\n",
       "          -14180.1440,  -15273.6149,  -16775.2073,  -18684.9214,  -21002.7570,\n",
       "          -23728.7144,  -26862.7933,  -30404.9938,  -34355.3160,  -38713.7598,\n",
       "          -43480.3252,  -48655.0122,  -54237.8208,  -60228.7511,  -66627.8030,\n",
       "          -73434.9765,  -80650.2716,  -88273.6884,  -96305.2267, -104744.8867,\n",
       "         -113592.6683, -122848.5715, -132512.5964, -142584.7429, -153065.0109,\n",
       "         -163953.4006, -175249.9120, -186954.5449, -199067.2995, -211588.1757,\n",
       "         -224517.1735, -237854.2929, -251599.5340, -265752.8966, -280314.3809,\n",
       "         -295283.9868, -310661.7144, -326447.5635, -342641.5343, -359243.6267]),\n",
       " tensor([-728433.8895, -704421.2796, -680816.7912, -657620.4245, -634832.1793,\n",
       "         -612452.0558, -590480.0539, -568916.1737, -547760.4150, -527012.7780,\n",
       "         -506673.2626, -486741.8688, -467218.5967, -448103.4461, -429396.4172,\n",
       "         -411097.5099, -393206.7242, -375724.0602, -358649.5177, -341983.0969,\n",
       "         -325724.7977, -309874.6201, -294432.5642, -279398.6298, -264772.8171,\n",
       "         -250555.1260, -236745.5565, -223344.1087, -210350.7824, -197765.5778,\n",
       "         -185588.4948, -173819.5334, -162458.6937, -151505.9755, -140961.3790,\n",
       "         -130824.9041, -121096.5509, -111776.3192, -102864.2092,  -94360.2207,\n",
       "          -86264.3539,  -78576.6088,  -71296.9852,  -64425.4833,  -57962.1030,\n",
       "          -51906.8443,  -46259.7072,  -41020.6918,  -36189.7979,  -31767.0257,\n",
       "          -27752.3751,  -24145.8461,  -20947.4388,  -18157.1531,  -15774.9889,\n",
       "          -13800.9465,  -12235.0256,  -11077.2263,  -10327.5487,   -9985.9927,\n",
       "          -10052.5583,  -10527.2455,  -11410.0544,  -12700.9848,  -14400.0369,\n",
       "          -16507.2106,  -19022.5060,  -21945.9229,  -25277.4615,  -29017.1217,\n",
       "          -33164.9035,  -37720.8069,  -42684.8320,  -48056.9787,  -53837.2470,\n",
       "          -60025.6369,  -66622.1484,  -73626.7816,  -81039.5363,  -88860.4127,\n",
       "          -97089.4107, -105726.5304, -114771.7716, -124225.1345, -134086.6190,\n",
       "         -144356.2251, -155033.9529, -166119.8022, -177613.7732, -189515.8658,\n",
       "         -201826.0800, -214544.4158, -227670.8733, -241205.4524, -255148.1531,\n",
       "         -269498.9754, -284257.9193, -299424.9849, -315000.1721, -330983.4809]),\n",
       " tensor([-698479.6414, -674938.3845, -651805.2491, -629080.2354, -606763.3433,\n",
       "         -584854.5728, -563353.9239, -542261.3967, -521576.9910, -501300.7070,\n",
       "         -481432.5446, -461972.5039, -442920.5847, -424276.7872, -406041.1113,\n",
       "         -388213.5570, -370794.1243, -353782.8133, -337179.6238, -320984.5560,\n",
       "         -305197.6098, -289818.7853, -274848.0823, -260285.5010, -246131.0413,\n",
       "         -232384.7032, -219046.4867, -206116.3919, -193594.4187, -181480.5671,\n",
       "         -169774.8371, -158477.2287, -147587.7420, -137106.3769, -127033.1333,\n",
       "         -117368.0115, -108111.0112,  -99262.1326,  -90821.3755,  -82788.7401,\n",
       "          -75164.2263,  -67947.8342,  -61139.5636,  -54739.4147,  -48747.3874,\n",
       "          -43163.4817,  -37987.6977,  -33220.0352,  -28860.4944,  -24909.0752,\n",
       "          -21365.7776,  -18230.6017,  -15503.5473,  -13184.6146,  -11273.8035,\n",
       "           -9771.1140,   -8676.5462,   -7990.0999,   -7711.7753,   -7841.5723,\n",
       "           -8379.4910,   -9325.5312,  -10679.6931,  -12441.9765,  -14612.3816,\n",
       "          -17190.9084,  -20177.5567,  -23572.3267,  -27375.2183,  -31586.2315,\n",
       "          -36205.3663,  -41232.6227,  -46668.0008,  -52511.5005,  -58763.1218,\n",
       "          -65422.8647,  -72490.7293,  -79966.7154,  -87850.8232,  -96143.0526,\n",
       "         -104843.4037, -113951.8763, -123468.4706, -133393.1865, -143726.0240,\n",
       "         -154466.9831, -165616.0638, -177173.2662, -189138.5902, -201512.0358,\n",
       "         -214293.6030, -227483.2919, -241081.1024, -255087.0345, -269501.0882,\n",
       "         -284323.2635, -299553.5604, -315191.9790, -331238.5192, -347693.1810]),\n",
       " tensor([-690893.0544, -667526.4351, -644567.9374, -622017.5613, -599875.3069,\n",
       "         -578141.1740, -556815.1628, -535897.2732, -515387.5053, -495285.8589,\n",
       "         -475592.3342, -456306.9311, -437429.6496, -418960.4897, -400899.4515,\n",
       "         -383246.5349, -366001.7399, -349165.0665, -332736.5147, -316716.0846,\n",
       "         -301103.7760, -285899.5891, -271103.5238, -256715.5802, -242735.7581,\n",
       "         -229164.0577, -216000.4789, -203245.0217, -190897.6862, -178958.4722,\n",
       "         -167427.3799, -156304.4092, -145589.5601, -135282.8327, -125384.2268,\n",
       "         -115893.7426, -106811.3800,  -98137.1390,  -89871.0197,  -82013.0219,\n",
       "          -74563.1458,  -67521.3913,  -60887.7584,  -54662.2472,  -48844.8575,\n",
       "          -43435.5895,  -38434.4431,  -33841.4183,  -29656.5152,  -25879.7336,\n",
       "          -22511.0737,  -19550.5354,  -16998.1187,  -14853.8237,  -13117.6502,\n",
       "          -11789.5984,  -10869.6682,  -10357.8596,  -10254.1727,  -10558.6074,\n",
       "          -11271.1636,  -12391.8415,  -13920.6411,  -15857.5622,  -18202.6050,\n",
       "          -20955.7694,  -24117.0554,  -27686.4630,  -31663.9923,  -36049.6431,\n",
       "          -40843.4156,  -46045.3097,  -51655.3254,  -57673.4628,  -64099.7218,\n",
       "          -70934.1023,  -78176.6046,  -85827.2284,  -93885.9738, -102352.8409,\n",
       "         -111227.8296, -120510.9399, -130202.1718, -140301.5254, -150809.0006,\n",
       "         -161724.5973, -173048.3158, -184780.1558, -196920.1174, -209468.2007,\n",
       "         -222424.4056, -235788.7321, -249561.1802, -263741.7500, -278330.4414,\n",
       "         -293327.2544, -308732.1890, -324545.2452, -340766.4231, -357395.7225]),\n",
       " tensor([-721524.5494, -697609.7039, -674102.9799, -651004.3775, -628313.8968,\n",
       "         -606031.5377, -584157.3002, -562691.1843, -541633.1901, -520983.3175,\n",
       "         -500741.5665, -480907.9371, -461482.4293, -442465.0432, -423855.7786,\n",
       "         -405654.6357, -387861.6144, -370476.7148, -353499.9367, -336931.2803,\n",
       "         -320770.7455, -305018.3323, -289674.0407, -274737.8708, -260209.8225,\n",
       "         -246089.8958, -232378.0907, -219074.4072, -206178.8454, -193691.4051,\n",
       "         -181612.0865, -169940.8896, -158677.8142, -147822.8605, -137376.0283,\n",
       "         -127337.3178, -117706.7289, -108484.2617,  -99669.9160,  -91263.6920,\n",
       "          -83265.5896,  -75675.6088,  -68493.7497,  -61720.0121,  -55354.3962,\n",
       "          -49396.9019,  -43847.5292,  -38706.2782,  -33973.1487,  -29648.1409,\n",
       "          -25731.2547,  -22222.4902,  -19121.8472,  -16429.3259,  -14144.9261,\n",
       "          -12268.6480,  -10800.4916,   -9740.4567,   -9088.5435,   -8844.7519,\n",
       "           -9009.0819,   -9581.5335,  -10562.1067,  -11950.8016,  -13747.6181,\n",
       "          -15952.5562,  -18565.6159,  -21586.7973,  -25016.1002,  -28853.5248,\n",
       "          -33099.0710,  -37752.7388,  -42814.5283,  -48284.4394,  -54162.4720,\n",
       "          -60448.6263,  -67142.9023,  -74245.2998,  -81755.8190,  -89674.4598,\n",
       "          -98001.2222, -106736.1062, -115879.1119, -125430.2391, -135389.4880,\n",
       "         -145756.8585, -156532.3507, -167715.9644, -179307.6998, -191307.5568,\n",
       "         -203715.5354, -216531.6356, -229755.8575, -243388.2009, -257428.6660,\n",
       "         -271877.2527, -286733.9611, -301998.7910, -317671.7426, -333752.8158]),\n",
       " tensor([-743655.8506, -719436.4144, -695625.0998, -672221.9069, -649226.8355,\n",
       "         -626639.8858, -604461.0577, -582690.3512, -561327.7664, -540373.3032,\n",
       "         -519826.9615, -499688.7415, -479958.6432, -460636.6664, -441722.8113,\n",
       "         -423217.0778, -405119.4659, -387429.9756, -370148.6070, -353275.3599,\n",
       "         -336810.2345, -320753.2307, -305104.3486, -289863.5880, -275030.9491,\n",
       "         -260606.4318, -246590.0361, -232981.7620, -219781.6096, -206989.5787,\n",
       "         -194605.6695, -182629.8820, -171062.2160, -159902.6716, -149151.2489,\n",
       "         -138807.9478, -128872.7683, -119345.7105, -110226.7742, -101515.9596,\n",
       "          -93213.2666,  -85318.6952,  -77832.2454,  -70753.9173,  -64083.7108,\n",
       "          -57821.6259,  -51967.6626,  -46521.8209,  -41484.1009,  -36854.5024,\n",
       "          -32633.0256,  -28819.6705,  -25414.4369,  -22417.3250,  -19828.3346,\n",
       "          -17647.4659,  -15874.7188,  -14510.0934,  -13553.5895,  -13005.2073,\n",
       "          -12864.9467,  -13132.8077,  -13808.7904,  -14892.8946,  -16385.1205,\n",
       "          -18285.4680,  -20593.9371,  -23310.5279,  -26435.2402,  -29968.0742,\n",
       "          -33909.0298,  -38258.1071,  -43015.3059,  -48180.6264,  -53754.0684,\n",
       "          -59735.6321,  -66125.3175,  -72923.1244,  -80129.0530,  -87743.1032,\n",
       "          -95765.2750, -104195.5684, -113033.9834, -122280.5201, -131935.1784,\n",
       "         -141997.9583, -152468.8598, -163347.8830, -174635.0277, -186330.2941,\n",
       "         -198433.6821, -210945.1918, -223864.8230, -237192.5759, -250928.4504,\n",
       "         -265072.4465, -279624.5642, -294584.8035, -309953.1645, -325729.6471]),\n",
       " tensor([-744609.9595, -720438.6502, -696675.4624, -673320.3963, -650373.4518,\n",
       "         -627834.6289, -605703.9277, -583981.3481, -562666.8900, -541760.5536,\n",
       "         -521262.3389, -501172.2457, -481490.2742, -462216.4243, -443350.6960,\n",
       "         -424893.0893, -406843.6043, -389202.2408, -371968.9990, -355143.8788,\n",
       "         -338726.8803, -322718.0033, -307117.2480, -291924.6143, -277140.1022,\n",
       "         -262763.7117, -248795.4429, -235235.2956, -222083.2700, -209339.3660,\n",
       "         -197003.5837, -185075.9229, -173556.3838, -162444.9663, -151741.6704,\n",
       "         -141446.4961, -131559.4435, -122080.5125, -113009.7031, -104347.0153,\n",
       "          -96092.4491,  -88246.0046,  -80807.6816,  -73777.4803,  -67155.4007,\n",
       "          -60941.4426,  -55135.6061,  -49737.8913,  -44748.2981,  -40166.8265,\n",
       "          -35993.4766,  -32228.2482,  -28871.1415,  -25922.1564,  -23381.2929,\n",
       "          -21248.5511,  -19523.9308,  -18207.4322,  -17299.0552,  -16798.7998,\n",
       "          -16706.6661,  -17022.6539,  -17746.7634,  -18878.9945,  -20419.3472,\n",
       "          -22367.8216,  -24724.4175,  -27489.1351,  -30661.9743,  -34242.9351,\n",
       "          -38232.0176,  -42629.2216,  -47434.5473,  -52647.9946,  -58269.5635,\n",
       "          -64299.2541,  -70737.0662,  -77583.0000,  -84837.0554,  -92499.2325,\n",
       "         -100569.5311, -109047.9514, -117934.4933, -127229.1568, -136931.9419,\n",
       "         -147042.8486, -157561.8770, -168489.0270, -179824.2986, -191567.6918,\n",
       "         -203719.2067, -216278.8431, -229246.6012, -242622.4809, -256406.4822,\n",
       "         -270598.6052, -285198.8498, -300207.2160, -315623.7038, -331448.3132]),\n",
       " tensor([-734508.0291, -710477.7677, -686855.6279, -663641.6097, -640835.7132,\n",
       "         -618437.9383, -596448.2850, -574866.7533, -553693.3432, -532928.0548,\n",
       "         -512570.8880, -492621.8428, -473080.9192, -453948.1172, -435223.4369,\n",
       "         -416906.8782, -398998.4411, -381498.1256, -364405.9318, -347721.8595,\n",
       "         -331445.9089, -315578.0799, -300118.3725, -285066.7868, -270423.3226,\n",
       "         -256187.9801, -242360.7592, -228941.6599, -215930.6823, -203327.8263,\n",
       "         -191133.0918, -179346.4790, -167967.9879, -156997.6183, -146435.3704,\n",
       "         -136281.2441, -126535.2394, -117197.3563, -108267.5948,  -99745.9550,\n",
       "          -91632.4368,  -83927.0402,  -76629.7652,  -69740.6119,  -63259.5802,\n",
       "          -57186.6700,  -51521.8816,  -46265.2147,  -41416.6694,  -36976.2458,\n",
       "          -32943.9438,  -29319.7634,  -26103.7046,  -23295.7675,  -20895.9520,\n",
       "          -18904.2580,  -17320.6858,  -16145.2351,  -15377.9060,  -15018.6986,\n",
       "          -15067.6128,  -15524.6486,  -16389.8061,  -17663.0851,  -19344.4858,\n",
       "          -21434.0081,  -23931.6520,  -26837.4175,  -30151.3047,  -33873.3135,\n",
       "          -38003.4438,  -42541.6959,  -47488.0695,  -52842.5648,  -58605.1816,\n",
       "          -64775.9201,  -71354.7802,  -78341.7620,  -85736.8653,  -93540.0903,\n",
       "         -101751.4369, -110370.9051, -119398.4950, -128834.2064, -138678.0395,\n",
       "         -148929.9942, -159590.0705, -170658.2685, -182134.5880, -194019.0292,\n",
       "         -206311.5920, -219012.2764, -232121.0825, -245638.0101, -259563.0594,\n",
       "         -273896.2303, -288637.5228, -303786.9370, -319344.4727, -335310.1301]),\n",
       " tensor([-713788.4795, -690018.1733, -666655.9887, -643701.9257, -621155.9844,\n",
       "         -599018.1647, -577288.4666, -555966.8901, -535053.4352, -514548.1020,\n",
       "         -494450.8903, -474761.8003, -455480.8319, -436607.9852, -418143.2600,\n",
       "         -400086.6565, -382438.1746, -365197.8143, -348365.5757, -331941.4586,\n",
       "         -315925.4632, -300317.5894, -285117.8372, -270326.2066, -255942.6977,\n",
       "         -241967.3104, -228400.0447, -215240.9006, -202489.8781, -190146.9773,\n",
       "         -178212.1981, -166685.5405, -155567.0045, -144856.5901, -134554.2974,\n",
       "         -124660.1263, -115174.0768, -106096.1489,  -97426.3426,  -89164.6580,\n",
       "          -81311.0950,  -73865.6536,  -66828.3338,  -60199.1356,  -53978.0591,\n",
       "          -48165.1042,  -42760.2709,  -37763.5592,  -33174.9691,  -28994.5007,\n",
       "          -25222.1539,  -21857.9287,  -18901.8251,  -16353.8432,  -14213.9828,\n",
       "          -12482.2441,  -11158.6270,  -10243.1315,   -9735.7577,   -9636.5054,\n",
       "           -9945.3748,  -10662.3658,  -11787.4785,  -13320.7127,  -15262.0686,\n",
       "          -17611.5461,  -20369.1452,  -23534.8659,  -27108.7083,  -31090.6722,\n",
       "          -35480.7578,  -40278.9650,  -45485.2938,  -51099.7443,  -57122.3164,\n",
       "          -63553.0101,  -70391.8254,  -77638.7623,  -85293.8208,  -93357.0010,\n",
       "         -101828.3028, -110707.7262, -119995.2712, -129690.9379, -139794.7262,\n",
       "         -150306.6361, -161226.6676, -172554.8207, -184291.0955, -196435.4918,\n",
       "         -208988.0098, -221948.6494, -235317.4107, -249094.2935, -263279.2980,\n",
       "         -277872.4241, -292873.6718, -308283.0411, -324100.5321, -340326.1447]),\n",
       " tensor([-778387.9315, -753409.3082, -728838.8066, -704676.4265, -680922.1680,\n",
       "         -657576.0312, -634638.0160, -612108.1224, -589986.3505, -568272.7001,\n",
       "         -546967.1714, -526069.7643, -505580.4788, -485499.3149, -465826.2727,\n",
       "         -446561.3521, -427704.5531, -409255.8757, -391215.3199, -373582.8858,\n",
       "         -356358.5732, -339542.3823, -323134.3131, -307134.3654, -291542.5394,\n",
       "         -276358.8349, -261583.2521, -247215.7909, -233256.4514, -219705.2334,\n",
       "         -206562.1371, -193827.1624, -181500.3093, -169581.5779, -158070.9680,\n",
       "         -146968.4798, -136274.1132, -125987.8682, -116109.7449, -106639.7432,\n",
       "          -97577.8630,  -88924.1045,  -80678.4677,  -72840.9524,  -65411.5588,\n",
       "          -58390.2867,  -51777.1363,  -45572.1076,  -39775.2004,  -34386.4149,\n",
       "          -29405.7510,  -24833.2087,  -20668.7880,  -16912.4889,  -13564.3115,\n",
       "          -10624.2557,   -8092.3215,   -5968.5089,   -4252.8180,   -2945.2486,\n",
       "           -2045.8009,   -1554.4748,   -1471.2704,   -1796.1875,   -2529.2263,\n",
       "           -3670.3867,   -5219.6687,   -7177.0723,   -9542.5975,  -12316.2444,\n",
       "          -15498.0129,  -19087.9030,  -23085.9147,  -27492.0481,  -32306.3031,\n",
       "          -37528.6797,  -43159.1779,  -49197.7977,  -55644.5391,  -62499.4022,\n",
       "          -69762.3869,  -77433.4932,  -85512.7212,  -94000.0707, -102895.5419,\n",
       "         -112199.1347, -121910.8491, -132030.6851, -142558.6428, -153494.7220,\n",
       "         -164838.9229, -176591.2455, -188751.6896, -201320.2553, -214296.9427,\n",
       "         -227681.7517, -241474.6823, -255675.7346, -270284.9084, -285302.2039])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "195e569f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(log_probs_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a259651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
