{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1aa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# !wget \"http://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\" --no-check-certificate\n",
    "data = pd.read_excel('ENB2012_data.xlsx', header=0).iloc[:, :10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240997c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from torch import nn\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import HMC, MCMC, SVI, NUTS, TraceMeanField_ELBO\n",
    "from pyro import poutine\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange\n",
    "from rec.utils import kl_estimate_with_mc\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f82ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Laplace_GCN_Code.preds.laplace import Laplace\n",
    "from Laplace_GCN_Code.preds.likelihoods import GaussianLh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c277c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3e5bc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "x_ = data.iloc[:, 1:-1].values\n",
    "y_ = data.iloc[:, -1].values.reshape(-1, 1)\n",
    "\n",
    "np.random.seed(0)\n",
    "shuffle_idxs = np.arange(x_.shape[0])\n",
    "np.random.shuffle(shuffle_idxs)\n",
    "\n",
    "num_train = int(x_.shape[0] * 0.5)\n",
    "train_idxs = shuffle_idxs[:num_train]\n",
    "test_idxs = shuffle_idxs[:num_train]\n",
    "x_train = x_[train_idxs]\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train - x_m) / x_s\n",
    "x_test = x_[test_idxs]\n",
    "x_test = (x_test - x_m) / x_s\n",
    "y_train = y_[train_idxs]\n",
    "y_test = y_[test_idxs]\n",
    "\n",
    "D_in = x_train.shape[-1]\n",
    "D_out = 10\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_test= torch.FloatTensor(x_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1dfbdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(x, y=None, weights=None, in_size=1, num_nodes=10, out_size=1, ELBO_BETA=1.):\n",
    "    # sample vector of weights for regression\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    # sample params\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        weights = pyro.sample(\"weights\", dist.Normal(torch.zeros(total_weights), 1.).to_event(1))\n",
    "\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    logits = x.squeeze()\n",
    "    \n",
    "    with pyro.plate(\"data\", x.shape[0]):\n",
    "        obs = pyro.sample(\"obs\", dist.Categorical(logits=logits).to_event(1), obs=y)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "def make_empirical_gmm(samples, num_nodes, x_test):\n",
    "    rho_noise = samples['params'][:, -D_out:]\n",
    "    noise = F.softplus(rho_noise) ** 2\n",
    "    preds_dict = Predictive(regression_model, samples, return_sites=['_RETURN'])(x_test, None, num_nodes=num_nodes,\n",
    "                                                                                 in_size=D_in, out_size=D_out)\n",
    "    preds = preds_dict['_RETURN']\n",
    "    mix = dist.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = dist.MultivariateNormal(loc=preds.squeeze().permute(1, 0, 2), covariance_matrix=torch.diag_embed(noise))\n",
    "    gmm = dist.MixtureSameFamily(mix, comp)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "71944c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class map_regression_model(nn.Module):\n",
    "    def __init__(self, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(map_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "        self.fc1_weights = nn.Parameter(torch.randn(self.num_nodes, self.in_size))\n",
    "        self.fc1_bias = nn.Parameter(torch.randn(self.num_nodes))\n",
    "\n",
    "        self.fc2_weights = nn.Parameter(torch.randn(self.num_nodes, self.num_nodes))\n",
    "        self.fc2_bias = nn.Parameter(torch.randn(self.num_nodes))\n",
    "\n",
    "        self.fc3_weights = nn.Parameter(torch.randn(self.out_size, self.num_nodes))\n",
    "        self.fc3_bias = nn.Parameter(torch.randn(self.out_size))\n",
    "\n",
    "        self.rho = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    # compute forward pass\n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "\n",
    "        return x  \n",
    "    \n",
    "    def loss_function(self, x, y):\n",
    "        y_preds = self.forward(x)\n",
    "        return -D.Normal(loc=y_preds, scale=F.softplus(self.rho)).log_prob(y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9e035560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deterministic_regression_model(nn.Module):\n",
    "    def __init__(self, params, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(deterministic_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "        weights, rho = params[:-out_size], params[-out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes *self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx +self.out_size].reshape(self.out_size)\n",
    "        idx +=self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params\n",
    "\n",
    "        # compute forward pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def weight_prior_lp(self):\n",
    "        return dist.Normal(loc=0., scale=1.).log_prob(self.params).mean()\n",
    "    \n",
    "    def data_likelihood(self, x, y):\n",
    "        likelihood = dist.Normal(loc=self.forward(x),\n",
    "                              scale=F.softplus(self.rho))\n",
    "        return likelihood.log_prob(y).sum(-1).mean()\n",
    "    \n",
    "    def joint_log_prob(self, x, y):\n",
    "        return self.data_likelihood(x, y) + self.weight_prior_lp(x, y)\n",
    "    \n",
    "    def make_weights_from_sample(self, params):\n",
    "        weights, rho = params[:-self.out_size], params[-self.out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes * self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx + self.out_size].reshape(self.out_size)\n",
    "        idx += self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f8f31aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 5/2000 [00:00, 29.61it/s, step size=5.22e-06, acc. prob=0.200]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-45065cf035e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnuts_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_accept_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tree_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmcmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmcmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mELBO_BETA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mELBO_BETA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/poutine/messenger.py\u001b[0m in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_context_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/mcmc/api.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# requires_grad\", which happens with `jit_compile` under PyTorch 1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchain_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0mnum_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchain_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/mcmc/api.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mhook_w_logging\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_logging_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             for sample in _gen_samples(self.kernel, self.warmup_steps, self.num_samples, hook_w_logging,\n\u001b[0m\u001b[1;32m    170\u001b[0m                                        \u001b[0mi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_chains\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                                        *args, **kwargs):\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/mcmc/api.py\u001b[0m in \u001b[0;36m_gen_samples\u001b[0;34m(kernel, warmup_steps, num_samples, hook, chain_id, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarmup_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Warmup [{}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchain_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'Warmup'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/mcmc/hmc.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;31m# NaNs are expected during step size adaptation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_t\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warmup_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             z_new, r_new, z_grads_new, potential_energy_new = velocity_verlet(\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotential_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmass_matrix_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinetic_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 self.step_size, self.num_steps, z_grads=z_grads)\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/ops/integrator.py\u001b[0m in \u001b[0;36mvelocity_verlet\u001b[0;34m(z, r, potential_fn, kinetic_grad, step_size, num_steps, z_grads)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mr_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         z_next, r_next, z_grads, potential_energy = _single_step_verlet(z_next,\n\u001b[0m\u001b[1;32m     31\u001b[0m                                                                         \u001b[0mr_next\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                                         \u001b[0mpotential_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/ops/integrator.py\u001b[0m in \u001b[0;36m_single_step_verlet\u001b[0;34m(z, r, potential_fn, kinetic_grad, step_size, z_grads)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mr_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite_name\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# z(n+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mz_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotential_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotential_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpotential_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msite_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# r(n+1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/ops/integrator.py\u001b[0m in \u001b[0;36mpotential_grad\u001b[0;34m(potential_fn, z)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mpotential_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpotential_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;31m# deal with singular matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/mcmc/util.py\u001b[0m in \u001b[0;36m_potential_fn\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         model_trace = poutine.trace(cond_model).get_trace(*self.model_args,\n\u001b[1;32m    261\u001b[0m                                                           **self.model_kwargs)\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mlog_joint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_prob_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             log_joint = log_joint - torch.sum(\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/mcmc/util.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, model_trace)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_enumerable_sites\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_log_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mshared_intermediates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mlog_prob_sum\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    195\u001b[0m                         raise ValueError(\"Error while computing log_prob_sum at site '{}':\\n{}\\n{}\\n\"\n\u001b[1;32m    196\u001b[0m                                          .format(name, exc_value, shapes)).with_traceback(traceback) from e\n\u001b[0;32m--> 197\u001b[0;31m                     \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_and_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                     \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log_prob_sum\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/util.py\u001b[0m in \u001b[0;36mscale_and_mask\u001b[0;34m(tensor, scale, mask)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \"\"\"\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_identically_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_identically_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/util.py\u001b[0m in \u001b[0;36mis_identically_zero\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(10)\n",
    "ELBO_BETA = 1.\n",
    "S=0\n",
    "num_nodes = 50\n",
    "\n",
    "# run HMC\n",
    "kernel = HMC(classification_model, step_size=0.001, num_steps=5, target_accept_prob=0.8)\n",
    "nuts_kernel = NUTS(classification_model, step_size=0.1, target_accept_prob=0.5, max_tree_depth=5)\n",
    "mcmc = MCMC(kernel, num_samples=1000, warmup_steps=1000, num_chains=1)\n",
    "mcmc.run(x_train, y_train, ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "31603ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_samples = mcmc.get_samples(50)\n",
    "from pyro.infer import Predictive\n",
    "pred = Predictive(classification_model, full_samples, return_sites=['obs', '_RETURN'])(x_train, None, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4621dfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 2,  ..., 1, 2, 2],\n",
       "        [2, 1, 2,  ..., 1, 2, 2],\n",
       "        [1, 1, 2,  ..., 1, 2, 2],\n",
       "        ...,\n",
       "        [1, 1, 2,  ..., 1, 2, 2],\n",
       "        [1, 1, 2,  ..., 1, 2, 2],\n",
       "        [1, 1, 2,  ..., 1, 2, 2]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['_RETURN'].argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2a31e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e66c540e3b479fbb37cbdf724489ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Warmup:   0%|          | 7/2000 [00:18, 29.61it/s, step size=1.04e-06, acc. prob=0.316]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-7e1dbadb7aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# calculate the loss and take a gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mELBO_BETA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mELBO_BETA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[iteration %04d] loss: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrainable_params\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurrogate_loss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'requires_grad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0msurrogate_loss_particle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mwarn_if_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwarn_if_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"backward \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch_isnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = pyro.optim.Adam({\"lr\": 1e-1})\n",
    "\n",
    "# train Factored Gaussian approx\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(classification_model)\n",
    "svi = SVI(classification_model, guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_iterations = 20000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train, y_train, ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc92aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fab2f19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e2c058160>]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cc9a2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = params\n",
    "variational_posterior = dist.MultivariateNormal(loc=means, covariance_matrix=torch.diag(stds ** 2))\n",
    "variational_sample = variational_posterior.sample((50,))\n",
    "variational_samples = {\"weights\" : variational_sample}\n",
    "#kl_var_prior = kl_estimate_with_mc(variational_posterior, prior)\n",
    "var_pred = Predictive(classification_model, variational_samples, return_sites=['obs', '_RETURN'])(x_test, None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cfbebb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2,  ..., 2, 2, 2],\n",
       "        [1, 2, 1,  ..., 1, 1, 1],\n",
       "        [2, 2, 2,  ..., 2, 2, 2],\n",
       "        ...,\n",
       "        [2, 2, 2,  ..., 2, 2, 1],\n",
       "        [2, 2, 2,  ..., 2, 2, 2],\n",
       "        [2, 2, 2,  ..., 2, 2, 2]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(var_pred[\"_RETURN\"], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19384eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_test[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_test[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_test[S]).mean()}, KDE {kde_gmm.log_prob(y_test[S]).mean()}, VAR {var_gmm.log_prob(y_test[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_train[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_train[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_train[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_train[S]).mean()}, KDE {kde_gmm.log_prob(y_train[S]).mean()}, VAR {var_gmm.log_prob(y_train[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a0740",
   "metadata": {},
   "source": [
    "# Compress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd607f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f50d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = deterministic_regression_model(full_samples['params'][10], in_size=D_in, num_nodes=num_nodes, out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20464c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = full_samples['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2cfde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p = kl_kde_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = samples.mean(0)\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1.\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d14d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dummy_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bec8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = torch.zeros([0])\n",
    "for w in compressed_weights_emp_low_eps:\n",
    "    weight_samples = torch.cat([weight_samples, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890686b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = {'params':weight_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1175cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c41881",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm = make_empirical_gmm(weight_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71553a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298483e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE_BNN import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_target = kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train[S],\n",
    "                         y_data=y_train[S],\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1.,\n",
    "                        total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    weight_samples_kde = torch.cat([weight_samples_kde, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffea139",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    dummy_model.make_weights_from_sample(w)\n",
    "    log_probs_kde = torch.cat([log_probs_kde, dummy_model.data_likelihood(x_train[S], y_train[S])[None]], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192855a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"params\":weight_samples_kde[torch.topk(log_probs_kde, k=25)[1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = {'params':weight_samples_kde}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_kde, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde = make_empirical_gmm(weight_samples_kde, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb80562",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde_train = make_empirical_gmm(weight_samples_kde, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_kde_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbaf5c0",
   "metadata": {},
   "source": [
    "# Variational Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1.)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1322371",
   "metadata": {},
   "outputs": [],
   "source": [
    "del compute_params_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = torch.zeros([0])\n",
    "for w in compressed_weights_var_high_eps:\n",
    "    weight_samples_var = torch.cat([weight_samples_var, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a543bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = {'params':weight_samples_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da278808",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_var, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var = make_empirical_gmm(weight_samples_var, num_nodes, x_test[S])\n",
    "\n",
    "compressed_gmm_var.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var_train = make_empirical_gmm(weight_samples_var, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_var_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "# pkl.dump(full_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/full_samples_split{S}.pkl\", \"wb\"))\n",
    "# pkl.dump(kde_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(variational_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/variational_samples_split{S}.pkl\", \"wb\"))\n",
    "# pkl.dump(weight_samples_kde, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_kde_samples_split{S}.pkl\", \"wb\"))\n",
    "# pkl.dump(weight_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_emp_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_var, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_var_samples_split{S}.pkl\", \"wb\"))\n",
    "# pkl.dump(kl_kde_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_kl_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_var_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/var_kl_split{S}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ea80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4763d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
