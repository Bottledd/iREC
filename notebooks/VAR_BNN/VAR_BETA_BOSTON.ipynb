{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fede91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d37e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24022a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434ee3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb00df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64a02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltorch.set_random_seed(0)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d2284e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "470f6928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "x_ = data['data']\n",
    "y_ = data['target']\n",
    "N_tr = int(x_.shape[0] * 0.5)\n",
    "N_val = x_.shape[0] - N_tr\n",
    "a = np.arange(x_.shape[0])\n",
    "train_index = np.random.choice(a, size = N_tr, replace = False)\n",
    "val_index = np.delete(a, train_index, axis=0)\n",
    "x_train = x_[train_index]\n",
    "y_train = y_[train_index]\n",
    "x_val = x_[val_index][:]\n",
    "y_val = y_[val_index][:]\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train-x_m)/ x_s\n",
    "x_val = (x_val-x_m)/ x_s\n",
    "\n",
    "D_in = x_train.shape[1]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "plt.scatter(x_train.numpy()[:,0],y_train.numpy())\n",
    "    \n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f8f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BNNs.DeterministicNN import Deterministic_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5628dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device=torch.device('cpu')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(D_in, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "num_nodes = 2\n",
    "alpha = 1.\n",
    "beta = 2.\n",
    "ELBO_BETA = 1.\n",
    "net = Net(num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a64b5",
   "metadata": {},
   "source": [
    "# MF-VI Approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daaef14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BNNs.pyroVIBNN_BOSTON import BayesianNeuralNetwork\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "980b4808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# create models\n",
    "model = BayesianNeuralNetwork(in_features=D_in, prior_var=1./alpha, likelihood_var=1./beta * ELBO_BETA, hidden_nodes=num_nodes)\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fcd18bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f19d9a7e55b4596bad6abdafd464bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AutoDiagonalNormal()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyro.infer import SVI, TraceMeanField_ELBO\n",
    "\n",
    "adam = pyro.optim.Adamax({\"lr\": 5e-2})\n",
    "svi = SVI(model, guide, adam, loss=TraceMeanField_ELBO())\n",
    "\n",
    "num_iterations = 5000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train, y_train)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "\n",
    "guide.requires_grad_(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77ad4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fdcd3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, stds = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3557d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py:81: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n"
     ]
    }
   ],
   "source": [
    "model_loss = 'regression'\n",
    "\n",
    "# Effect of tau\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = beta # Output Precision\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "variational_posterior = D.MultivariateNormal(loc=mean, covariance_matrix=torch.diag(stds ** 2))\n",
    "\n",
    "variational_samples = variational_posterior.sample((1000,))\n",
    "pred_list_var_exact, log_probs_f = hamiltorch.predict_model(net, x = x_train.to(device),\n",
    "                                                  y = y_train.to(device), samples=variational_samples,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49e1118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(579.3444)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = D.MultivariateNormal(loc=torch.zeros_like(variational_posterior.mean), covariance_matrix = 1./alpha * torch.eye(variational_posterior.mean.shape[-1]))\n",
    "D.kl_divergence(variational_posterior, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e34c0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "predictive = Predictive(model, guide=guide, num_samples=800,\n",
    "                        return_sites=((\"obs\",)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55bb11d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.1182)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((predictive(x_train)['obs'].mean(0) - y_train) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b627e50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultivariateNormal(loc: torch.Size([37]), covariance_matrix: torch.Size([37, 37]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variational_posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdfea1",
   "metadata": {},
   "source": [
    "# Compress some weights with variational scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1./alpha)\n",
    "aux_vars = var_opt.run_optimiser(epochs=5000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c21416",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "compressed_weights_low_eps = []\n",
    "num_compressed_samples = 250\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30140ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_var_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_var_low_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d077f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "\n",
    "compressed_weights_var_med_eps = []\n",
    "num_compressed_samples = 250\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_var_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_var_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "plot_preds(pred_list_var_med_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 250\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_var_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_var_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "plot_preds(pred_list_var_high_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empirical_predictive(weights, x_input, y_output):\n",
    "    pred_list, _ = hamiltorch.predict_model(net, x = x_input.flatten().to(device),\n",
    "                                                  y = y_output.flatten().to(device), samples=weights,\n",
    "                                                  model_loss='regression', tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "    \n",
    "    # need to make gmm at each sample\n",
    "    return pred_list\n",
    "\n",
    "def make_empirical_gmm(preds):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Normal(loc=preds.squeeze().permute(1, 0), scale=beta ** -0.5)\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "    return gmm\n",
    "\n",
    "def compute_gmm_lp(weights, x, y):\n",
    "    preds = make_empirical_predictive(weights, x, y)\n",
    "    \n",
    "    gmm = make_empirical_gmm(preds)\n",
    "    \n",
    "    return gmm.log_prob(y.squeeze()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(variational_samples, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(variational_samples, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_var_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f81aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_var_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2387f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(variational_posterior, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_post_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(aux_vars, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_optimised_vars_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(kl_q_p, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_kl_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(variational_samples, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
