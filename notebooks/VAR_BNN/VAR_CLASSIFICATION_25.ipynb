{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fede91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d37e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24022a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434ee3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb00df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c64a02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltorch.set_random_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d2284e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a754c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "x_ = data.iloc[:, 1:-1].values\n",
    "y_ = data.iloc[:, -1].values.reshape(-1, 1)\n",
    "\n",
    "np.random.seed(0)\n",
    "shuffle_idxs = np.arange(x_.shape[0])\n",
    "np.random.shuffle(shuffle_idxs)\n",
    "\n",
    "num_train = int(x_.shape[0] * 0.5)\n",
    "train_idxs = shuffle_idxs[:num_train]\n",
    "test_idxs = shuffle_idxs[:num_train]\n",
    "x_train = x_[train_idxs]\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train - x_m) / x_s\n",
    "x_test = x_[test_idxs]\n",
    "x_test = (x_test - x_m) / x_s\n",
    "y_train = y_[train_idxs]\n",
    "y_test = y_[test_idxs]\n",
    "\n",
    "D_in = x_train.shape[-1]\n",
    "D_out = 10\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_test= torch.FloatTensor(x_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb8de898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (fc3): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "num_nodes = 2\n",
    "net = Net(num_nodes=num_nodes)\n",
    "\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a64b5",
   "metadata": {},
   "source": [
    "# MF-VI Approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a527643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_categorical_mixture(preds, y):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Categorical(logits=preds.permute(1, 0, 2))\n",
    "    \n",
    "    mixture_of_categorical = D.MixtureSameFamily(mix, comp)\n",
    "    mean_preds = torch.argmax(mixture_of_categorical.component_distribution.probs.mean(1), dim=1).float()\n",
    "    accuracy = torch.sum(mean_preds == y) / y.shape[0]\n",
    "    \n",
    "    ll = mixture_of_categorical.log_prob(y).sum()\n",
    "    return accuracy, ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daaef14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "from models.BNNs.VI_BNN_CLASSIFICTION import VI_BNN\n",
    "from models.BNNs.pyroBNN_classification import BayesianNeuralNetwork\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9407ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.\n",
    "ELBO_BETA = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d53dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianNeuralNetwork(in_features=D_in, prior_var=1./alpha, hidden_nodes=num_nodes, kl_beta=ELBO_BETA, out_features=D_out)\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87e43e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe839201a84a499787475978751293e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "at site \"obs\", invalid log_prob shape\n  Expected [107], actual [107, 107]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with pyro.plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-30c887accf8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# calculate the loss and take a gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[iteration %04d] loss: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0magainst\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         model_trace, guide_trace = get_importance_trace(\n\u001b[0m\u001b[1;32m     58\u001b[0m             \"flat\", self.max_plate_nesting, model, guide, args, kwargs)\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mcheck_site_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_plate_nesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msite\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"sample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/util.py\u001b[0m in \u001b[0;36mcheck_site_shape\u001b[0;34m(site, max_plate_nesting)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mactual_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_longest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpected_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexpected_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mactual_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             raise ValueError('\\n  '.join([\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;34m'at site \"{}\", invalid log_prob shape'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;34m'Expected {}, actual {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at site \"obs\", invalid log_prob shape\n  Expected [107], actual [107, 107]\n  Try one of the following fixes:\n  - enclose the batched tensor in a with pyro.plate(...): context\n  - .to_event(...) the distribution being sampled\n  - .permute() data dimensions"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "adam = pyro.optim.Adamax({\"lr\": 1e-1})\n",
    "svi = SVI(model, guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "num_iterations = 5000\n",
    "pyro.clear_param_store()\n",
    "for j in trange(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train, y_train)\n",
    "    if j % 1000 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a34d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = 'multi_class_linear_output'\n",
    "\n",
    "mean, stds = params\n",
    "# Effect of tau\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = 1. # Output Precision\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "\n",
    "variational_posterior = D.MultivariateNormal(loc=mean, covariance_matrix=torch.diag(stds ** 2))\n",
    "\n",
    "variational_samps = variational_posterior.sample((1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a96823f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6500), tensor(-86.9254))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_val, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=variational_samps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74f693f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7000), tensor(-43.1921))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_train, _ = hamiltorch.predict_model(net, x=x_train, y=y_train, samples=variational_samps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49e1118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.3537)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = D.MultivariateNormal(loc=torch.zeros_like(mean), covariance_matrix = 1./alpha * torch.eye(mean.shape[-1]))\n",
    "D.kl_divergence(variational_posterior, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdfea1",
   "metadata": {},
   "source": [
    "# Compress some weights with variational scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a406433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The mean loss is 3.12623. The mean KL is: 4.88095: 100%|██████████| 1000/1000 [05:04<00:00,  3.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1./alpha)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1c21416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.3537)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_q_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fde0adca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f86811871143c680db4d60347724b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "compressed_weights_low_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30140ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6500), tensor(-93.0654))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_low_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_low_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_low_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0d077f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b04bc42daa4cc984f1f17020008ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "\n",
    "compressed_weights_var_med_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e4f1697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6500), tensor(-91.0513))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_var_med_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_var_med_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_var_med_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d67d8d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99aeec896984743a4f3f9ade19870a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6d4fb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6500), tensor(-89.9019))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_var_high_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_var_high_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_var_high_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2387f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(variational_posterior, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_post_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(aux_vars, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_optimised_vars_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(kl_q_p, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_kl_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(variational_samps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_low_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_med_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_high_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
