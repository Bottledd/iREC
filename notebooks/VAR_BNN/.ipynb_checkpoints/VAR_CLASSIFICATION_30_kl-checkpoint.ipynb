{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fede91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d37e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24022a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434ee3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb00df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64a02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltorch.set_random_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d2284e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a754c64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "device = torch.device('cpu')\n",
    "data = load_iris()\n",
    "x_ = data['data']\n",
    "y_ = data['target']\n",
    "N_tr = 50\n",
    "N_val = 150 - N_tr\n",
    "a = np.arange(x_.shape[0])\n",
    "train_index = np.random.choice(a, size = N_tr, replace = False)\n",
    "val_index = np.delete(a, train_index, axis=0)\n",
    "x_train = x_[train_index]\n",
    "y_train = y_[train_index]\n",
    "x_val = x_[val_index][:]\n",
    "y_val = y_[val_index][:]\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train-x_m)/ x_s\n",
    "x_val = (x_val-x_m)/ x_s\n",
    "D_in = x_train.shape[1]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "plt.scatter(x_train.numpy()[:,0],y_train.numpy())\n",
    "    \n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb8de898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (fc3): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "num_nodes = 2\n",
    "net = Net(num_nodes=num_nodes)\n",
    "\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a64b5",
   "metadata": {},
   "source": [
    "# MF-VI Approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a527643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_categorical_mixture(preds, y):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Categorical(logits=preds.permute(1, 0, 2))\n",
    "    \n",
    "    mixture_of_categorical = D.MixtureSameFamily(mix, comp)\n",
    "    mean_preds = torch.argmax(mixture_of_categorical.component_distribution.probs.mean(1), dim=1).float()\n",
    "    accuracy = torch.sum(mean_preds == y) / y.shape[0]\n",
    "    \n",
    "    ll = mixture_of_categorical.log_prob(y).sum()\n",
    "    return accuracy, ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daaef14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "from models.BNNs.VI_BNN_CLASSIFICTION import VI_BNN\n",
    "from models.BNNs.pyroBNN_classification import BayesianNeuralNetwork\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9407ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10.\n",
    "ELBO_BETA = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d53dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianNeuralNetwork(in_features=D_in, prior_var=1./alpha, hidden_nodes=num_nodes, kl_beta=ELBO_BETA)\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87e43e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1665ee73cedf4a809c42704787f8395b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 3.2344\n",
      "[iteration 1001] loss: 1.2193\n",
      "[iteration 2001] loss: 1.0750\n",
      "[iteration 3001] loss: 0.7107\n",
      "[iteration 4001] loss: 0.7529\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "adam = pyro.optim.Adamax({\"lr\": 1e-1})\n",
    "svi = SVI(model, guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "num_iterations = 5000\n",
    "pyro.clear_param_store()\n",
    "for j in trange(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train, y_train)\n",
    "    if j % 1000 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a34d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py:81: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n"
     ]
    }
   ],
   "source": [
    "model_loss = 'multi_class_linear_output'\n",
    "\n",
    "mean, stds = params\n",
    "# Effect of tau\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = 1. # Output Precision\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "\n",
    "variational_posterior = D.MultivariateNormal(loc=mean, covariance_matrix=torch.diag(stds ** 2))\n",
    "\n",
    "variational_samps = variational_posterior.sample((1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a96823f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9700), tensor(-86.4334))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_val, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=variational_samps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74f693f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9800), tensor(-43.5403))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_train, _ = hamiltorch.predict_model(net, x=x_train, y=y_train, samples=variational_samps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49e1118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.1874)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = D.MultivariateNormal(loc=torch.zeros_like(mean), covariance_matrix = 1./alpha * torch.eye(mean.shape[-1]))\n",
    "D.kl_divergence(variational_posterior, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdfea1",
   "metadata": {},
   "source": [
    "# Compress some weights with variational scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a406433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The mean loss is 1.89709. The mean KL is: 5.02081: 100%|██████████| 1000/1000 [04:59<00:00,  3.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1./alpha)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1c21416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.1874)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_q_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fde0adca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9750c103061a41d5948e9375303aa99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "compressed_weights_low_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30140ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9200), tensor(-91.8218))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_low_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_low_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_low_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0d077f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9392ab0eaf024eee9dfdf316f549eebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "\n",
    "compressed_weights_var_med_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e4f1697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9400), tensor(-89.5740))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_var_med_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_var_med_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_var_med_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d67d8d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4012491dbba348b8ae8af3cc5fcb5c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6d4fb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9400), tensor(-88.5168))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_var_high_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_var_high_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_var_high_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2387f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(variational_posterior, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_post_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(aux_vars, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_optimised_vars_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(kl_q_p, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_kl_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(variational_samps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_low_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_med_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_high_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
