{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fede91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d37e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24022a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kristophermiltiadou/Documents/UniWork/Cambridge/Thesis/CODE/new_iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434ee3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb00df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64a02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltorch.set_random_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d2284e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a754c64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "device = torch.device('cpu')\n",
    "data = load_iris()\n",
    "x_ = data['data']\n",
    "y_ = data['target']\n",
    "N_tr = 10\n",
    "N_val = 150 - N_tr\n",
    "a = np.arange(x_.shape[0])\n",
    "train_index = np.random.choice(a, size = N_tr, replace = False)\n",
    "val_index = np.delete(a, train_index, axis=0)\n",
    "x_train = x_[train_index]\n",
    "y_train = y_[train_index]\n",
    "x_val = x_[val_index][:]\n",
    "y_val = y_[val_index][:]\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train-x_m)/ x_s\n",
    "x_val = (x_val-x_m)/ x_s\n",
    "D_in = x_train.shape[1]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "plt.scatter(x_train.numpy()[:,0],y_train.numpy())\n",
    "    \n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bb8de898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (fc2): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "num_nodes = 3\n",
    "net = Net(num_nodes=num_nodes)\n",
    "\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a64b5",
   "metadata": {},
   "source": [
    "# MF-VI Approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a527643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_categorical_mixture(preds, y):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Categorical(logits=preds.permute(1, 0, 2))\n",
    "    \n",
    "    mixture_of_categorical = D.MixtureSameFamily(mix, comp)\n",
    "    mean_preds = torch.argmax(mixture_of_categorical.component_distribution.probs.mean(1), dim=1).float()\n",
    "    accuracy = torch.sum(mean_preds == y) / y.shape[0]\n",
    "    \n",
    "    ll = mixture_of_categorical.log_prob(y).sum()\n",
    "    return accuracy, ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "daaef14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "from models.BNNs.VI_BNN_CLASSIFICTION import VI_BNN\n",
    "from models.BNNs.pyroBNN_classification import BayesianNeuralNetwork\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9407ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .5\n",
    "ELBO_BETA = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1d53dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianNeuralNetwork(in_features=D_in, prior_var=1./alpha, hidden_nodes=num_nodes, kl_beta=ELBO_BETA)\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "87e43e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3581ea53e47e47ffb4e501207624e57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 9.5171\n",
      "[iteration 1001] loss: 2.8580\n",
      "[iteration 2001] loss: 2.5765\n",
      "[iteration 3001] loss: 2.1585\n",
      "[iteration 4001] loss: 6.6123\n",
      "[iteration 5001] loss: 3.4002\n",
      "[iteration 6001] loss: 2.9621\n",
      "[iteration 7001] loss: 3.4165\n",
      "[iteration 8001] loss: 3.9614\n",
      "[iteration 9001] loss: 3.7111\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "adam = pyro.optim.Adamax({\"lr\": 5e-1})\n",
    "svi = SVI(model, guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "num_iterations = 10000\n",
    "pyro.clear_param_store()\n",
    "for j in trange(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train, y_train)\n",
    "    if j % 1000 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6a34d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = 'multi_class_linear_output'\n",
    "\n",
    "mean, stds = params\n",
    "# Effect of tau\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = 1. # Output Precision\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "\n",
    "variational_posterior = D.MultivariateNormal(loc=mean, covariance_matrix=torch.diag(stds ** 2))\n",
    "\n",
    "variational_samps = variational_posterior.sample((10000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a96823f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6643), tensor(-94.6446))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_val, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=variational_samps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "74f693f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7000), tensor(-6.6053))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_train, _ = hamiltorch.predict_model(net, x=x_train, y=y_train, samples=variational_samps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "49e1118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.5665)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = D.MultivariateNormal(loc=torch.zeros_like(mean), covariance_matrix = 1./alpha * torch.eye(mean.shape[-1]))\n",
    "D.kl_divergence(variational_posterior, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdfea1",
   "metadata": {},
   "source": [
    "# Compress some weights with variational scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a406433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The mean loss is 7.94443. The mean KL is: 6.54320: 100%|██████████| 5000/5000 [16:05<00:00,  5.18it/s] \n"
     ]
    }
   ],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1./alpha)\n",
    "aux_vars = var_opt.run_optimiser(epochs=5000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c1c21416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.5665)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_q_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fde0adca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07090c37c3fd4ca2a3c6d552377e5b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "compressed_weights_low_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "30140ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7571), tensor(-119.6584))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_low_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_low_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_low_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f0d077f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016fc27f40034b6683dc350b6720aa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "\n",
    "compressed_weights_var_med_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2e4f1697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6714), tensor(-117.9989))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_var_med_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_var_med_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_var_med_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d67d8d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f8783f28064d56ac7615f31ec7bb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e6d4fb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6286), tensor(-114.9382))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_var_high_eps, _ = hamiltorch.predict_model(net, x=x_val, y=y_val, samples=compressed_weights_var_high_eps, \n",
    "                                                    model_loss='multi_class_linear_output', tau_out=1., \n",
    "                                                    tau_list=tau_list)\n",
    "\n",
    "compute_categorical_mixture(pred_list_var_high_eps, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d2387f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(variational_posterior, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_post_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(aux_vars, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_optimised_vars_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(kl_q_p, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_kl_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(variational_samps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_low_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_med_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_high_eps, open(f'PickledStuff/BNN_BETA_CLASSIFICATION/VAR/var_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026d9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
