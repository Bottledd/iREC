{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fede91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d37e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24022a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434ee3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import hamiltorch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb00df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64a02a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamiltorch.set_random_seed(0)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d2284e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0.dev1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamiltorch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "470f6928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "x_ = data['data']\n",
    "y_ = data['target']\n",
    "N_tr = int(x_.shape[0] * 0.8)\n",
    "N_val = x_.shape[0] - N_tr\n",
    "a = np.arange(x_.shape[0])\n",
    "train_index = np.random.choice(a, size = N_tr, replace = False)\n",
    "val_index = np.delete(a, train_index, axis=0)\n",
    "x_train = x_[train_index]\n",
    "y_train = y_[train_index]\n",
    "x_val = x_[val_index][:]\n",
    "y_val = y_[val_index][:]\n",
    "x_m = x_train.mean(0)\n",
    "x_s = x_train.std(0)\n",
    "x_train = (x_train-x_m)/ x_s\n",
    "x_val = (x_val-x_m)/ x_s\n",
    "\n",
    "D_in = x_train.shape[1]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_val = torch.FloatTensor(x_val)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "plt.scatter(x_train.numpy()[:,0],y_train.numpy())\n",
    "    \n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f079d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5f8f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BNNs.DeterministicNN import Deterministic_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5628dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# if torch.cuda.is_available():\n",
    "#     print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device=torch.device('cpu')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_nodes: int = 10):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(D_in, num_nodes)\n",
    "        self.fc2 = nn.Linear(num_nodes, num_nodes)\n",
    "        self.fc3 = nn.Linear(num_nodes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "num_nodes = 2\n",
    "alpha = 1.\n",
    "beta = 1.\n",
    "ELBO_BETA = 1.\n",
    "net = Net(num_nodes=num_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a64b5",
   "metadata": {},
   "source": [
    "# MF-VI Approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "daaef14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BNNs.SimpleBBPBNN import SimpleBBPBNN, train_bnn\n",
    "from models.BNNs.pyroVIBNN_BOSTON import BayesianNeuralNetwork\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "980b4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models\n",
    "model = BayesianNeuralNetwork(in_features=D_in, prior_var=1./alpha, likelihood_var=1./beta * ELBO_BETA, hidden_nodes=num_nodes)\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3fcd18bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae42208ed956405ea0b159a9a8bece5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 297.7158\n",
      "[iteration 1001] loss: 8.2455\n",
      "[iteration 2001] loss: 7.9838\n",
      "[iteration 3001] loss: 8.0146\n",
      "[iteration 4001] loss: 7.6451\n",
      "[iteration 5001] loss: 8.2446\n",
      "[iteration 6001] loss: 8.0917\n",
      "[iteration 7001] loss: 8.0062\n",
      "[iteration 8001] loss: 7.8583\n",
      "[iteration 9001] loss: 7.5525\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import SVI, TraceMeanField_ELBO\n",
    "\n",
    "adam = pyro.optim.Adamax({\"lr\": 5e-1})\n",
    "svi = SVI(model, guide, adam, loss=TraceMeanField_ELBO())\n",
    "\n",
    "num_iterations = 10000\n",
    "pyro.clear_param_store()\n",
    "for j in trange(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train, y_train)\n",
    "    if j % 1000 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f78b3332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3155, 0.2639, 0.1410, 0.2041, 0.2516, 0.1981, 0.2514, 0.2200, 0.1443,\n",
       "        0.1272, 0.1767, 0.3276, 0.2824, 1.0548, 1.0208, 1.0230, 1.0022, 0.9740,\n",
       "        1.0030, 0.9034, 1.0751, 0.8028, 1.1615, 1.1706, 0.9739, 1.0497, 0.1799,\n",
       "        0.9708, 0.1472, 0.1252, 0.0147, 0.0144, 0.1168, 0.0121, 0.1922, 0.2698,\n",
       "        0.1824])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c3557d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = 'regression'\n",
    "\n",
    "# Effect of tau\n",
    "tau = alpha # Prior Precision\n",
    "tau_out = beta # Output Precision\n",
    "\n",
    "tau_list = []\n",
    "for w in net.parameters():\n",
    "    tau_list.append(tau) # set the prior precision to be the same for each set of weights\n",
    "tau_list = torch.tensor(tau_list).to(device)\n",
    "\n",
    "mean, stds = params\n",
    "\n",
    "variational_posterior = dist.MultivariateNormal(loc=mean, covariance_matrix=torch.diag(stds ** 2))\n",
    "\n",
    "variational_samples = variational_posterior.sample((1000,))\n",
    "pred_list_var_exact, log_probs_f = hamiltorch.predict_model(net, x = x_train.to(device),\n",
    "                                                  y = y_train.to(device), samples=variational_samples,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2fa026a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.6255],\n",
       "        [21.3738],\n",
       "        [19.4515],\n",
       "        [10.6187],\n",
       "        [45.3644],\n",
       "        [18.3902],\n",
       "        [20.9343],\n",
       "        [16.8235],\n",
       "        [18.6989],\n",
       "        [15.7323],\n",
       "        [19.6294],\n",
       "        [21.2925],\n",
       "        [19.7600],\n",
       "        [19.0026],\n",
       "        [15.5489],\n",
       "        [17.2705],\n",
       "        [21.4672],\n",
       "        [10.5154],\n",
       "        [21.9479],\n",
       "        [29.4533],\n",
       "        [11.1561],\n",
       "        [13.6361],\n",
       "        [19.2594],\n",
       "        [37.0658],\n",
       "        [20.9414],\n",
       "        [28.3672],\n",
       "        [10.6288],\n",
       "        [26.3009],\n",
       "        [23.4187],\n",
       "        [22.2567],\n",
       "        [18.5154],\n",
       "        [44.9236],\n",
       "        [16.1034],\n",
       "        [19.4130],\n",
       "        [17.0418],\n",
       "        [21.7459],\n",
       "        [19.2023],\n",
       "        [25.3464],\n",
       "        [19.0080],\n",
       "        [11.6887],\n",
       "        [26.2452],\n",
       "        [25.0940],\n",
       "        [24.8950],\n",
       "        [18.2906],\n",
       "        [20.8168],\n",
       "        [18.5510],\n",
       "        [20.8066],\n",
       "        [20.5262],\n",
       "        [22.6885],\n",
       "        [16.8148],\n",
       "        [14.8170],\n",
       "        [11.3195],\n",
       "        [18.3628],\n",
       "        [30.1817],\n",
       "        [21.3811],\n",
       "        [12.6790],\n",
       "        [12.5695],\n",
       "        [20.2654],\n",
       "        [19.1832],\n",
       "        [23.5509],\n",
       "        [23.7466],\n",
       "        [15.8922],\n",
       "        [17.5324],\n",
       "        [18.2876],\n",
       "        [10.6011],\n",
       "        [27.0741],\n",
       "        [23.3285],\n",
       "        [12.0544],\n",
       "        [24.5342],\n",
       "        [16.2893],\n",
       "        [11.2057],\n",
       "        [39.8446],\n",
       "        [22.3731],\n",
       "        [28.7580],\n",
       "        [16.5236],\n",
       "        [23.8655],\n",
       "        [19.9589],\n",
       "        [24.6582],\n",
       "        [16.4914],\n",
       "        [25.7975],\n",
       "        [45.4682],\n",
       "        [10.5811],\n",
       "        [18.8228],\n",
       "        [10.6446],\n",
       "        [24.3442],\n",
       "        [20.5422],\n",
       "        [23.2375],\n",
       "        [25.3993],\n",
       "        [20.1876],\n",
       "        [22.1361],\n",
       "        [23.6317],\n",
       "        [20.1698],\n",
       "        [30.8038],\n",
       "        [22.5544],\n",
       "        [16.1693],\n",
       "        [19.1089],\n",
       "        [18.0648],\n",
       "        [14.5237],\n",
       "        [39.0877],\n",
       "        [17.9485],\n",
       "        [20.1373],\n",
       "        [21.0403],\n",
       "        [27.6419],\n",
       "        [21.4114],\n",
       "        [24.5260],\n",
       "        [11.4122],\n",
       "        [12.1948],\n",
       "        [23.7817],\n",
       "        [24.4109],\n",
       "        [45.4850],\n",
       "        [19.2038],\n",
       "        [16.3878],\n",
       "        [45.3013],\n",
       "        [41.4707],\n",
       "        [18.8947],\n",
       "        [23.9079],\n",
       "        [17.0881],\n",
       "        [20.2974],\n",
       "        [13.7038],\n",
       "        [45.4887],\n",
       "        [20.1596],\n",
       "        [22.0780],\n",
       "        [45.3089],\n",
       "        [25.9554],\n",
       "        [22.1895],\n",
       "        [19.6948],\n",
       "        [40.5368],\n",
       "        [29.7009],\n",
       "        [24.1724],\n",
       "        [20.7336],\n",
       "        [22.5727],\n",
       "        [22.6079],\n",
       "        [14.8449],\n",
       "        [20.7379],\n",
       "        [19.0200],\n",
       "        [16.2785],\n",
       "        [19.3229],\n",
       "        [17.5910],\n",
       "        [19.0851],\n",
       "        [20.2528],\n",
       "        [25.4146],\n",
       "        [19.1633],\n",
       "        [19.3617],\n",
       "        [31.5405],\n",
       "        [23.7601],\n",
       "        [33.2347],\n",
       "        [ 6.4553],\n",
       "        [10.5164],\n",
       "        [21.0964],\n",
       "        [45.4975],\n",
       "        [20.1177],\n",
       "        [20.9688],\n",
       "        [20.1760],\n",
       "        [30.0705],\n",
       "        [16.5267],\n",
       "        [43.4210],\n",
       "        [17.9251],\n",
       "        [29.1408],\n",
       "        [21.7886],\n",
       "        [28.0051],\n",
       "        [21.5790],\n",
       "        [34.4706],\n",
       "        [39.1721],\n",
       "        [29.6746],\n",
       "        [45.4216],\n",
       "        [24.7890],\n",
       "        [18.7338],\n",
       "        [15.1540],\n",
       "        [29.2979],\n",
       "        [18.9227],\n",
       "        [20.3241],\n",
       "        [38.3679],\n",
       "        [24.5982],\n",
       "        [18.9048],\n",
       "        [18.6757],\n",
       "        [24.1104],\n",
       "        [17.8211],\n",
       "        [18.8369],\n",
       "        [ 9.7570],\n",
       "        [18.3843],\n",
       "        [23.5397],\n",
       "        [28.5966],\n",
       "        [12.9710],\n",
       "        [19.0446],\n",
       "        [11.0637],\n",
       "        [26.0312],\n",
       "        [18.8183],\n",
       "        [24.0546],\n",
       "        [13.5397],\n",
       "        [14.0790],\n",
       "        [25.0770],\n",
       "        [41.5059],\n",
       "        [13.2683],\n",
       "        [19.0989],\n",
       "        [17.6621],\n",
       "        [25.6852],\n",
       "        [13.6187],\n",
       "        [27.9279],\n",
       "        [18.8292],\n",
       "        [27.1824],\n",
       "        [23.7181],\n",
       "        [28.7712],\n",
       "        [22.3475],\n",
       "        [19.0792],\n",
       "        [18.9974],\n",
       "        [24.5630],\n",
       "        [38.6861],\n",
       "        [10.5707],\n",
       "        [33.3374],\n",
       "        [17.3977],\n",
       "        [22.0755],\n",
       "        [30.7672],\n",
       "        [33.5969],\n",
       "        [45.3695],\n",
       "        [10.5633],\n",
       "        [20.8815],\n",
       "        [27.1453],\n",
       "        [23.6871],\n",
       "        [25.5093],\n",
       "        [19.1755],\n",
       "        [43.9191],\n",
       "        [29.4740],\n",
       "        [24.4102],\n",
       "        [19.1430],\n",
       "        [14.6106],\n",
       "        [21.5661],\n",
       "        [26.9704],\n",
       "        [17.8739],\n",
       "        [19.4627],\n",
       "        [18.9575],\n",
       "        [18.9394],\n",
       "        [39.2586],\n",
       "        [10.5165],\n",
       "        [13.6193],\n",
       "        [11.0801],\n",
       "        [21.2297],\n",
       "        [13.1586],\n",
       "        [16.7649],\n",
       "        [21.0547],\n",
       "        [22.9984],\n",
       "        [21.4064],\n",
       "        [19.2832],\n",
       "        [27.0089],\n",
       "        [20.7679],\n",
       "        [22.5529],\n",
       "        [19.3972],\n",
       "        [45.4620],\n",
       "        [21.4579],\n",
       "        [19.2295],\n",
       "        [43.1677],\n",
       "        [12.1046],\n",
       "        [18.1653],\n",
       "        [23.1972],\n",
       "        [21.5165],\n",
       "        [25.1550],\n",
       "        [18.9670],\n",
       "        [13.1555],\n",
       "        [24.1406],\n",
       "        [20.6245],\n",
       "        [17.8607],\n",
       "        [13.0777],\n",
       "        [12.9823],\n",
       "        [19.3126],\n",
       "        [11.1302],\n",
       "        [19.1043],\n",
       "        [17.8070],\n",
       "        [15.0969],\n",
       "        [24.1904],\n",
       "        [18.8610],\n",
       "        [33.3075],\n",
       "        [28.6402],\n",
       "        [40.3819],\n",
       "        [22.7098],\n",
       "        [22.4019],\n",
       "        [18.2878],\n",
       "        [23.1368],\n",
       "        [19.1730],\n",
       "        [19.6770],\n",
       "        [21.0330],\n",
       "        [10.4934],\n",
       "        [21.8816],\n",
       "        [41.7205],\n",
       "        [14.5953],\n",
       "        [15.5841],\n",
       "        [19.3016],\n",
       "        [21.0780],\n",
       "        [45.4993],\n",
       "        [19.3768],\n",
       "        [12.2184],\n",
       "        [33.4937],\n",
       "        [45.4994],\n",
       "        [19.4193],\n",
       "        [23.7104],\n",
       "        [11.5545],\n",
       "        [10.8985],\n",
       "        [20.0230],\n",
       "        [19.0644],\n",
       "        [45.4295],\n",
       "        [10.5823],\n",
       "        [19.6101],\n",
       "        [17.1740],\n",
       "        [10.5306],\n",
       "        [11.6394],\n",
       "        [23.9299],\n",
       "        [19.2854],\n",
       "        [23.7525],\n",
       "        [11.6478],\n",
       "        [19.8411],\n",
       "        [16.3777],\n",
       "        [25.5006],\n",
       "        [20.2200],\n",
       "        [17.0422],\n",
       "        [19.0410],\n",
       "        [20.0324],\n",
       "        [16.9728],\n",
       "        [44.0878],\n",
       "        [24.9131],\n",
       "        [17.5419],\n",
       "        [16.5709],\n",
       "        [15.7194],\n",
       "        [23.4264],\n",
       "        [21.1491],\n",
       "        [19.5100],\n",
       "        [19.0106],\n",
       "        [14.0402],\n",
       "        [29.2238],\n",
       "        [25.9467],\n",
       "        [20.5819],\n",
       "        [20.6954],\n",
       "        [27.5104],\n",
       "        [17.5802],\n",
       "        [29.1378],\n",
       "        [31.5790],\n",
       "        [13.9914],\n",
       "        [20.5558],\n",
       "        [22.1772],\n",
       "        [45.4749],\n",
       "        [23.7373],\n",
       "        [10.5531],\n",
       "        [10.4002],\n",
       "        [18.1846],\n",
       "        [14.1313],\n",
       "        [10.5167],\n",
       "        [45.0374],\n",
       "        [14.1143],\n",
       "        [29.7543],\n",
       "        [26.7328],\n",
       "        [23.7277],\n",
       "        [25.4738],\n",
       "        [23.3355],\n",
       "        [31.8181],\n",
       "        [24.5626],\n",
       "        [19.1601],\n",
       "        [26.2493],\n",
       "        [15.9772],\n",
       "        [18.7407],\n",
       "        [22.2939],\n",
       "        [19.1098],\n",
       "        [24.9427],\n",
       "        [21.9960],\n",
       "        [23.2547],\n",
       "        [11.5639],\n",
       "        [22.3769],\n",
       "        [23.4279],\n",
       "        [18.4994],\n",
       "        [22.9244],\n",
       "        [26.3567],\n",
       "        [20.3757],\n",
       "        [22.0608],\n",
       "        [29.3226],\n",
       "        [11.7642],\n",
       "        [23.9662],\n",
       "        [15.1918],\n",
       "        [16.7042],\n",
       "        [22.1267],\n",
       "        [13.8690],\n",
       "        [44.9192],\n",
       "        [19.3319],\n",
       "        [18.8180],\n",
       "        [10.4921],\n",
       "        [14.4121],\n",
       "        [20.9601],\n",
       "        [19.1965],\n",
       "        [19.2913],\n",
       "        [34.1532],\n",
       "        [14.5760],\n",
       "        [22.5694],\n",
       "        [13.4700],\n",
       "        [45.1518],\n",
       "        [25.5964],\n",
       "        [18.5704],\n",
       "        [23.7582],\n",
       "        [19.7415],\n",
       "        [18.7040],\n",
       "        [19.0496],\n",
       "        [24.2252],\n",
       "        [17.5110],\n",
       "        [27.0232],\n",
       "        [16.5765],\n",
       "        [22.7235],\n",
       "        [21.9646],\n",
       "        [24.4298],\n",
       "        [33.6253],\n",
       "        [21.7800]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list_var_exact.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "49e1118b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(517.1501)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = D.MultivariateNormal(loc=torch.zeros_like(mean), covariance_matrix = 1./alpha * torch.eye(mean.shape[-1]))\n",
    "D.kl_divergence(variational_posterior, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fdfea1",
   "metadata": {},
   "source": [
    "# Compress some weights with variational scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1./alpha)\n",
    "aux_vars = var_opt.run_optimiser(epochs=5000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c21416",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "compressed_weights_low_eps = []\n",
    "num_compressed_samples = 250\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30140ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_var_low_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_low_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "\n",
    "plot_preds(pred_list_var_low_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d077f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.1\n",
    "\n",
    "compressed_weights_var_med_eps = []\n",
    "num_compressed_samples = 250\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_med_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_var_med_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_var_med_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "plot_preds(pred_list_var_med_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 250\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1./alpha)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_var_high_eps, log_probs_f = hamiltorch.predict_model(net, x = xs.to(device),\n",
    "                                                  y = xs.to(device), samples=compressed_weights_var_high_eps,\n",
    "                                                  model_loss=model_loss, tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "plot_preds(pred_list_var_high_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empirical_predictive(weights, x_input, y_output):\n",
    "    pred_list, _ = hamiltorch.predict_model(net, x = x_input.flatten().to(device),\n",
    "                                                  y = y_output.flatten().to(device), samples=weights,\n",
    "                                                  model_loss='regression', tau_out=tau_out,\n",
    "                                                  tau_list=tau_list)\n",
    "    \n",
    "    # need to make gmm at each sample\n",
    "    return pred_list\n",
    "\n",
    "def make_empirical_gmm(preds):\n",
    "    mix = D.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = D.Normal(loc=preds.squeeze().permute(1, 0), scale=beta ** -0.5)\n",
    "    gmm = D.MixtureSameFamily(mix, comp)\n",
    "    return gmm\n",
    "\n",
    "def compute_gmm_lp(weights, x, y):\n",
    "    preds = make_empirical_predictive(weights, x, y)\n",
    "    \n",
    "    gmm = make_empirical_gmm(preds)\n",
    "    \n",
    "    return gmm.log_prob(y.squeeze()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(variational_samples, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(variational_samples, x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_low_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_var_med_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f81aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_gmm_lp(compressed_weights_var_high_eps, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2387f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the important stuff\n",
    "import pickle as pkl\n",
    "pkl.dump(variational_posterior, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_post_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(aux_vars, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_optimised_vars_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(kl_q_p, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_kl_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(variational_samples, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_exact_beta_{ELBO_BETA}.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_low_eps, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_beta_{ELBO_BETA}_eps_0.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_med_eps, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_beta_{ELBO_BETA}_eps_0.1.pkl', 'wb'))\n",
    "pkl.dump(compressed_weights_var_high_eps, open(f'PickledStuff/BNN_BETA_RESULTS/VAR/var_beta_{ELBO_BETA}_eps_0.2.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
