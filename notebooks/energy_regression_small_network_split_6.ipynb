{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1aa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# !wget \"http://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\" --no-check-certificate\n",
    "data = pd.read_excel('ENB2012_data.xlsx', header=0).iloc[:, :10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240997c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from torch import nn\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import HMC, MCMC, SVI, NUTS, TraceMeanField_ELBO\n",
    "from pyro import poutine\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange\n",
    "from rec.utils import kl_estimate_with_mc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c84bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = data[:, :-2]\n",
    "y_ = data[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f476367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_idxs = []\n",
    "for d in range(x_.shape[-1]):\n",
    "    sorted_x = np.argsort(x_[:,d], axis=-1)\n",
    "    total_points = sorted_x.shape[0]\n",
    "    lower_third = total_points // 3\n",
    "    upper_third = total_points * 2 // 3\n",
    "    test_index = sorted_x[lower_third: upper_third]\n",
    "    test_splits_idxs.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6b102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_x, test_splits_y = [], []\n",
    "train_splits_x, train_splits_y = [], []\n",
    "for d in range(x_.shape[-1]):\n",
    "    a = np.arange(x_.shape[0])\n",
    "    test_index = test_splits_idxs[d]\n",
    "    train_index = np.delete(a, test_index, axis=0)\n",
    "    x_train = x_[train_index]\n",
    "    y_train = y_[train_index]\n",
    "    x_test = x_[test_index][:]\n",
    "    y_test = y_[test_index][:]\n",
    "    x_m = x_train.mean(0)\n",
    "    x_s = x_train.std(0)\n",
    "    x_train = (x_train - x_m) / x_s\n",
    "    x_test = (x_test - x_m) / x_s\n",
    "    test_splits_x.append(x_test)\n",
    "    test_splits_y.append(y_test)\n",
    "    train_splits_x.append(x_train)\n",
    "    train_splits_y.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2b3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = x_train.shape[-1]\n",
    "D_out = y_test.shape[-1]\n",
    "x_train = torch.FloatTensor(np.array(train_splits_x))\n",
    "y_train = torch.FloatTensor(np.array(train_splits_y))\n",
    "x_test= torch.FloatTensor(np.array(test_splits_x))\n",
    "y_test = torch.FloatTensor(np.array(test_splits_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfbdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(x, y=None, weight_samples=None, in_size=1, num_nodes=10, out_size=1, ELBO_BETA=1.):\n",
    "    # sample vector of weights for regression\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    # sample params\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(torch.zeros(total_weights + D_out), 1.).to_event(1))\n",
    "    weights, rho = params[:-D_out], params[-D_out:]\n",
    "\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "    with pyro.plate(\"data\"):\n",
    "        obs = pyro.sample(\"obs\", dist.MultivariateNormal(loc=mu, \n",
    "                                                         covariance_matrix=torch.diag(F.softplus(rho) ** 2)), obs=y)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def KDE_guide(x, y=None, weight_samples=None, in_size=D_in, num_nodes=10, out_size=1, ELBO_BETA=None):\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    iso_noise = pyro.param(\"iso_noise\", torch.tensor(1e-5), constraint=dist.constraints.positive)\n",
    "    assignment = dist.Categorical(probs=torch.ones(weight_samples.shape[0])).sample()\n",
    "\n",
    "    # sample assigmnent\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(weight_samples[assignment], iso_noise).to_event(1))\n",
    "\n",
    "    weights, rho = params[:-1], params[-1]\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "def make_empirical_gmm(samples, num_nodes, x_test):\n",
    "    rho_noise = samples['params'][:, -D_out:]\n",
    "    noise = F.softplus(rho_noise) ** 2\n",
    "    preds_dict = Predictive(regression_model, samples, return_sites=['_RETURN'])(x_test, None, num_nodes=num_nodes,\n",
    "                                                                                 in_size=D_in, out_size=D_out)\n",
    "    preds = preds_dict['_RETURN']\n",
    "    mix = dist.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = dist.MultivariateNormal(loc=preds.squeeze().permute(1, 0, 2), covariance_matrix=torch.diag_embed(noise))\n",
    "    gmm = dist.MixtureSameFamily(mix, comp)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e035560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deterministic_regression_model(nn.Module):\n",
    "    def __init__(self, params, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(deterministic_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "        weights, rho = params[:-out_size], params[-out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes *self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx +self.out_size].reshape(self.out_size)\n",
    "        idx +=self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params\n",
    "\n",
    "        # compute forward pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def weight_prior_lp(self):\n",
    "        return dist.Normal(loc=0., scale=1.).log_prob(self.params).mean()\n",
    "    \n",
    "    def data_likelihood(self, x, y):\n",
    "        likelihood = dist.Normal(loc=self.forward(x),\n",
    "                              scale=F.softplus(self.rho))\n",
    "        return likelihood.log_prob(y).sum(-1).mean()\n",
    "    \n",
    "    def joint_log_prob(self, x, y):\n",
    "        return self.data_likelihood(x, y) + self.weight_prior_lp(x, y)\n",
    "    \n",
    "    def make_weights_from_sample(self, params):\n",
    "        weights, rho = params[:-self.out_size], params[-self.out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes * self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx + self.out_size].reshape(self.out_size)\n",
    "        idx += self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aef7f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 2000/2000 [00:32, 61.94it/s, step size=9.54e-02, acc. prob=0.947]\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(10)\n",
    "ELBO_BETA = 1.\n",
    "S=6\n",
    "in_size = x_train.shape[-1]\n",
    "num_nodes = 3\n",
    "\n",
    "# run HMC\n",
    "kernel = HMC(regression_model, step_size=0.001, num_steps=5, target_accept_prob=0.8)\n",
    "nuts_kernel = NUTS(regression_model, step_size=0.1, target_accept_prob=0.5, max_tree_depth=5)\n",
    "mcmc = MCMC(kernel, num_samples=1000, warmup_steps=1000, num_chains=1)\n",
    "mcmc.run(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d708ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py:81: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n"
     ]
    }
   ],
   "source": [
    "full_samples = mcmc.get_samples(50)\n",
    "from pyro.infer import Predictive\n",
    "pred = Predictive(regression_model, full_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "HMC_RMSE = ((pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37458d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66e4e2476994e3cbab6304a8f0b465c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "scheduler = pyro.optim.ExponentialLR({'optimizer': optimizer, 'optim_args': {'lr': 1}, 'gamma': .95})\n",
    "# train KDE\n",
    "svi = SVI(regression_model, KDE_guide, scheduler, loss=TraceMeanField_ELBO())\n",
    "\n",
    "num_iterations = 1000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train[S], y_train[S], full_samples['params'], \n",
    "                    ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "    scheduler.step()\n",
    "kde_noise = pyro.param(\"iso_noise\")\n",
    "flattened_params = full_samples['params']\n",
    "kde_mix = dist.Categorical(probs=torch.ones(flattened_params.shape[0]))\n",
    "kde_comps = dist.MultivariateNormal(loc=flattened_params,\n",
    "                                    covariance_matrix=kde_noise * torch.eye(flattened_params.shape[-1]))\n",
    "kde = dist.MixtureSameFamily(kde_mix, kde_comps)\n",
    "prior = dist.MultivariateNormal(loc=torch.ones_like(flattened_params[0]),\n",
    "                                covariance_matrix=torch.eye(flattened_params[0].shape[-1]))\n",
    "kl_kde_prior = kl_estimate_with_mc(kde, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3358f2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0328, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de2bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5dd0205e80>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d153c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_sample = kde.sample((50,))\n",
    "kde_samples = {\"params\" : kde_sample}\n",
    "kde_pred = Predictive(regression_model, kde_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                     out_size=D_out)\n",
    "KDE_RMSE = ((kde_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984f418b7fc7407ca5c51c4110769244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "# train Factored Gaussian approx\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(regression_model)\n",
    "svi = SVI(regression_model, guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_iterations = 50000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = params\n",
    "variational_posterior = dist.MultivariateNormal(loc=means, covariance_matrix=torch.diag(stds ** 2))\n",
    "variational_sample = variational_posterior.sample((50,))\n",
    "variational_samples = {\"params\" : variational_sample}\n",
    "kl_var_prior = kl_estimate_with_mc(variational_posterior, prior)\n",
    "var_pred = Predictive(regression_model, variational_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)\n",
    "VAR_RMSE = ((var_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_test[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_test[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_test[S]).mean()}, KDE {kde_gmm.log_prob(y_test[S]).mean()}, VAR {var_gmm.log_prob(y_test[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_train[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_train[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_train[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_train[S]).mean()}, KDE {kde_gmm.log_prob(y_train[S]).mean()}, VAR {var_gmm.log_prob(y_train[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a0740",
   "metadata": {},
   "source": [
    "# Compress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd607f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f50d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = deterministic_regression_model(full_samples['params'][10], in_size=D_in, num_nodes=num_nodes, out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = full_samples['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bff399",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p = kl_kde_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac21b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = samples.mean(0)\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1.\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0daa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dummy_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c846557",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = torch.zeros([0])\n",
    "for w in compressed_weights_emp_low_eps:\n",
    "    weight_samples = torch.cat([weight_samples, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = {'params':weight_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm = make_empirical_gmm(weight_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE_BNN import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_target = kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train[S],\n",
    "                         y_data=y_train[S],\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1.,\n",
    "                        total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    weight_samples_kde = torch.cat([weight_samples_kde, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07405071",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = {'params':weight_samples_kde}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_kde, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb968dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde = make_empirical_gmm(weight_samples_kde, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde_train = make_empirical_gmm(weight_samples_kde, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_kde_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f1203",
   "metadata": {},
   "source": [
    "# Variational Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1.)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = torch.zeros([0])\n",
    "for w in compressed_weights_var_high_eps:\n",
    "    weight_samples_var = torch.cat([weight_samples_var, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = {'params':weight_samples_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_var, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var = make_empirical_gmm(weight_samples_var, num_nodes, x_test[S])\n",
    "\n",
    "compressed_gmm_var.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e91fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var_train = make_empirical_gmm(weight_samples_var, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_var_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d44aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(full_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/full_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kde_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(variational_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/variational_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_kde, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_emp_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_var, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_var_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_kde_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_kl_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_var_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/var_kl_split{S}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed6ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
