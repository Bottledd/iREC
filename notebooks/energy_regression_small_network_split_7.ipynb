{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1aa6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953d6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# !wget \"http://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\" --no-check-certificate\n",
    "data = pd.read_excel('ENB2012_data.xlsx', header=0).iloc[:, :10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240997c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from torch import nn\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import HMC, MCMC, SVI, NUTS, TraceMeanField_ELBO\n",
    "from pyro import poutine\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import trange\n",
    "from rec.utils import kl_estimate_with_mc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83c84bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = data[:, :-2]\n",
    "y_ = data[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f476367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_idxs = []\n",
    "for d in range(x_.shape[-1]):\n",
    "    sorted_x = np.argsort(x_[:,d], axis=-1)\n",
    "    total_points = sorted_x.shape[0]\n",
    "    lower_third = total_points // 3\n",
    "    upper_third = total_points * 2 // 3\n",
    "    test_index = sorted_x[lower_third: upper_third]\n",
    "    test_splits_idxs.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6b102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_splits_x, test_splits_y = [], []\n",
    "train_splits_x, train_splits_y = [], []\n",
    "for d in range(x_.shape[-1]):\n",
    "    a = np.arange(x_.shape[0])\n",
    "    test_index = test_splits_idxs[d]\n",
    "    train_index = np.delete(a, test_index, axis=0)\n",
    "    x_train = x_[train_index]\n",
    "    y_train = y_[train_index]\n",
    "    x_test = x_[test_index][:]\n",
    "    y_test = y_[test_index][:]\n",
    "    x_m = x_train.mean(0)\n",
    "    x_s = x_train.std(0)\n",
    "    x_train = (x_train - x_m) / x_s\n",
    "    x_test = (x_test - x_m) / x_s\n",
    "    test_splits_x.append(x_test)\n",
    "    test_splits_y.append(y_test)\n",
    "    train_splits_x.append(x_train)\n",
    "    train_splits_y.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2b3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = x_train.shape[-1]\n",
    "D_out = y_test.shape[-1]\n",
    "x_train = torch.FloatTensor(np.array(train_splits_x))\n",
    "y_train = torch.FloatTensor(np.array(train_splits_y))\n",
    "x_test= torch.FloatTensor(np.array(test_splits_x))\n",
    "y_test = torch.FloatTensor(np.array(test_splits_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfbdd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(x, y=None, weight_samples=None, in_size=1, num_nodes=10, out_size=1, ELBO_BETA=1.):\n",
    "    # sample vector of weights for regression\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    # sample params\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(torch.zeros(total_weights + D_out), 1.).to_event(1))\n",
    "    weights, rho = params[:-D_out], params[-D_out:]\n",
    "\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "    with pyro.plate(\"data\"):\n",
    "        obs = pyro.sample(\"obs\", dist.MultivariateNormal(loc=mu, \n",
    "                                                         covariance_matrix=torch.diag(F.softplus(rho) ** 2)), obs=y)\n",
    "    return mu\n",
    "\n",
    "\n",
    "def KDE_guide(x, y=None, weight_samples=None, in_size=D_in, num_nodes=10, out_size=1, ELBO_BETA=None):\n",
    "    total_weights = (in_size + 1) * num_nodes + (num_nodes + 1) * num_nodes + (num_nodes + 1) * out_size\n",
    "    iso_noise = pyro.param(\"iso_noise\", torch.tensor(1e-5), constraint=dist.constraints.positive)\n",
    "    assignment = dist.Categorical(probs=torch.ones(weight_samples.shape[0])).sample()\n",
    "\n",
    "    # sample assigmnent\n",
    "    with poutine.scale(scale=ELBO_BETA):\n",
    "        params = pyro.sample(\"params\", dist.Normal(weight_samples[assignment], iso_noise).to_event(1))\n",
    "\n",
    "    weights, rho = params[:-1], params[-1]\n",
    "    idx = 0\n",
    "    fc1_weights = weights[idx: idx + in_size * num_nodes].reshape(num_nodes, in_size)\n",
    "    idx += in_size * num_nodes\n",
    "    fc1_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc2_weights = weights[idx: idx + num_nodes * num_nodes].reshape(num_nodes, num_nodes)\n",
    "    idx += num_nodes * num_nodes\n",
    "    fc2_bias = weights[idx: idx + num_nodes].reshape(num_nodes)\n",
    "    idx += num_nodes\n",
    "\n",
    "    fc3_weights = weights[idx: idx + num_nodes * out_size].reshape(out_size, num_nodes)\n",
    "    idx += num_nodes * out_size\n",
    "    fc3_bias = weights[idx: idx + out_size].reshape(out_size)\n",
    "    idx += out_size\n",
    "\n",
    "    assert idx == total_weights, \"Something wrong with number of weights!\"\n",
    "\n",
    "    # compute forward pass\n",
    "    batch_shape = x.shape[0]\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc1_weights, x) + fc1_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc2_weights, x) + fc2_bias[None].repeat(batch_shape, 1)\n",
    "    x = torch.relu(x)\n",
    "\n",
    "    x = torch.einsum(\"ij, kj -> ki\", fc3_weights, x) + fc3_bias[None].repeat(batch_shape, 1)\n",
    "    mu = x.squeeze()\n",
    "\n",
    "def make_empirical_gmm(samples, num_nodes, x_test):\n",
    "    rho_noise = samples['params'][:, -D_out:]\n",
    "    noise = F.softplus(rho_noise) ** 2\n",
    "    preds_dict = Predictive(regression_model, samples, return_sites=['_RETURN'])(x_test, None, num_nodes=num_nodes,\n",
    "                                                                                 in_size=D_in, out_size=D_out)\n",
    "    preds = preds_dict['_RETURN']\n",
    "    mix = dist.Categorical(torch.ones(preds.shape[0]))\n",
    "    comp = dist.MultivariateNormal(loc=preds.squeeze().permute(1, 0, 2), covariance_matrix=torch.diag_embed(noise))\n",
    "    gmm = dist.MixtureSameFamily(mix, comp)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e035560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deterministic_regression_model(nn.Module):\n",
    "    def __init__(self, params, in_size=1, num_nodes=10, out_size=1):\n",
    "        super(deterministic_regression_model, self).__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.activation = torch.relu\n",
    "        self.num_nodes = num_nodes\n",
    "        weights, rho = params[:-out_size], params[-out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes *self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx +self.out_size].reshape(self.out_size)\n",
    "        idx +=self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params\n",
    "\n",
    "        # compute forward pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_shape = x.shape[0]\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc1_weights, x) + self.fc1_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc2_weights, x) + self.fc2_bias[None].repeat(batch_shape, 1)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = torch.einsum(\"ij, kj -> ki\", self.fc3_weights, x) + self.fc3_bias[None].repeat(batch_shape, 1)\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def weight_prior_lp(self):\n",
    "        return dist.Normal(loc=0., scale=1.).log_prob(self.params).mean()\n",
    "    \n",
    "    def data_likelihood(self, x, y):\n",
    "        likelihood = dist.Normal(loc=self.forward(x),\n",
    "                              scale=F.softplus(self.rho))\n",
    "        return likelihood.log_prob(y).sum(-1).mean()\n",
    "    \n",
    "    def joint_log_prob(self, x, y):\n",
    "        return self.data_likelihood(x, y) + self.weight_prior_lp(x, y)\n",
    "    \n",
    "    def make_weights_from_sample(self, params):\n",
    "        weights, rho = params[:-self.out_size], params[-self.out_size:]\n",
    "\n",
    "        idx = 0\n",
    "        self.fc1_weights = weights[idx: idx + self.in_size * self.num_nodes].reshape(self.num_nodes, self.in_size)\n",
    "        idx += self.in_size * self.num_nodes\n",
    "        self.fc1_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc2_weights = weights[idx: idx + self.num_nodes * self.num_nodes].reshape(self.num_nodes, self.num_nodes)\n",
    "        idx += self.num_nodes * self.num_nodes\n",
    "        self.fc2_bias = weights[idx: idx + self.num_nodes].reshape(self.num_nodes)\n",
    "        idx += self.num_nodes\n",
    "\n",
    "        self.fc3_weights = weights[idx: idx + self.num_nodes * self.out_size].reshape(self.out_size, self.num_nodes)\n",
    "        idx += self.num_nodes *self.out_size\n",
    "        self.fc3_bias = weights[idx: idx + self.out_size].reshape(self.out_size)\n",
    "        idx += self.out_size\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.rho = rho\n",
    "        self.params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aef7f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 2000/2000 [00:33, 59.00it/s, step size=1.51e-01, acc. prob=0.773]\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(10)\n",
    "ELBO_BETA = 1.\n",
    "S=7\n",
    "in_size = x_train.shape[-1]\n",
    "num_nodes = 3\n",
    "\n",
    "# run HMC\n",
    "kernel = HMC(regression_model, step_size=0.001, num_steps=5, target_accept_prob=0.8)\n",
    "nuts_kernel = NUTS(regression_model, step_size=0.1, target_accept_prob=0.5, max_tree_depth=5)\n",
    "mcmc = MCMC(kernel, num_samples=1000, warmup_steps=1000, num_chains=1)\n",
    "mcmc.run(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d708ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/km817/miniconda3/envs/Torch/lib/python3.8/site-packages/pyro/distributions/torch_patch.py:81: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  return torch.stack([v.symeig(eigenvectors=False)[0][:1] > 0.0\n"
     ]
    }
   ],
   "source": [
    "full_samples = mcmc.get_samples(50)\n",
    "from pyro.infer import Predictive\n",
    "pred = Predictive(regression_model, full_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "HMC_RMSE = ((pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37458d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebac6bef329f4c5a89903df7e60673fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "scheduler = pyro.optim.ExponentialLR({'optimizer': optimizer, 'optim_args': {'lr': 1}, 'gamma': .95})\n",
    "# train KDE\n",
    "svi = SVI(regression_model, KDE_guide, scheduler, loss=TraceMeanField_ELBO())\n",
    "\n",
    "num_iterations = 1000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train[S], y_train[S], full_samples['params'], \n",
    "                    ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "    scheduler.step()\n",
    "kde_noise = pyro.param(\"iso_noise\")\n",
    "flattened_params = full_samples['params']\n",
    "kde_mix = dist.Categorical(probs=torch.ones(flattened_params.shape[0]))\n",
    "kde_comps = dist.MultivariateNormal(loc=flattened_params,\n",
    "                                    covariance_matrix=kde_noise * torch.eye(flattened_params.shape[-1]))\n",
    "kde = dist.MixtureSameFamily(kde_mix, kde_comps)\n",
    "prior = dist.MultivariateNormal(loc=torch.ones_like(flattened_params[0]),\n",
    "                                covariance_matrix=torch.eye(flattened_params[0].shape[-1]))\n",
    "kl_kde_prior = kl_estimate_with_mc(kde, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3358f2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0270, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kde_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3de2bb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e84035a30>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d153c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_sample = kde.sample((50,))\n",
    "kde_samples = {\"params\" : kde_sample}\n",
    "kde_pred = Predictive(regression_model, kde_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                     out_size=D_out)\n",
    "KDE_RMSE = ((kde_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31e01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e777ca232a8e4e43bf4484a91fabe51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "# train Factored Gaussian approx\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "guide = AutoDiagonalNormal(regression_model)\n",
    "svi = SVI(regression_model, guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_iterations = 50000\n",
    "pyro.clear_param_store()\n",
    "pbar = trange(num_iterations)\n",
    "losses = []\n",
    "for j in pbar:\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(x_train[S], y_train[S], ELBO_BETA=ELBO_BETA, num_nodes=num_nodes, in_size=D_in, out_size=D_out)\n",
    "    losses.append(loss)\n",
    "    pbar.set_description(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(x_train)))\n",
    "guide.requires_grad_(False)\n",
    "\n",
    "params = []\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    params.append(pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "means, stds = params\n",
    "variational_posterior = dist.MultivariateNormal(loc=means, covariance_matrix=torch.diag(stds ** 2))\n",
    "variational_sample = variational_posterior.sample((50,))\n",
    "variational_samples = {\"params\" : variational_sample}\n",
    "kl_var_prior = kl_estimate_with_mc(variational_posterior, prior)\n",
    "var_pred = Predictive(regression_model, variational_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)\n",
    "VAR_RMSE = ((var_pred['_RETURN'].mean(0) - y_test[S]) ** 2).mean().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_test[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_test[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_test[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_test[S]).mean()}, KDE {kde_gmm.log_prob(y_test[S]).mean()}, VAR {var_gmm.log_prob(y_test[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_gmm = make_empirical_gmm(full_samples, num_nodes, x_train[S])\n",
    "kde_gmm = make_empirical_gmm(kde_samples, num_nodes, x_train[S])\n",
    "var_gmm = make_empirical_gmm(variational_samples, num_nodes, x_train[S])\n",
    "print(f\"The final KLs are: KDE {kl_kde_prior}, VAR {kl_var_prior}\\n\"\n",
    "      f\"The final RMSE are: HMC {HMC_RMSE}, KDE {KDE_RMSE}, VAR {VAR_RMSE}\\n\"\n",
    "      f\"The final LLs are: HMC {hmc_gmm.log_prob(y_train[S]).mean()}, KDE {kde_gmm.log_prob(y_train[S]).mean()}, VAR {var_gmm.log_prob(y_train[S]).mean()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16a0740",
   "metadata": {},
   "source": [
    "# Compress weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd607f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets compress some samples\n",
    "#### sample weights with compression algorithm\n",
    "from tqdm.notebook import trange\n",
    "from rec.beamsearch.Coders.Encoder_Empirical import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f50d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = deterministic_regression_model(full_samples['params'][10], in_size=D_in, num_nodes=num_nodes, out_size=D_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = full_samples['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bff399",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_q_p = kl_kde_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac21b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "dummy_encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "\n",
    "z_sample = samples.mean(0)\n",
    "omega = 5\n",
    "n_trajectories = 64\n",
    "n_auxiliaries = dummy_encoder.n_auxiliary\n",
    "prior_var = 1.\n",
    "emp_opt = FinalJointOptimiser(z_sample, omega, n_auxiliaries, kl_q_p, n_trajectories, prior_var)\n",
    "aux_vars = emp_opt.run_optimiser(epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0daa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dummy_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c846557",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = EmpiricalMixturePosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_emp_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(dummy_model,\n",
    "                     x_train[S],\n",
    "                     y_train[S],\n",
    "                     samples,\n",
    "                     initial_seed,\n",
    "                     coding_sampler,\n",
    "                     selection_sampler,\n",
    "                     auxiliary_posterior,\n",
    "                     omega,\n",
    "                     beamwidth,\n",
    "                     epsilon=epsilon,\n",
    "                     prior_var=1.,\n",
    "                     total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_emp_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = torch.zeros([0])\n",
    "for w in compressed_weights_emp_low_eps:\n",
    "    weight_samples = torch.cat([weight_samples, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples = {'params':weight_samples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm = make_empirical_gmm(weight_samples, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.KDEPosterior import KDEPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling_BNNs import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_KDE_BNN import EncoderKDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "KDE_target = kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = KDEPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "num_compressed_samples = 500\n",
    "compressed_weights_kde_low_eps = []\n",
    "\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = EncoderKDE(model=dummy_model,\n",
    "                         x_data=x_train[S],\n",
    "                         y_data=y_train[S],\n",
    "                         target=KDE_target,\n",
    "                         initial_seed=initial_seed,\n",
    "                         coding_sampler=coding_sampler,\n",
    "                         selection_sampler=selection_sampler,\n",
    "                         auxiliary_posterior=auxiliary_posterior,\n",
    "                         omega=omega,\n",
    "                         epsilon=epsilon,\n",
    "                         beamwidth=beamwidth,\n",
    "                         prior_var=1.,\n",
    "                        total_kl=kl_q_p)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    w, idx = encoder.run_encoder()\n",
    "    compressed_weights_kde_low_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f9926",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = torch.zeros([0])\n",
    "for w in compressed_weights_kde_low_eps:\n",
    "    weight_samples_kde = torch.cat([weight_samples_kde, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07405071",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_kde = {'params':weight_samples_kde}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_kde, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb968dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde = make_empirical_gmm(weight_samples_kde, num_nodes, x_test[S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39de99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_kde_train = make_empirical_gmm(weight_samples_kde, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_kde_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f1203",
   "metadata": {},
   "source": [
    "# Variational Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### sample weights with compression algorithm\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from tqdm.notebook import trange\n",
    "coding_sampler = CodingSampler\n",
    "auxiliary_posterior = VariationalPosterior\n",
    "selection_sampler = GreedySampler\n",
    "omega = 5\n",
    "\n",
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.\n",
    "\n",
    "\n",
    "\n",
    "compute_params_enc =  encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "\n",
    "n_auxiliaries = compute_params_enc.n_auxiliary\n",
    "kl_q_p = compute_params_enc.total_kl\n",
    "var_opt = VariationalOptimiser(compute_params_enc.target, omega, n_auxiliaries, kl_q_p, n_trajectories=16, total_var=1.)\n",
    "aux_vars = var_opt.run_optimiser(epochs=1000, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_seed = 0\n",
    "beamwidth = 1\n",
    "epsilon = 0.2\n",
    "\n",
    "compressed_weights_var_high_eps = []\n",
    "num_compressed_samples = 500\n",
    "for i in trange(num_compressed_samples):\n",
    "    initial_seed = initial_seed + i * 10\n",
    "    encoder = Encoder(variational_posterior,\n",
    "                      initial_seed,\n",
    "                      coding_sampler,\n",
    "                      selection_sampler,\n",
    "                      auxiliary_posterior,\n",
    "                      omega,\n",
    "                      epsilon=epsilon,\n",
    "                      beamwidth=beamwidth,\n",
    "                      prior_var=1.)\n",
    "    \n",
    "    encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    w, idx = encoder.run_encoder()\n",
    "\n",
    "    compressed_weights_var_high_eps.append(w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = torch.zeros([0])\n",
    "for w in compressed_weights_var_high_eps:\n",
    "    weight_samples_var = torch.cat([weight_samples_var, w[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_samples_var = {'params':weight_samples_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed = Predictive(regression_model, weight_samples_var, return_sites=['obs', '_RETURN'])(x_test[S], None, \n",
    "                                                                        num_nodes=num_nodes, in_size=D_in,\n",
    "                                                                                             out_size=D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var = make_empirical_gmm(weight_samples_var, num_nodes, x_test[S])\n",
    "\n",
    "compressed_gmm_var.log_prob(y_test[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e91fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_gmm_var_train = make_empirical_gmm(weight_samples_var, num_nodes, x_train[S])\n",
    "\n",
    "compressed_gmm_var_train.log_prob(y_train[S]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d44aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(full_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/full_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kde_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(variational_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/variational_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_kde, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_kde_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_emp_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(weight_samples_var, open(f\"PickledStuff/BNN_UCI/ENERGY/compressed_var_samples_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_kde_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/kde_kl_split{S}.pkl\", \"wb\"))\n",
    "pkl.dump(kl_var_prior, open(f\"PickledStuff/BNN_UCI/ENERGY/var_kl_split{S}.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc4ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
