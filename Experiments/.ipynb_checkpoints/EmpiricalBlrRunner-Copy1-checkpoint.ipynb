{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c54de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475f87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3dae1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kristophermiltiadou/Documents/UniWork/Cambridge/Thesis/CODE/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297685ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as dist\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.EmpiricalMixturePosterior import EmpiricalMixturePosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder import Encoder as Empirical_Encoder\n",
    "from models.BayesianLinRegressor import BayesLinRegressor\n",
    "from rec.utils import kl_estimate_with_mc, plot_samples_in_2d, plot_running_sum_2d, plot_pairs_of_samples\n",
    "from rec.OptimisingVars.FinalJointOptimiser import FinalJointOptimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c8950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sample(target, omega=8, epsilon=0.,\n",
    "                  n_empirical_samples=10, seed=0, beamwidth=1, optimising_vars=False, aux_vars=None):\n",
    "    \n",
    "    encoder = Empirical_Encoder(target,\n",
    "                                seed,\n",
    "                                CodingSampler,\n",
    "                                GreedySampler,\n",
    "                                EmpiricalMixturePosterior,\n",
    "                                omega,\n",
    "                                n_empirical_samples,\n",
    "                                epsilon=epsilon,\n",
    "                                beamwidth=beamwidth\n",
    "                                )\n",
    "    \n",
    "    return encoder, *encoder.run_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913cec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blr_problem(dim, seed):\n",
    "    \n",
    "    initial_seed_target = seed\n",
    "    blr = BayesLinRegressor(prior_mean=torch.zeros(dim),\n",
    "                        prior_alpha=1,\n",
    "                        signal_std=1,\n",
    "                        num_targets=10000,\n",
    "                        seed=initial_seed_target)\n",
    "    blr.sample_feature_inputs()\n",
    "    blr.sample_regression_targets()\n",
    "    blr.posterior_update()\n",
    "    target = blr.weight_posterior\n",
    "    return blr, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10348e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 50\n",
    "beamwidth = 20\n",
    "omega = 5\n",
    "blr_seed = 1\n",
    "b, t = create_blr_problem(dim=dim, seed=blr_seed)\n",
    "num_compressed_samples = 50\n",
    "\n",
    "torch.manual_seed(0)\n",
    "seeds = torch.randint(low = 0, high = int(1e6), size=(num_compressed_samples,))\n",
    "epsilons = [0., 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "for eps in epsilons:\n",
    "    exp_dict = {}\n",
    "    exp_dict['seeds'] = seeds.numpy()\n",
    "    exp_dict['target_mean'] = t.mean.numpy()\n",
    "    exp_dict['target_covar'] = t.covariance_matrix.numpy()\n",
    "    exp_dict['compressed_samples'] = []\n",
    "    exp_dict['compressed_samples_idxs'] = []\n",
    "    pbar = tqdm(enumerate(seeds), total=num_compressed_samples)\n",
    "    for i, s in pbar:\n",
    "        enc, z, idx = encode_sample(target=t, beamwidth=beamwidth, epsilon=eps, omega=omega, seed=s, n_empirical_samples=50)\n",
    "        idxs_to_transmit = idx[0]\n",
    "        best_sample = z[0]\n",
    "        exp_dict['compressed_samples'].append(best_sample.numpy())\n",
    "        exp_dict['compressed_samples_idxs'].append(idxs_to_transmit.numpy())\n",
    "        pbar.set_description(f\"Coded sample {i + 1}, has log prob of {t.log_prob(best_sample)}\")\n",
    "\n",
    "    with open(f\"PickledStuff/Dim{dim}/Empirical_Epsilon{eps}_Beam{beamwidth}_Omega{omega}.pkl\", \"wb\") as f:\n",
    "        pkl.dump(exp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f78fe556",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_z = 0\n",
    "for sample in exp_dict['compressed_samples']:\n",
    "    big_z += sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e871a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "meany = big_z / num_compressed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "18457d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.6819)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.log_prob(torch.tensor(meany))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8c48bf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.6854)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.log_prob(t.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "28831881",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pkl.load(open(\"PickledStuff/Dim2/Empirical_Epsilon0.2.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6df66239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([595., 300.], dtype=float32),\n",
       " array([227., 640.], dtype=float32),\n",
       " array([233., 375.], dtype=float32),\n",
       " array([160., 609.], dtype=float32),\n",
       " array([268., 171.], dtype=float32),\n",
       " array([212., 535.], dtype=float32),\n",
       " array([563., 463.], dtype=float32),\n",
       " array([637., 570.], dtype=float32),\n",
       " array([571., 386.], dtype=float32),\n",
       " array([ 62., 504.], dtype=float32),\n",
       " array([146., 459.], dtype=float32),\n",
       " array([614.,  88.], dtype=float32),\n",
       " array([631., 123.], dtype=float32),\n",
       " array([117., 431.], dtype=float32),\n",
       " array([176., 549.], dtype=float32),\n",
       " array([344., 299.], dtype=float32),\n",
       " array([460., 292.], dtype=float32),\n",
       " array([458., 471.], dtype=float32),\n",
       " array([393., 114.], dtype=float32),\n",
       " array([ 36., 433.], dtype=float32),\n",
       " array([ 17., 125.], dtype=float32),\n",
       " array([ 24., 505.], dtype=float32),\n",
       " array([548., 154.], dtype=float32),\n",
       " array([649., 592.], dtype=float32),\n",
       " array([310.,  70.], dtype=float32),\n",
       " array([276.,  49.], dtype=float32),\n",
       " array([496., 339.], dtype=float32),\n",
       " array([466., 544.], dtype=float32),\n",
       " array([329., 485.], dtype=float32),\n",
       " array([579., 376.], dtype=float32),\n",
       " array([ 76., 180.], dtype=float32),\n",
       " array([174.,  35.], dtype=float32),\n",
       " array([446., 217.], dtype=float32),\n",
       " array([473.,  37.], dtype=float32),\n",
       " array([284., 267.], dtype=float32),\n",
       " array([545.,  62.], dtype=float32),\n",
       " array([651., 537.], dtype=float32),\n",
       " array([376., 542.], dtype=float32),\n",
       " array([ 54., 228.], dtype=float32),\n",
       " array([574.,  89.], dtype=float32),\n",
       " array([451., 372.], dtype=float32),\n",
       " array([359., 230.], dtype=float32),\n",
       " array([ 80., 136.], dtype=float32),\n",
       " array([304., 605.], dtype=float32),\n",
       " array([522.,  73.], dtype=float32),\n",
       " array([495., 483.], dtype=float32),\n",
       " array([316., 148.], dtype=float32),\n",
       " array([105., 261.], dtype=float32),\n",
       " array([411., 400.], dtype=float32),\n",
       " array([153., 145.], dtype=float32)]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dict['compressed_samples_idxs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "123006b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pkl.load(open(\"PickledStuff/Dim2/Empirical_Epsilon0.3.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "50089e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.6562)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.log_prob(torch.tensor(test['compressed_samples'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7661926a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
