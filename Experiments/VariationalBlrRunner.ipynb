{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a816477",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b5da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be78dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kristophermiltiadou/Documents/UniWork/Cambridge/Thesis/CODE/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fdfa05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as dist\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder as Variational_Encoder\n",
    "from models.BayesianLinRegressor import BayesLinRegressor\n",
    "from rec.utils import kl_estimate_with_mc, compute_variational_posterior, plot_samples_in_2d, plot_running_sum_2d, plot_pairs_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13274db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sample(target, omega=8, epsilon=0.,\n",
    "                  n_empirical_samples=10, seed=0, beamwidth=1):\n",
    "    \n",
    "    target = compute_variational_posterior(target)\n",
    "    encoder = Variational_Encoder(target,\n",
    "                                  seed,\n",
    "                                  CodingSampler,\n",
    "                                  GreedySampler,\n",
    "                                  VariationalPosterior,\n",
    "                                  omega,\n",
    "                                  epsilon=epsilon,\n",
    "                                  beamwidth=beamwidth\n",
    "                                  )\n",
    "\n",
    "    return encoder, *encoder.run_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5383b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blr_problem(dim, seed, signal_std=1):\n",
    "    \n",
    "    initial_seed_target = seed\n",
    "    blr = BayesLinRegressor(prior_mean=torch.zeros(dim),\n",
    "                        prior_alpha=1,\n",
    "                        signal_std=signal_std,\n",
    "                        num_targets=10000,\n",
    "                        seed=initial_seed_target)\n",
    "    blr.sample_feature_inputs()\n",
    "    blr.sample_regression_targets()\n",
    "    blr.posterior_update()\n",
    "    target = blr.weight_posterior\n",
    "    return blr, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9918539d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f680141b69aa4ae0aa7d8441d9b9e218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36e314ee1ad4a51b7f21d4cfb4b1abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cbb9b6b1684c5389f2f369a9d5cee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb204de9e98404d94984e1d268d8bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408d88fee0a04957be2e40e825cfb228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 2\n",
    "beamwidth = 5\n",
    "omega = 5\n",
    "blr_seed = 1\n",
    "b, t = create_blr_problem(dim=dim, seed=blr_seed, signal_std=1e-1)\n",
    "num_compressed_samples = 50\n",
    "\n",
    "torch.manual_seed(0)\n",
    "seeds = torch.randint(low = 0, high = int(1e6), size=(num_compressed_samples,))\n",
    "epsilons = [0., 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "for eps in epsilons:\n",
    "    exp_dict = {}\n",
    "    exp_dict['seeds'] = seeds.numpy()\n",
    "    exp_dict['target_mean'] = t.mean.numpy()\n",
    "    exp_dict['target_covar'] = t.covariance_matrix.numpy()\n",
    "    exp_dict['compressed_samples'] = []\n",
    "    exp_dict['compressed_samples_idxs'] = []\n",
    "    pbar = tqdm(enumerate(seeds), total=num_compressed_samples)\n",
    "    for i, s in pbar:\n",
    "        enc, z, idx = encode_sample(target=t, beamwidth=beamwidth, epsilon=eps, omega=omega, seed=s)\n",
    "        idxs_to_transmit = idx[0]\n",
    "        best_sample = z[0]\n",
    "        exp_dict['compressed_samples'].append(best_sample.numpy())\n",
    "        exp_dict['compressed_samples_idxs'].append(idxs_to_transmit.numpy())\n",
    "        pbar.set_description(f\"Coded sample {i + 1}, has log prob of {t.log_prob(best_sample)}\")\n",
    "\n",
    "    with open(f\"PickledStuff/New_Exp/Dim{dim}/Variational_Epsilon{eps}_Beam{beamwidth}_Omega{omega}_HARD.pkl\", \"wb\") as f:\n",
    "        pkl.dump(exp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77e2b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
