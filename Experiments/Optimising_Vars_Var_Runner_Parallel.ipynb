{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c54de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475f87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3dae1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/km817/REC/iREC\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297685ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as dist\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "from rec.beamsearch.distributions.CodingSampler import CodingSampler\n",
    "from rec.beamsearch.distributions.VariationalPosterior import VariationalPosterior\n",
    "from rec.OptimisingVars.VariationalOptimiser import VariationalOptimiser\n",
    "from rec.beamsearch.samplers.GreedySampling import GreedySampler\n",
    "from rec.beamsearch.Coders.Encoder_Variational import Encoder as Variational_Encoder\n",
    "from models.BayesianLinRegressor import BayesLinRegressor\n",
    "from rec.utils import kl_estimate_with_mc, compute_variational_posterior, plot_samples_in_2d, plot_running_sum_2d, plot_pairs_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c8950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sample(target, omega=5, epsilon=0.,\n",
    "                  n_empirical_samples=10, seed=0, beamwidth=1, optimising_vars=False, aux_vars=None, dont_run=False):\n",
    "    \n",
    "    target = compute_variational_posterior(target)\n",
    "    encoder = Variational_Encoder(target,\n",
    "                                  seed,\n",
    "                                  CodingSampler,\n",
    "                                  GreedySampler,\n",
    "                                  VariationalPosterior,\n",
    "                                  omega,\n",
    "                                  epsilon=epsilon,\n",
    "                                  beamwidth=beamwidth\n",
    "                                  )\n",
    "    if aux_vars is not None:\n",
    "        encoder.auxiliary_posterior.coding_sampler.auxiliary_vars = aux_vars\n",
    "    \n",
    "    if dont_run:\n",
    "        return encoder\n",
    "    else:\n",
    "        return encoder, *encoder.run_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913cec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blr_problem(dim, seed):\n",
    "    \n",
    "    initial_seed_target = seed\n",
    "    blr = BayesLinRegressor(prior_mean=torch.zeros(dim),\n",
    "                        prior_alpha=1,\n",
    "                        signal_std=1,\n",
    "                        num_targets=10000,\n",
    "                        seed=initial_seed_target)\n",
    "    blr.sample_feature_inputs()\n",
    "    blr.sample_regression_targets()\n",
    "    blr.posterior_update()\n",
    "    target = blr.weight_posterior\n",
    "    return blr, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c36ca63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 20\n",
    "beamwidth = 1\n",
    "omega = 5\n",
    "blr_seed = 1\n",
    "b, t = create_blr_problem(dim=dim, seed=blr_seed)\n",
    "num_compressed_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91705703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c5db0a01674ffeaf8f57216b37459b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-520.9982)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5607502e1946d4930ff350d6f90a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-422.0664)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6503975e444ddea7b3a3d599126aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-115.6356)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aaff4f0e58a4fb2b31f868f948c0711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-21.4819)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05094006f7aa40bf835725d689999bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.2890)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "seeds = torch.randint(low = 0, high = int(1e6), size=(num_compressed_samples,))\n",
    "epsilons = [0., 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "aux_vars = pkl.load(open(f\"PickledStuff/Optimising_Vars/Dim{dim}/optimised_vars_var.pkl\", \"rb\"))\n",
    "for eps in epsilons:\n",
    "    exp_dict = {}\n",
    "    exp_dict['seeds'] = seeds.numpy()\n",
    "    exp_dict['target_mean'] = t.mean.numpy()\n",
    "    exp_dict['target_covar'] = t.covariance_matrix.numpy()\n",
    "    exp_dict['compressed_samples'] = []\n",
    "    exp_dict['compressed_samples_idxs'] = []\n",
    "    exp_dict['aux_vars'] = aux_vars\n",
    "    pbar = tqdm(enumerate(seeds), total=num_compressed_samples)\n",
    "    log_probs = torch.zeros([0])\n",
    "    for i, s in pbar:\n",
    "        enc, z, idx = encode_sample(target=t, beamwidth=beamwidth, epsilon=eps, omega=omega, \n",
    "                                    seed=s, n_empirical_samples=50, aux_vars=aux_vars)\n",
    "        idxs_to_transmit = idx[0]\n",
    "        best_sample = z[0]\n",
    "        log_probs = torch.cat((log_probs, t.log_prob(best_sample)[None]))\n",
    "        exp_dict['compressed_samples'].append(best_sample.numpy())\n",
    "        exp_dict['compressed_samples_idxs'].append(idxs_to_transmit.numpy())\n",
    "        pbar.set_description(f\"Coded sample {i + 1}, has log prob of {t.log_prob(best_sample)}\")\n",
    "    \n",
    "    print(torch.mean(log_probs))\n",
    "    with open(f\"PickledStuff/Optimising_Vars/Dim{dim}/Variational_Epsilon{eps}_Beam{beamwidth}_Omega{omega}.pkl\", \"wb\") as f:\n",
    "        pkl.dump(exp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58b5c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 20\n",
    "beamwidth = 5\n",
    "omega = 5\n",
    "blr_seed = 1\n",
    "b, t = create_blr_problem(dim=dim, seed=blr_seed)\n",
    "num_compressed_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38102ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8a0a974a8342e3818bd2cea8d1cc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-354.1690)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f2ba2a964746f5a521db7822e957ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-139.6036)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab13c0a6d92441aac3df7c721277918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-67.5503)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04b3be5e9ec4fb8ae7b67cff43f09d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.1403)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450fb6674fe44a41b4d52dc6b4fd4130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(45.0052)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "seeds = torch.randint(low = 0, high = int(1e6), size=(num_compressed_samples,))\n",
    "epsilons = [0., 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "aux_vars = pkl.load(open(f\"PickledStuff/Optimising_Vars/Dim{dim}/optimised_vars_var.pkl\", \"rb\"))\n",
    "for eps in epsilons:\n",
    "    exp_dict = {}\n",
    "    exp_dict['seeds'] = seeds.numpy()\n",
    "    exp_dict['target_mean'] = t.mean.numpy()\n",
    "    exp_dict['target_covar'] = t.covariance_matrix.numpy()\n",
    "    exp_dict['compressed_samples'] = []\n",
    "    exp_dict['compressed_samples_idxs'] = []\n",
    "    exp_dict['aux_vars'] = aux_vars\n",
    "    pbar = tqdm(enumerate(seeds), total=num_compressed_samples)\n",
    "    log_probs = torch.zeros([0])\n",
    "    for i, s in pbar:\n",
    "        enc, z, idx = encode_sample(target=t, beamwidth=beamwidth, epsilon=eps, omega=omega, \n",
    "                                    seed=s, n_empirical_samples=50, aux_vars=aux_vars)\n",
    "        idxs_to_transmit = idx[0]\n",
    "        best_sample = z[0]\n",
    "        log_probs = torch.cat((log_probs, t.log_prob(best_sample)[None]))\n",
    "        exp_dict['compressed_samples'].append(best_sample.numpy())\n",
    "        exp_dict['compressed_samples_idxs'].append(idxs_to_transmit.numpy())\n",
    "        pbar.set_description(f\"Coded sample {i + 1}, has log prob of {t.log_prob(best_sample)}\")\n",
    "    \n",
    "    print(torch.mean(log_probs))\n",
    "    with open(f\"PickledStuff/Optimising_Vars/Dim{dim}/Variational_Epsilon{eps}_Beam{beamwidth}_Omega{omega}.pkl\", \"wb\") as f:\n",
    "        pkl.dump(exp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40f39c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 20\n",
    "beamwidth = 20\n",
    "omega = 5\n",
    "blr_seed = 1\n",
    "b, t = create_blr_problem(dim=dim, seed=blr_seed)\n",
    "num_compressed_samples = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd48b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580f3f3d99714bff9d93c2b14f38099e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-313.9733)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b8d4d834184b71a5e4f8f43ce1cb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-95.3963)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c955d4e36c14c63b5f1b7ddc3e05a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-40.9282)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f207670564d4a0fb03225e5f0338c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(31.8479)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16efaf723d734f12934a6a1f285d047a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "seeds = torch.randint(low = 0, high = int(1e6), size=(num_compressed_samples,))\n",
    "epsilons = [0., 0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "aux_vars = pkl.load(open(f\"PickledStuff/Optimising_Vars/Dim{dim}/optimised_vars_var.pkl\", \"rb\"))\n",
    "for eps in epsilons:\n",
    "    exp_dict = {}\n",
    "    exp_dict['seeds'] = seeds.numpy()\n",
    "    exp_dict['target_mean'] = t.mean.numpy()\n",
    "    exp_dict['target_covar'] = t.covariance_matrix.numpy()\n",
    "    exp_dict['compressed_samples'] = []\n",
    "    exp_dict['compressed_samples_idxs'] = []\n",
    "    exp_dict['aux_vars'] = aux_vars\n",
    "    pbar = tqdm(enumerate(seeds), total=num_compressed_samples)\n",
    "    log_probs = torch.zeros([0])\n",
    "    for i, s in pbar:\n",
    "        enc, z, idx = encode_sample(target=t, beamwidth=beamwidth, epsilon=eps, omega=omega, \n",
    "                                    seed=s, n_empirical_samples=50, aux_vars=aux_vars)\n",
    "        idxs_to_transmit = idx[0]\n",
    "        best_sample = z[0]\n",
    "        log_probs = torch.cat((log_probs, t.log_prob(best_sample)[None]))\n",
    "        exp_dict['compressed_samples'].append(best_sample.numpy())\n",
    "        exp_dict['compressed_samples_idxs'].append(idxs_to_transmit.numpy())\n",
    "        pbar.set_description(f\"Coded sample {i + 1}, has log prob of {t.log_prob(best_sample)}\")\n",
    "    \n",
    "    print(torch.mean(log_probs))\n",
    "    with open(f\"PickledStuff/Optimising_Vars/Dim{dim}/Variational_Epsilon{eps}_Beam{beamwidth}_Omega{omega}.pkl\", \"wb\") as f:\n",
    "        pkl.dump(exp_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75d1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
